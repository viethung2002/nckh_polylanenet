[2024-12-25 21:57:32,451] [INFO] Experiment name: tusimple
[2024-12-25 21:57:32,451] [INFO] Config:
# Training settings
exps_dir: 'experiments'
iter_log_interval: 1
iter_time_window: 100
model_save_interval: 1
seed: 1
backup:
model:
  name: PolyRegression
  parameters:
    num_outputs: 35 # (5 lanes) * (1 conf + 2 (upper & lower) + 4 poly coeffs)
    pretrained: true
    backbone: 'mobilenet_v2'
    pred_category: false
    curriculum_steps: [0, 0, 0, 0]
loss_parameters:
  conf_weight: 1
  lower_weight: 1
  upper_weight: 1
  cls_weight: 0
  poly_weight: 1000
batch_size: 1
epochs: 2695
optimizer:
  name: Adam
  parameters:
    lr: 3.0e-4
lr_scheduler:
  name: CosineAnnealingLR
  parameters:
    T_max: 385


# Testing settings
test_parameters:
  conf_threshold: 0.5

# Dataset settings
datasets:
  train:
    type: LaneDataset
    parameters:
      dataset: tusimple
      split: train
      img_size: [360, 640]
      normalize: true
      aug_chance: 0.9090909090909091 # 10/11
      augmentations:
       - name: Affine
         parameters:
           rotate: !!python/tuple [-10, 10]
       - name: HorizontalFlip
         parameters:
           p: 0.5
       - name: CropToFixedSize
         parameters:
           width: 1152
           height: 648
      root: "D:/manga/nckh_polylanenet/TUSimple/train_set"

  test: &test
    type: LaneDataset
    parameters:
      dataset: tusimple
      split: val
      max_lanes: 5
      img_size: [360, 640]
      root: "D:/manga/nckh_polylanenet/TUSimple/train_set"
      # D:\manga\nckh_polylanenet\TUSimple\train_set
      normalize: true
      augmentations: []

  # val = test
  val:
    <<: *test

[2024-12-25 21:57:32,457] [INFO] Args:
Namespace(exp_name='tusimple', cfg='D:\\manga\\nckh_polylanenet\\cfgs\\tusimple.yaml', resume=True, validate=True, deterministic=False)
total annos 910
Transforming annotations...
Done.
D:\manga\myenv\Lib\site-packages\torchvision\models\_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.
  warnings.warn(
D:\manga\myenv\Lib\site-packages\torchvision\models\_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=MobileNet_V2_Weights.IMAGENET1K_V1`. You can also use `weights=MobileNet_V2_Weights.DEFAULT` to get the most up-to-date weights.
  warnings.warn(msg)
D:\manga\nckh_polylanenet\train.py:33: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.
  checkpoint = torch.load(checkpoint_path, map_location=device)
--- Logging error ---
Traceback (most recent call last):
  File "C:\Users\LENOVO\AppData\Local\Programs\Python\Python311\Lib\logging\__init__.py", line 1113, in emit
    stream.write(msg + self.terminator)
  File "C:\Users\LENOVO\AppData\Local\Programs\Python\Python311\Lib\encodings\cp1252.py", line 19, in encode
    return codecs.charmap_encode(input,self.errors,encoding_table)[0]
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
UnicodeEncodeError: 'charmap' codec can't encode character '\u1eeb' in position 108: character maps to <undefined>
Call stack:
  File "D:\manga\nckh_polylanenet\train.py", line 288, in <module>
    train_state = get_exp_train_state(exp_root)
  File "D:\manga\nckh_polylanenet\train.py", line 223, in get_exp_train_state
    model, optimizer, scheduler, epoch = load_checkpoint(model, optimizer, scheduler, checkpoint_path)
  File "D:\manga\nckh_polylanenet\train.py", line 44, in load_checkpoint
    logging.info(f"Checkpoint loaded from {checkpoint_path}, starting từ epoch {epoch}")
Message: 'Checkpoint loaded from experiments\\tusimple\\models\\model_021.pt, starting từ epoch 21'
Arguments: ()
[2024-12-25 21:57:33,043] [INFO] Checkpoint loaded from experiments\tusimple\models\model_021.pt, starting từ epoch 21
[2024-12-25 21:57:33,072] [INFO] Loaded train state from experiments\tusimple\models\model_021.pt (epoch 21)
total annos 358
Transforming annotations...
Done.
[2024-12-25 21:57:33,118] [INFO] Model structure: PolyRegression(
  (sigmoid): Sigmoid()
  (model): ModuleList(
    (0): Sequential(
      (0): Conv2dNormActivation(
        (0): Conv2d(3, 32, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
        (1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (2): ReLU6(inplace=True)
      )
      (1): InvertedResidual(
        (conv): Sequential(
          (0): Conv2dNormActivation(
            (0): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=32, bias=False)
            (1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (2): ReLU6(inplace=True)
          )
          (1): Conv2d(32, 16, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (2): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
      )
    )
    (1): Sequential(
      (2): InvertedResidual(
        (conv): Sequential(
          (0): Conv2dNormActivation(
            (0): Conv2d(16, 96, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (2): ReLU6(inplace=True)
          )
          (1): Conv2dNormActivation(
            (0): Conv2d(96, 96, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=96, bias=False)
            (1): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (2): ReLU6(inplace=True)
          )
          (2): Conv2d(96, 24, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (3): BatchNorm2d(24, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
      )
      (3): InvertedResidual(
        (conv): Sequential(
          (0): Conv2dNormActivation(
            (0): Conv2d(24, 144, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(144, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (2): ReLU6(inplace=True)
          )
          (1): Conv2dNormActivation(
            (0): Conv2d(144, 144, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=144, bias=False)
            (1): BatchNorm2d(144, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (2): ReLU6(inplace=True)
          )
          (2): Conv2d(144, 24, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (3): BatchNorm2d(24, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
      )
    )
    (2): Sequential(
      (4): InvertedResidual(
        (conv): Sequential(
          (0): Conv2dNormActivation(
            (0): Conv2d(24, 144, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(144, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (2): ReLU6(inplace=True)
          )
          (1): Conv2dNormActivation(
            (0): Conv2d(144, 144, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=144, bias=False)
            (1): BatchNorm2d(144, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (2): ReLU6(inplace=True)
          )
          (2): Conv2d(144, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (3): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
      )
      (5): InvertedResidual(
        (conv): Sequential(
          (0): Conv2dNormActivation(
            (0): Conv2d(32, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (2): ReLU6(inplace=True)
          )
          (1): Conv2dNormActivation(
            (0): Conv2d(192, 192, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=192, bias=False)
            (1): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (2): ReLU6(inplace=True)
          )
          (2): Conv2d(192, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (3): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
      )
      (6): InvertedResidual(
        (conv): Sequential(
          (0): Conv2dNormActivation(
            (0): Conv2d(32, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (2): ReLU6(inplace=True)
          )
          (1): Conv2dNormActivation(
            (0): Conv2d(192, 192, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=192, bias=False)
            (1): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (2): ReLU6(inplace=True)
          )
          (2): Conv2d(192, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (3): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
      )
    )
    (3): Sequential(
      (7): InvertedResidual(
        (conv): Sequential(
          (0): Conv2dNormActivation(
            (0): Conv2d(32, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (2): ReLU6(inplace=True)
          )
          (1): Conv2dNormActivation(
            (0): Conv2d(192, 192, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=192, bias=False)
            (1): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (2): ReLU6(inplace=True)
          )
          (2): Conv2d(192, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (3): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
      )
      (8): InvertedResidual(
        (conv): Sequential(
          (0): Conv2dNormActivation(
            (0): Conv2d(64, 384, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (2): ReLU6(inplace=True)
          )
          (1): Conv2dNormActivation(
            (0): Conv2d(384, 384, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=384, bias=False)
            (1): BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (2): ReLU6(inplace=True)
          )
          (2): Conv2d(384, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (3): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
      )
      (9): InvertedResidual(
        (conv): Sequential(
          (0): Conv2dNormActivation(
            (0): Conv2d(64, 384, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (2): ReLU6(inplace=True)
          )
          (1): Conv2dNormActivation(
            (0): Conv2d(384, 384, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=384, bias=False)
            (1): BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (2): ReLU6(inplace=True)
          )
          (2): Conv2d(384, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (3): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
      )
      (10): InvertedResidual(
        (conv): Sequential(
          (0): Conv2dNormActivation(
            (0): Conv2d(64, 384, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (2): ReLU6(inplace=True)
          )
          (1): Conv2dNormActivation(
            (0): Conv2d(384, 384, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=384, bias=False)
            (1): BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (2): ReLU6(inplace=True)
          )
          (2): Conv2d(384, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (3): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
      )
      (11): InvertedResidual(
        (conv): Sequential(
          (0): Conv2dNormActivation(
            (0): Conv2d(64, 384, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (2): ReLU6(inplace=True)
          )
          (1): Conv2dNormActivation(
            (0): Conv2d(384, 384, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=384, bias=False)
            (1): BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (2): ReLU6(inplace=True)
          )
          (2): Conv2d(384, 96, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (3): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
      )
      (12): InvertedResidual(
        (conv): Sequential(
          (0): Conv2dNormActivation(
            (0): Conv2d(96, 576, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(576, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (2): ReLU6(inplace=True)
          )
          (1): Conv2dNormActivation(
            (0): Conv2d(576, 576, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=576, bias=False)
            (1): BatchNorm2d(576, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (2): ReLU6(inplace=True)
          )
          (2): Conv2d(576, 96, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (3): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
      )
      (13): InvertedResidual(
        (conv): Sequential(
          (0): Conv2dNormActivation(
            (0): Conv2d(96, 576, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(576, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (2): ReLU6(inplace=True)
          )
          (1): Conv2dNormActivation(
            (0): Conv2d(576, 576, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=576, bias=False)
            (1): BatchNorm2d(576, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (2): ReLU6(inplace=True)
          )
          (2): Conv2d(576, 96, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (3): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
      )
    )
  )
  (papfn): PathAggregationFeaturePyramidNetwork(
    (inner_blocks): ModuleList(
      (0): Conv2d(16, 256, kernel_size=(1, 1), stride=(1, 1))
      (1): Conv2d(24, 256, kernel_size=(1, 1), stride=(1, 1))
      (2): Conv2d(32, 256, kernel_size=(1, 1), stride=(1, 1))
      (3): Conv2d(96, 256, kernel_size=(1, 1), stride=(1, 1))
    )
    (layer_blocks): ModuleList(
      (0-3): 4 x Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    )
  )
  (papfn_output): Conv2d(256, 35, kernel_size=(1, 1), stride=(1, 1))
  (flip_block): FeatureFlipBlock(
    (conv): Conv2d(6, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (avg_pool): AvgPool2d(kernel_size=(1, 2), stride=(1, 2), padding=0)
  )
  (channel_adapter): Conv2d(256, 3, kernel_size=(1, 1), stride=(1, 1))
  (attention): SelfAttention(
    (attention): MultiheadAttention(
      (out_proj): NonDynamicallyQuantizableLinear(in_features=35, out_features=35, bias=True)
    )
    (norm): LayerNorm((35,), eps=1e-05, elementwise_affine=True)
  )
)
D:\manga\myenv\Lib\site-packages\torch\optim\lr_scheduler.py:232: UserWarning: The epoch parameter in `scheduler.step()` was not necessary and is being deprecated where possible. Please use `scheduler.step()` to step the scheduler. During the deprecation, if epoch is different from None, the closed form is used instead of the new chainable form, where available. Please open an issue if you are unable to replicate your use case: https://github.com/pytorch/pytorch/issues/new/choose.
  warnings.warn(EPOCH_DEPRECATION_WARNING, UserWarning)
[2024-12-25 21:57:33,172] [INFO] Starting training.
[2024-12-25 21:57:33,173] [INFO] Beginning epoch 22
[2024-12-25 21:58:32,025] [INFO] Epoch [22/2695], Step [1/910], Loss: 214.5645 (poly: 2.2543, lower: 0.0002, upper: 0.0127, cls_loss: 0.0000, line_iou: 211.9056, conf: 0.3917), s/iter: 6.7169, lr: 3.0e-04
[2024-12-25 21:58:32,114] [INFO] Epoch [22/2695], Step [2/910], Loss: 266.5943 (poly: 25.1755, lower: 0.0000, upper: 0.0322, cls_loss: 0.0000, line_iou: 293.0247, conf: 0.3917), s/iter: 3.3991, lr: 3.0e-04
[2024-12-25 21:58:32,175] [INFO] Epoch [22/2695], Step [3/910], Loss: 284.5044 (poly: 87.7878, lower: 0.0063, upper: 0.0401, cls_loss: 0.0000, line_iou: 232.0385, conf: 0.4519), s/iter: 2.2852, lr: 3.0e-04
[2024-12-25 21:58:32,228] [INFO] Epoch [22/2695], Step [4/910], Loss: 269.4827 (poly: 1.6835, lower: 0.0064, upper: 0.0173, cls_loss: 0.0000, line_iou: 222.4804, conf: 0.2301), s/iter: 1.7265, lr: 3.0e-04
[2024-12-25 21:58:32,279] [INFO] Epoch [22/2695], Step [5/910], Loss: 260.5487 (poly: 2.7525, lower: 0.0006, upper: 0.0203, cls_loss: 0.0000, line_iou: 221.6477, conf: 0.3915), s/iter: 1.3910, lr: 3.0e-04
[2024-12-25 21:58:32,331] [INFO] Epoch [22/2695], Step [6/910], Loss: 254.2691 (poly: 1.8825, lower: 0.0018, upper: 0.0147, cls_loss: 0.0000, line_iou: 220.7424, conf: 0.2299), s/iter: 1.1674, lr: 3.0e-04
[2024-12-25 21:58:32,384] [INFO] Epoch [22/2695], Step [7/910], Loss: 252.1199 (poly: 2.6121, lower: 0.0000, upper: 0.0126, cls_loss: 0.0000, line_iou: 236.3696, conf: 0.2299), s/iter: 1.0080, lr: 3.0e-04
[2024-12-25 21:58:32,431] [INFO] Epoch [22/2695], Step [8/910], Loss: 265.8014 (poly: 92.2158, lower: 0.0004, upper: 0.0456, cls_loss: 0.0000, line_iou: 268.8563, conf: 0.4541), s/iter: 0.8876, lr: 3.0e-04
[2024-12-25 21:58:32,462] [INFO] Weight SoftAdapt Loss tensor([300,   1,   1,   1, 300,   1])
[2024-12-25 21:58:32,504] [INFO] Epoch [22/2695], Step [9/910], Loss: 236.3403 (poly: 0.0005, lower: 0.0000, upper: 0.0000, cls_loss: 0.0000, line_iou: 0.4256, conf: 0.2256), s/iter: 0.7966, lr: 3.0e-04
[2024-12-25 21:58:32,557] [INFO] Epoch [22/2695], Step [10/910], Loss: 212.7577 (poly: 0.0000, lower: 0.0000, upper: 0.0000, cls_loss: 0.0000, line_iou: 0.4001, conf: 0.1142), s/iter: 0.7218, lr: 3.0e-04
[2024-12-25 21:58:32,606] [INFO] Epoch [22/2695], Step [11/910], Loss: 193.4655 (poly: 0.0000, lower: 0.0000, upper: 0.0000, cls_loss: 0.0000, line_iou: 0.4290, conf: 0.1142), s/iter: 0.6605, lr: 3.0e-04
[2024-12-25 21:58:32,656] [INFO] Epoch [22/2695], Step [12/910], Loss: 177.3999 (poly: 0.0004, lower: 0.0000, upper: 0.0000, cls_loss: 0.0000, line_iou: 0.4523, conf: 0.2259), s/iter: 0.6093, lr: 3.0e-04
[2024-12-25 21:58:32,711] [INFO] Epoch [22/2695], Step [13/910], Loss: 163.8041 (poly: 0.0001, lower: 0.0000, upper: 0.0001, cls_loss: 0.0000, line_iou: 0.4601, conf: 0.1944), s/iter: 0.5665, lr: 3.0e-04
[2024-12-25 21:58:32,765] [INFO] Epoch [22/2695], Step [14/910], Loss: 152.1524 (poly: 0.0002, lower: 0.0000, upper: 0.0001, cls_loss: 0.0000, line_iou: 0.4847, conf: 0.1945), s/iter: 0.5297, lr: 3.0e-04
[2024-12-25 21:58:32,823] [INFO] Epoch [22/2695], Step [15/910], Loss: 142.0455 (poly: 0.0000, lower: 0.0000, upper: 0.0000, cls_loss: 0.0000, line_iou: 0.4349, conf: 0.1142), s/iter: 0.4981, lr: 3.0e-04
[2024-12-25 21:58:32,874] [INFO] Epoch [22/2695], Step [16/910], Loss: 133.2057 (poly: 0.0000, lower: 0.0000, upper: 0.0000, cls_loss: 0.0000, line_iou: 0.4141, conf: 0.1945), s/iter: 0.4701, lr: 3.0e-04
[2024-12-25 21:58:32,925] [INFO] Epoch [22/2695], Step [17/910], Loss: 125.4118 (poly: 0.0004, lower: 0.0000, upper: 0.0001, cls_loss: 0.0000, line_iou: 0.4835, conf: 0.2262), s/iter: 0.4453, lr: 3.0e-04
[2024-12-25 21:58:32,957] [INFO] Weight SoftAdapt Loss tensor([0.0017, 0.0017, 0.0017, 0.0017, 0.4967, 0.4967], dtype=torch.float64)
[2024-12-25 21:58:32,985] [INFO] Epoch [22/2695], Step [18/910], Loss: 118.4645 (poly: 0.1323, lower: 0.0000, upper: 0.0001, cls_loss: 0.0000, line_iou: 0.0016, conf: 0.2263), s/iter: 0.4237, lr: 3.0e-04
[2024-12-25 21:58:33,033] [INFO] Epoch [22/2695], Step [19/910], Loss: 112.2487 (poly: 0.1361, lower: 0.0000, upper: 0.0001, cls_loss: 0.0000, line_iou: 0.0016, conf: 0.2263), s/iter: 0.4038, lr: 3.0e-04
[2024-12-25 21:58:33,085] [INFO] Epoch [22/2695], Step [20/910], Loss: 106.6422 (poly: 0.0022, lower: 0.0000, upper: 0.0000, cls_loss: 0.0000, line_iou: 0.0014, conf: 0.1143), s/iter: 0.3860, lr: 3.0e-04
[2024-12-25 21:58:33,135] [INFO] Epoch [22/2695], Step [21/910], Loss: 101.5700 (poly: 0.0102, lower: 0.0000, upper: 0.0000, cls_loss: 0.0000, line_iou: 0.0015, conf: 0.1142), s/iter: 0.3699, lr: 3.0e-04
[2024-12-25 21:58:33,183] [INFO] Epoch [22/2695], Step [22/910], Loss: 96.9586 (poly: 0.0033, lower: 0.0000, upper: 0.0000, cls_loss: 0.0000, line_iou: 0.0014, conf: 0.1142), s/iter: 0.3552, lr: 3.0e-04
[2024-12-25 21:58:33,230] [INFO] Epoch [22/2695], Step [23/910], Loss: 92.7589 (poly: 0.1380, lower: 0.0000, upper: 0.0001, cls_loss: 0.0000, line_iou: 0.0017, conf: 0.2264), s/iter: 0.3417, lr: 3.0e-04
[2024-12-25 21:58:33,281] [INFO] Epoch [22/2695], Step [24/910], Loss: 88.8989 (poly: 0.0028, lower: 0.0000, upper: 0.0000, cls_loss: 0.0000, line_iou: 0.0014, conf: 0.1142), s/iter: 0.3294, lr: 3.0e-04
[2024-12-25 21:58:33,333] [INFO] Epoch [22/2695], Step [25/910], Loss: 85.3476 (poly: 0.0025, lower: 0.0000, upper: 0.0000, cls_loss: 0.0000, line_iou: 0.0012, conf: 0.1142), s/iter: 0.3182, lr: 3.0e-04
[2024-12-25 21:58:33,379] [INFO] Epoch [22/2695], Step [26/910], Loss: 82.0729 (poly: 0.0093, lower: 0.0000, upper: 0.0001, cls_loss: 0.0000, line_iou: 0.0014, conf: 0.1946), s/iter: 0.3076, lr: 3.0e-04
[2024-12-25 21:58:33,406] [INFO] Weight SoftAdapt Loss tensor([0.4967, 0.0017, 0.0017, 0.0017, 0.0017, 0.4967], dtype=torch.float64)
[2024-12-25 21:58:33,437] [INFO] Epoch [22/2695], Step [27/910], Loss: 79.0528 (poly: 0.0984, lower: 0.0000, upper: 0.0000, cls_loss: 0.0000, line_iou: 0.4285, conf: 0.0008), s/iter: 0.2983, lr: 3.0e-04
[2024-12-25 21:58:33,485] [INFO] Epoch [22/2695], Step [28/910], Loss: 76.2440 (poly: 0.0037, lower: 0.0000, upper: 0.0000, cls_loss: 0.0000, line_iou: 0.4045, conf: 0.0004), s/iter: 0.2893, lr: 3.0e-04
[2024-12-25 21:58:33,537] [INFO] Epoch [22/2695], Step [29/910], Loss: 73.6273 (poly: 0.0034, lower: 0.0000, upper: 0.0000, cls_loss: 0.0000, line_iou: 0.3540, conf: 0.0004), s/iter: 0.2810, lr: 3.0e-04
[2024-12-25 21:58:33,595] [INFO] Epoch [22/2695], Step [30/910], Loss: 71.1897 (poly: 0.1086, lower: 0.0000, upper: 0.0000, cls_loss: 0.0000, line_iou: 0.3922, conf: 0.0008), s/iter: 0.2735, lr: 3.0e-04
[2024-12-25 21:58:33,645] [INFO] Epoch [22/2695], Step [31/910], Loss: 68.9064 (poly: 0.0030, lower: 0.0000, upper: 0.0000, cls_loss: 0.0000, line_iou: 0.4018, conf: 0.0004), s/iter: 0.2662, lr: 3.0e-04
[2024-12-25 21:58:33,698] [INFO] Epoch [22/2695], Step [32/910], Loss: 66.7697 (poly: 0.1117, lower: 0.0000, upper: 0.0000, cls_loss: 0.0000, line_iou: 0.4210, conf: 0.0008), s/iter: 0.2594, lr: 3.0e-04
[2024-12-25 21:58:33,748] [INFO] Epoch [22/2695], Step [33/910], Loss: 64.7632 (poly: 0.0692, lower: 0.0000, upper: 0.0002, cls_loss: 0.0000, line_iou: 0.4855, conf: 0.0006), s/iter: 0.2530, lr: 3.0e-04
[2024-12-25 21:58:33,795] [INFO] Epoch [22/2695], Step [34/910], Loss: 62.8768 (poly: 0.1356, lower: 0.0000, upper: 0.0001, cls_loss: 0.0000, line_iou: 0.4878, conf: 0.0008), s/iter: 0.2469, lr: 3.0e-04
[2024-12-25 21:58:33,839] [INFO] Epoch [22/2695], Step [35/910], Loss: 61.0933 (poly: 0.0058, lower: 0.0000, upper: 0.0000, cls_loss: 0.0000, line_iou: 0.4476, conf: 0.0004), s/iter: 0.2410, lr: 3.0e-04
[2024-12-25 21:58:33,862] [INFO] Weight SoftAdapt Loss tensor([0.4967, 0.0017, 0.0017, 0.0017, 0.4967, 0.0017], dtype=torch.float64)
[2024-12-25 21:58:33,886] [INFO] Epoch [22/2695], Step [36/910], Loss: 59.4115 (poly: 0.0000, lower: 0.0000, upper: 0.0000, cls_loss: 0.0000, line_iou: 0.4337, conf: 0.1142), s/iter: 0.2356, lr: 3.0e-04
[2024-12-25 21:58:33,931] [INFO] Epoch [22/2695], Step [37/910], Loss: 57.8200 (poly: 0.0000, lower: 0.0000, upper: 0.0000, cls_loss: 0.0000, line_iou: 0.4133, conf: 0.1142), s/iter: 0.2304, lr: 3.0e-04
[2024-12-25 21:58:33,974] [INFO] Epoch [22/2695], Step [38/910], Loss: 56.3118 (poly: 0.0000, lower: 0.0000, upper: 0.0000, cls_loss: 0.0000, line_iou: 0.3956, conf: 0.1141), s/iter: 0.2254, lr: 3.0e-04
[2024-12-25 21:58:34,017] [INFO] Epoch [22/2695], Step [39/910], Loss: 54.8819 (poly: 0.0000, lower: 0.0000, upper: 0.0000, cls_loss: 0.0000, line_iou: 0.4289, conf: 0.1141), s/iter: 0.2207, lr: 3.0e-04
[2024-12-25 21:58:34,068] [INFO] Epoch [22/2695], Step [40/910], Loss: 53.5269 (poly: 0.0002, lower: 0.0000, upper: 0.0002, cls_loss: 0.0000, line_iou: 0.4865, conf: 0.1946), s/iter: 0.2163, lr: 3.0e-04
[2024-12-25 21:58:34,119] [INFO] Epoch [22/2695], Step [41/910], Loss: 52.2341 (poly: 0.0000, lower: 0.0000, upper: 0.0000, cls_loss: 0.0000, line_iou: 0.4114, conf: 0.1141), s/iter: 0.2122, lr: 3.0e-04
[2024-12-25 21:58:34,178] [INFO] Epoch [22/2695], Step [42/910], Loss: 51.0042 (poly: 0.0000, lower: 0.0000, upper: 0.0000, cls_loss: 0.0000, line_iou: 0.3822, conf: 0.1946), s/iter: 0.2085, lr: 3.0e-04
[2024-12-25 21:58:34,233] [INFO] Epoch [22/2695], Step [43/910], Loss: 49.8307 (poly: 0.0000, lower: 0.0000, upper: 0.0000, cls_loss: 0.0000, line_iou: 0.4285, conf: 0.1141), s/iter: 0.2048, lr: 3.0e-04
[2024-12-25 21:58:34,277] [INFO] Epoch [22/2695], Step [44/910], Loss: 48.7136 (poly: 0.0002, lower: 0.0000, upper: 0.0001, cls_loss: 0.0000, line_iou: 0.4821, conf: 0.1946), s/iter: 0.2012, lr: 3.0e-04
[2024-12-25 21:58:34,301] [INFO] Weight SoftAdapt Loss tensor([0.0017, 0.0017, 0.0017, 0.0017, 0.4967, 0.4967], dtype=torch.float64)
[2024-12-25 21:58:34,332] [INFO] Epoch [22/2695], Step [45/910], Loss: 47.6367 (poly: 0.0600, lower: 0.0000, upper: 0.0002, cls_loss: 0.0000, line_iou: 0.0016, conf: 0.1946), s/iter: 0.1978, lr: 3.0e-04
[2024-12-25 21:58:34,378] [INFO] Epoch [22/2695], Step [46/910], Loss: 46.6065 (poly: 0.0517, lower: 0.0000, upper: 0.0002, cls_loss: 0.0000, line_iou: 0.0016, conf: 0.1946), s/iter: 0.1945, lr: 3.0e-04
[2024-12-25 21:58:34,424] [INFO] Epoch [22/2695], Step [47/910], Loss: 45.6192 (poly: 0.0039, lower: 0.0000, upper: 0.0000, cls_loss: 0.0000, line_iou: 0.0013, conf: 0.1946), s/iter: 0.1913, lr: 3.0e-04
[2024-12-25 21:58:34,469] [INFO] Epoch [22/2695], Step [48/910], Loss: 44.6741 (poly: 0.0603, lower: 0.0000, upper: 0.0002, cls_loss: 0.0000, line_iou: 0.0016, conf: 0.1946), s/iter: 0.1882, lr: 3.0e-04
[2024-12-25 21:58:34,517] [INFO] Epoch [22/2695], Step [49/910], Loss: 43.7648 (poly: 0.0026, lower: 0.0000, upper: 0.0000, cls_loss: 0.0000, line_iou: 0.0012, conf: 0.1141), s/iter: 0.1853, lr: 3.0e-04
[2024-12-25 21:58:34,564] [INFO] Epoch [22/2695], Step [50/910], Loss: 42.8921 (poly: 0.0154, lower: 0.0000, upper: 0.0001, cls_loss: 0.0000, line_iou: 0.0015, conf: 0.1141), s/iter: 0.1825, lr: 3.0e-04
[2024-12-25 21:58:34,610] [INFO] Epoch [22/2695], Step [51/910], Loss: 42.0561 (poly: 0.0575, lower: 0.0000, upper: 0.0002, cls_loss: 0.0000, line_iou: 0.0016, conf: 0.1945), s/iter: 0.1797, lr: 3.0e-04
[2024-12-25 21:58:34,656] [INFO] Epoch [22/2695], Step [52/910], Loss: 41.2496 (poly: 0.0039, lower: 0.0000, upper: 0.0000, cls_loss: 0.0000, line_iou: 0.0014, conf: 0.1141), s/iter: 0.1771, lr: 3.0e-04
[2024-12-25 21:58:34,705] [INFO] Epoch [22/2695], Step [53/910], Loss: 40.4735 (poly: 0.0026, lower: 0.0000, upper: 0.0000, cls_loss: 0.0000, line_iou: 0.0013, conf: 0.1141), s/iter: 0.1746, lr: 3.0e-04
[2024-12-25 21:58:34,731] [INFO] Weight SoftAdapt Loss tensor([0.4967, 0.0017, 0.0017, 0.0017, 0.0017, 0.4967], dtype=torch.float64)
[2024-12-25 21:58:34,755] [INFO] Epoch [22/2695], Step [54/910], Loss: 39.7315 (poly: 0.0039, lower: 0.0000, upper: 0.0000, cls_loss: 0.0000, line_iou: 0.4013, conf: 0.0004), s/iter: 0.1723, lr: 3.0e-04
[2024-12-25 21:58:34,805] [INFO] Epoch [22/2695], Step [55/910], Loss: 39.0168 (poly: 0.0041, lower: 0.0000, upper: 0.0000, cls_loss: 0.0000, line_iou: 0.4191, conf: 0.0004), s/iter: 0.1700, lr: 3.0e-04
[2024-12-25 21:58:34,856] [INFO] Epoch [22/2695], Step [56/910], Loss: 38.3285 (poly: 0.0181, lower: 0.0000, upper: 0.0001, cls_loss: 0.0000, line_iou: 0.4506, conf: 0.0006), s/iter: 0.1678, lr: 3.0e-04
[2024-12-25 21:58:34,928] [INFO] Epoch [22/2695], Step [57/910], Loss: 37.6636 (poly: 0.0062, lower: 0.0000, upper: 0.0000, cls_loss: 0.0000, line_iou: 0.4244, conf: 0.0004), s/iter: 0.1661, lr: 3.0e-04
[2024-12-25 21:58:34,977] [INFO] Epoch [22/2695], Step [58/910], Loss: 37.0252 (poly: 0.1355, lower: 0.0000, upper: 0.0002, cls_loss: 0.0000, line_iou: 0.4955, conf: 0.0008), s/iter: 0.1640, lr: 3.0e-04
[2024-12-25 21:58:35,026] [INFO] Epoch [22/2695], Step [59/910], Loss: 36.4048 (poly: 0.0046, lower: 0.0000, upper: 0.0000, cls_loss: 0.0000, line_iou: 0.4170, conf: 0.0006), s/iter: 0.1620, lr: 3.0e-04
[2024-12-25 21:58:35,086] [INFO] Epoch [22/2695], Step [60/910], Loss: 35.8052 (poly: 0.0053, lower: 0.0000, upper: 0.0000, cls_loss: 0.0000, line_iou: 0.4268, conf: 0.0004), s/iter: 0.1603, lr: 3.0e-04
[2024-12-25 21:58:35,139] [INFO] Epoch [22/2695], Step [61/910], Loss: 35.2256 (poly: 0.0049, lower: 0.0000, upper: 0.0000, cls_loss: 0.0000, line_iou: 0.4443, conf: 0.0004), s/iter: 0.1585, lr: 3.0e-04
[2024-12-25 21:58:35,187] [INFO] Epoch [22/2695], Step [62/910], Loss: 34.6645 (poly: 0.0052, lower: 0.0000, upper: 0.0000, cls_loss: 0.0000, line_iou: 0.4323, conf: 0.0004), s/iter: 0.1567, lr: 3.0e-04
[2024-12-25 21:58:35,212] [INFO] Weight SoftAdapt Loss tensor([0.4967, 0.0017, 0.0017, 0.0017, 0.4967, 0.0017], dtype=torch.float64)
[2024-12-25 21:58:35,239] [INFO] Epoch [22/2695], Step [63/910], Loss: 34.1256 (poly: 0.0004, lower: 0.0000, upper: 0.0001, cls_loss: 0.0000, line_iou: 0.4837, conf: 0.2267), s/iter: 0.1550, lr: 3.0e-04
[2024-12-25 21:58:35,291] [INFO] Epoch [22/2695], Step [64/910], Loss: 33.6031 (poly: 0.0004, lower: 0.0000, upper: 0.0001, cls_loss: 0.0000, line_iou: 0.4604, conf: 0.2266), s/iter: 0.1533, lr: 3.0e-04
[2024-12-25 21:58:35,338] [INFO] Epoch [22/2695], Step [65/910], Loss: 33.0961 (poly: 0.0001, lower: 0.0000, upper: 0.0000, cls_loss: 0.0000, line_iou: 0.4514, conf: 0.1943), s/iter: 0.1516, lr: 3.0e-04
[2024-12-25 21:58:35,384] [INFO] Epoch [22/2695], Step [66/910], Loss: 32.6027 (poly: 0.0000, lower: 0.0000, upper: 0.0000, cls_loss: 0.0000, line_iou: 0.4210, conf: 0.1141), s/iter: 0.1500, lr: 3.0e-04
[2024-12-25 21:58:35,437] [INFO] Epoch [22/2695], Step [67/910], Loss: 32.1261 (poly: 0.0002, lower: 0.0000, upper: 0.0001, cls_loss: 0.0000, line_iou: 0.4738, conf: 0.1943), s/iter: 0.1485, lr: 3.0e-04
[2024-12-25 21:58:35,488] [INFO] Epoch [22/2695], Step [68/910], Loss: 31.6618 (poly: 0.0000, lower: 0.0000, upper: 0.0000, cls_loss: 0.0000, line_iou: 0.4374, conf: 0.1141), s/iter: 0.1470, lr: 3.0e-04
[2024-12-25 21:58:35,542] [INFO] Epoch [22/2695], Step [69/910], Loss: 31.2126 (poly: 0.0002, lower: 0.0000, upper: 0.0001, cls_loss: 0.0000, line_iou: 0.4771, conf: 0.1942), s/iter: 0.1457, lr: 3.0e-04
[2024-12-25 21:58:35,595] [INFO] Epoch [22/2695], Step [70/910], Loss: 30.7770 (poly: 0.0004, lower: 0.0000, upper: 0.0001, cls_loss: 0.0000, line_iou: 0.4896, conf: 0.2266), s/iter: 0.1443, lr: 3.0e-04
[2024-12-25 21:58:35,646] [INFO] Epoch [22/2695], Step [71/910], Loss: 30.3537 (poly: 0.0004, lower: 0.0000, upper: 0.0002, cls_loss: 0.0000, line_iou: 0.4943, conf: 0.2265), s/iter: 0.1430, lr: 3.0e-04
[2024-12-25 21:58:35,668] [INFO] Weight SoftAdapt Loss tensor([0.0017, 0.0017, 0.0017, 0.0017, 0.4967, 0.4967], dtype=torch.float64)
[2024-12-25 21:58:35,701] [INFO] Epoch [22/2695], Step [72/910], Loss: 29.9349 (poly: 0.0054, lower: 0.0000, upper: 0.0000, cls_loss: 0.0000, line_iou: 0.0012, conf: 0.1942), s/iter: 0.1417, lr: 3.0e-04
[2024-12-25 21:58:35,754] [INFO] Epoch [22/2695], Step [73/910], Loss: 29.5264 (poly: 0.0037, lower: 0.0000, upper: 0.0000, cls_loss: 0.0000, line_iou: 0.0014, conf: 0.1140), s/iter: 0.1404, lr: 3.0e-04
[2024-12-25 21:58:35,803] [INFO] Epoch [22/2695], Step [74/910], Loss: 29.1290 (poly: 0.0030, lower: 0.0000, upper: 0.0000, cls_loss: 0.0000, line_iou: 0.0014, conf: 0.1140), s/iter: 0.1392, lr: 3.0e-04
[2024-12-25 21:58:35,849] [INFO] Epoch [22/2695], Step [75/910], Loss: 28.7454 (poly: 0.1278, lower: 0.0000, upper: 0.0001, cls_loss: 0.0000, line_iou: 0.0016, conf: 0.2266), s/iter: 0.1379, lr: 3.0e-04
[2024-12-25 21:58:35,903] [INFO] Epoch [22/2695], Step [76/910], Loss: 28.3714 (poly: 0.0905, lower: 0.0000, upper: 0.0000, cls_loss: 0.0000, line_iou: 0.0015, conf: 0.2266), s/iter: 0.1367, lr: 3.0e-04
[2024-12-25 21:58:35,956] [INFO] Epoch [22/2695], Step [77/910], Loss: 28.0074 (poly: 0.1207, lower: 0.0000, upper: 0.0001, cls_loss: 0.0000, line_iou: 0.0016, conf: 0.2266), s/iter: 0.1356, lr: 3.0e-04
[2024-12-25 21:58:36,001] [INFO] Epoch [22/2695], Step [78/910], Loss: 27.6499 (poly: 0.0039, lower: 0.0000, upper: 0.0000, cls_loss: 0.0000, line_iou: 0.0014, conf: 0.1140), s/iter: 0.1344, lr: 3.0e-04
[2024-12-25 21:58:36,047] [INFO] Epoch [22/2695], Step [79/910], Loss: 27.3044 (poly: 0.1253, lower: 0.0000, upper: 0.0001, cls_loss: 0.0000, line_iou: 0.0016, conf: 0.2265), s/iter: 0.1333, lr: 3.0e-04
[2024-12-25 21:58:36,095] [INFO] Epoch [22/2695], Step [80/910], Loss: 26.9646 (poly: 0.0034, lower: 0.0000, upper: 0.0000, cls_loss: 0.0000, line_iou: 0.0014, conf: 0.1140), s/iter: 0.1322, lr: 3.0e-04
[2024-12-25 21:58:36,117] [INFO] Weight SoftAdapt Loss tensor([0.4967, 0.0017, 0.0017, 0.0017, 0.0017, 0.4967], dtype=torch.float64)
[2024-12-25 21:58:36,141] [INFO] Epoch [22/2695], Step [81/910], Loss: 26.6382 (poly: 0.0943, lower: 0.0000, upper: 0.0000, cls_loss: 0.0000, line_iou: 0.4310, conf: 0.0008), s/iter: 0.1311, lr: 3.0e-04
[2024-12-25 21:58:36,195] [INFO] Epoch [22/2695], Step [82/910], Loss: 26.3186 (poly: 0.0036, lower: 0.0000, upper: 0.0000, cls_loss: 0.0000, line_iou: 0.4327, conf: 0.0004), s/iter: 0.1301, lr: 3.0e-04
[2024-12-25 21:58:36,238] [INFO] Epoch [22/2695], Step [83/910], Loss: 26.0065 (poly: 0.0060, lower: 0.0000, upper: 0.0000, cls_loss: 0.0000, line_iou: 0.4102, conf: 0.0004), s/iter: 0.1291, lr: 3.0e-04
[2024-12-25 21:58:36,291] [INFO] Epoch [22/2695], Step [84/910], Loss: 25.7036 (poly: 0.0577, lower: 0.0000, upper: 0.0001, cls_loss: 0.0000, line_iou: 0.4967, conf: 0.0004), s/iter: 0.1281, lr: 3.0e-04
[2024-12-25 21:58:36,349] [INFO] Epoch [22/2695], Step [85/910], Loss: 25.4079 (poly: 0.0743, lower: 0.0000, upper: 0.0001, cls_loss: 0.0000, line_iou: 0.4967, conf: 0.0004), s/iter: 0.1273, lr: 3.0e-04
[2024-12-25 21:58:36,395] [INFO] Epoch [22/2695], Step [86/910], Loss: 25.1197 (poly: 0.1312, lower: 0.0000, upper: 0.0001, cls_loss: 0.0000, line_iou: 0.4925, conf: 0.0008), s/iter: 0.1263, lr: 3.0e-04
[2024-12-25 21:58:36,449] [INFO] Epoch [22/2695], Step [87/910], Loss: 24.8382 (poly: 0.1344, lower: 0.0000, upper: 0.0001, cls_loss: 0.0000, line_iou: 0.4911, conf: 0.0008), s/iter: 0.1254, lr: 3.0e-04
[2024-12-25 21:58:36,498] [INFO] Epoch [22/2695], Step [88/910], Loss: 24.5606 (poly: 0.0057, lower: 0.0000, upper: 0.0000, cls_loss: 0.0000, line_iou: 0.4089, conf: 0.0004), s/iter: 0.1245, lr: 3.0e-04
[2024-12-25 21:58:36,544] [INFO] Epoch [22/2695], Step [89/910], Loss: 24.2907 (poly: 0.0987, lower: 0.0000, upper: 0.0000, cls_loss: 0.0000, line_iou: 0.4405, conf: 0.0008), s/iter: 0.1236, lr: 3.0e-04
[2024-12-25 21:58:36,568] [INFO] Weight SoftAdapt Loss tensor([0.4967, 0.0017, 0.0017, 0.0017, 0.4967, 0.0017], dtype=torch.float64)
[2024-12-25 21:58:36,593] [INFO] Epoch [22/2695], Step [90/910], Loss: 24.0281 (poly: 0.0003, lower: 0.0000, upper: 0.0000, cls_loss: 0.0000, line_iou: 0.4262, conf: 0.2264), s/iter: 0.1228, lr: 3.0e-04
[2024-12-25 21:58:36,641] [INFO] Epoch [22/2695], Step [91/910], Loss: 23.7714 (poly: 0.0002, lower: 0.0000, upper: 0.0002, cls_loss: 0.0000, line_iou: 0.4784, conf: 0.1942), s/iter: 0.1219, lr: 3.0e-04
[2024-12-25 21:58:36,684] [INFO] Epoch [22/2695], Step [92/910], Loss: 23.5192 (poly: 0.0000, lower: 0.0000, upper: 0.0000, cls_loss: 0.0000, line_iou: 0.3705, conf: 0.1942), s/iter: 0.1210, lr: 3.0e-04
[2024-12-25 21:58:36,730] [INFO] Epoch [22/2695], Step [93/910], Loss: 23.2720 (poly: 0.0000, lower: 0.0000, upper: 0.0000, cls_loss: 0.0000, line_iou: 0.4115, conf: 0.1139), s/iter: 0.1202, lr: 3.0e-04
[2024-12-25 21:58:36,776] [INFO] Epoch [22/2695], Step [94/910], Loss: 23.0314 (poly: 0.0003, lower: 0.0000, upper: 0.0000, cls_loss: 0.0000, line_iou: 0.4293, conf: 0.2263), s/iter: 0.1194, lr: 3.0e-04
[2024-12-25 21:58:36,832] [INFO] Epoch [22/2695], Step [95/910], Loss: 22.7945 (poly: 0.0000, lower: 0.0000, upper: 0.0000, cls_loss: 0.0000, line_iou: 0.4118, conf: 0.1138), s/iter: 0.1187, lr: 3.0e-04
[2024-12-25 21:58:36,890] [INFO] Epoch [22/2695], Step [96/910], Loss: 22.5638 (poly: 0.0003, lower: 0.0000, upper: 0.0000, cls_loss: 0.0000, line_iou: 0.4270, conf: 0.2263), s/iter: 0.1180, lr: 3.0e-04
[2024-12-25 21:58:36,935] [INFO] Epoch [22/2695], Step [97/910], Loss: 22.3364 (poly: 0.0000, lower: 0.0000, upper: 0.0000, cls_loss: 0.0000, line_iou: 0.3869, conf: 0.1138), s/iter: 0.1172, lr: 3.0e-04
[2024-12-25 21:58:36,980] [INFO] Epoch [22/2695], Step [98/910], Loss: 22.1141 (poly: 0.0000, lower: 0.0000, upper: 0.0000, cls_loss: 0.0000, line_iou: 0.4361, conf: 0.1138), s/iter: 0.1164, lr: 3.0e-04
[2024-12-25 21:58:37,002] [INFO] Weight SoftAdapt Loss tensor([0.0017, 0.0017, 0.0017, 0.0017, 0.4967, 0.4967], dtype=torch.float64)
[2024-12-25 21:58:37,027] [INFO] Epoch [22/2695], Step [99/910], Loss: 21.8944 (poly: 0.1369, lower: 0.0000, upper: 0.0001, cls_loss: 0.0000, line_iou: 0.0016, conf: 0.2263), s/iter: 0.1157, lr: 3.0e-04
[2024-12-25 21:58:37,078] [INFO] Epoch [22/2695], Step [100/910], Loss: 21.6766 (poly: 0.0063, lower: 0.0000, upper: 0.0000, cls_loss: 0.0000, line_iou: 0.0014, conf: 0.1138), s/iter: 0.1151, lr: 3.0e-04
[2024-12-25 21:58:37,130] [INFO] Epoch [22/2695], Step [101/910], Loss: 21.4656 (poly: 0.1382, lower: 0.0000, upper: 0.0002, cls_loss: 0.0000, line_iou: 0.0016, conf: 0.2262), s/iter: 0.0484, lr: 3.0e-04
[2024-12-25 21:58:37,175] [INFO] Epoch [22/2695], Step [102/910], Loss: 21.2564 (poly: 0.0035, lower: 0.0000, upper: 0.0000, cls_loss: 0.0000, line_iou: 0.0013, conf: 0.1138), s/iter: 0.0480, lr: 3.0e-04
[2024-12-25 21:58:37,220] [INFO] Epoch [22/2695], Step [103/910], Loss: 21.0512 (poly: 0.0042, lower: 0.0000, upper: 0.0000, cls_loss: 0.0000, line_iou: 0.0014, conf: 0.1138), s/iter: 0.0478, lr: 3.0e-04
[2024-12-25 21:58:37,265] [INFO] Epoch [22/2695], Step [104/910], Loss: 20.8499 (poly: 0.0034, lower: 0.0000, upper: 0.0000, cls_loss: 0.0000, line_iou: 0.0014, conf: 0.1138), s/iter: 0.0478, lr: 3.0e-04
[2024-12-25 21:58:37,310] [INFO] Epoch [22/2695], Step [105/910], Loss: 20.6548 (poly: 0.1408, lower: 0.0000, upper: 0.0001, cls_loss: 0.0000, line_iou: 0.0016, conf: 0.2261), s/iter: 0.0477, lr: 3.0e-04
[2024-12-25 21:58:37,366] [INFO] Epoch [22/2695], Step [106/910], Loss: 20.4611 (poly: 0.0048, lower: 0.0000, upper: 0.0000, cls_loss: 0.0000, line_iou: 0.0015, conf: 0.1138), s/iter: 0.0477, lr: 3.0e-04
[2024-12-25 21:58:37,414] [INFO] Epoch [22/2695], Step [107/910], Loss: 20.2724 (poly: 0.0730, lower: 0.0000, upper: 0.0002, cls_loss: 0.0000, line_iou: 0.0016, conf: 0.1943), s/iter: 0.0477, lr: 3.0e-04
[2024-12-25 21:58:37,436] [INFO] Weight SoftAdapt Loss tensor([0.4967, 0.0017, 0.0017, 0.0017, 0.0017, 0.4967], dtype=torch.float64)
[2024-12-25 21:58:37,462] [INFO] Epoch [22/2695], Step [108/910], Loss: 20.0897 (poly: 0.1068, lower: 0.0000, upper: 0.0000, cls_loss: 0.0000, line_iou: 0.4370, conf: 0.0008), s/iter: 0.0477, lr: 3.0e-04
[2024-12-25 21:58:37,508] [INFO] Epoch [22/2695], Step [109/910], Loss: 19.9093 (poly: 0.0027, lower: 0.0000, upper: 0.0000, cls_loss: 0.0000, line_iou: 0.4218, conf: 0.0004), s/iter: 0.0474, lr: 3.0e-04
[2024-12-25 21:58:37,561] [INFO] Epoch [22/2695], Step [110/910], Loss: 19.7321 (poly: 0.0034, lower: 0.0000, upper: 0.0000, cls_loss: 0.0000, line_iou: 0.4094, conf: 0.0006), s/iter: 0.0474, lr: 3.0e-04
[2024-12-25 21:58:37,623] [INFO] Epoch [22/2695], Step [111/910], Loss: 19.5581 (poly: 0.0041, lower: 0.0000, upper: 0.0000, cls_loss: 0.0000, line_iou: 0.4180, conf: 0.0004), s/iter: 0.0476, lr: 3.0e-04
[2024-12-25 21:58:37,675] [INFO] Epoch [22/2695], Step [112/910], Loss: 19.3871 (poly: 0.0039, lower: 0.0000, upper: 0.0000, cls_loss: 0.0000, line_iou: 0.4037, conf: 0.0004), s/iter: 0.0476, lr: 3.0e-04
[2024-12-25 21:58:37,726] [INFO] Epoch [22/2695], Step [113/910], Loss: 19.2196 (poly: 0.0043, lower: 0.0000, upper: 0.0000, cls_loss: 0.0000, line_iou: 0.4494, conf: 0.0004), s/iter: 0.0476, lr: 3.0e-04
[2024-12-25 21:58:37,772] [INFO] Epoch [22/2695], Step [114/910], Loss: 19.0558 (poly: 0.1057, lower: 0.0000, upper: 0.0000, cls_loss: 0.0000, line_iou: 0.4474, conf: 0.0008), s/iter: 0.0475, lr: 3.0e-04
[2024-12-25 21:58:37,820] [INFO] Epoch [22/2695], Step [115/910], Loss: 18.8938 (poly: 0.0028, lower: 0.0000, upper: 0.0000, cls_loss: 0.0000, line_iou: 0.4165, conf: 0.0004), s/iter: 0.0474, lr: 3.0e-04
[2024-12-25 21:58:37,874] [INFO] Epoch [22/2695], Step [116/910], Loss: 18.7344 (poly: 0.0028, lower: 0.0000, upper: 0.0000, cls_loss: 0.0000, line_iou: 0.4002, conf: 0.0004), s/iter: 0.0474, lr: 3.0e-04
[2024-12-25 21:58:37,898] [INFO] Weight SoftAdapt Loss tensor([0.4967, 0.0017, 0.0017, 0.0017, 0.4967, 0.0017], dtype=torch.float64)
[2024-12-25 21:58:37,922] [INFO] Epoch [22/2695], Step [117/910], Loss: 18.5786 (poly: 0.0000, lower: 0.0000, upper: 0.0000, cls_loss: 0.0000, line_iou: 0.3976, conf: 0.1136), s/iter: 0.0474, lr: 3.0e-04
[2024-12-25 21:58:37,980] [INFO] Epoch [22/2695], Step [118/910], Loss: 18.4269 (poly: 0.0004, lower: 0.0000, upper: 0.0000, cls_loss: 0.0000, line_iou: 0.4470, conf: 0.2260), s/iter: 0.0473, lr: 3.0e-04
[2024-12-25 21:58:38,035] [INFO] Epoch [22/2695], Step [119/910], Loss: 18.2765 (poly: 0.0000, lower: 0.0000, upper: 0.0000, cls_loss: 0.0000, line_iou: 0.4155, conf: 0.1137), s/iter: 0.0474, lr: 3.0e-04
[2024-12-25 21:58:38,082] [INFO] Epoch [22/2695], Step [120/910], Loss: 18.1298 (poly: 0.0004, lower: 0.0000, upper: 0.0000, cls_loss: 0.0000, line_iou: 0.4469, conf: 0.2259), s/iter: 0.0474, lr: 3.0e-04
[2024-12-25 21:58:38,128] [INFO] Epoch [22/2695], Step [121/910], Loss: 17.9844 (poly: 0.0000, lower: 0.0000, upper: 0.0000, cls_loss: 0.0000, line_iou: 0.4193, conf: 0.1136), s/iter: 0.0473, lr: 3.0e-04
[2024-12-25 21:58:38,178] [INFO] Epoch [22/2695], Step [122/910], Loss: 17.8415 (poly: 0.0000, lower: 0.0000, upper: 0.0000, cls_loss: 0.0000, line_iou: 0.4427, conf: 0.1137), s/iter: 0.0474, lr: 3.0e-04
[2024-12-25 21:58:38,226] [INFO] Epoch [22/2695], Step [123/910], Loss: 17.7020 (poly: 0.0004, lower: 0.0000, upper: 0.0000, cls_loss: 0.0000, line_iou: 0.4489, conf: 0.2259), s/iter: 0.0473, lr: 3.0e-04
[2024-12-25 21:58:38,269] [INFO] Epoch [22/2695], Step [124/910], Loss: 17.5637 (poly: 0.0000, lower: 0.0000, upper: 0.0000, cls_loss: 0.0000, line_iou: 0.4378, conf: 0.1136), s/iter: 0.0473, lr: 3.0e-04
[2024-12-25 21:58:38,322] [INFO] Epoch [22/2695], Step [125/910], Loss: 17.4275 (poly: 0.0000, lower: 0.0000, upper: 0.0000, cls_loss: 0.0000, line_iou: 0.4257, conf: 0.1136), s/iter: 0.0473, lr: 3.0e-04
[2024-12-25 21:58:38,345] [INFO] Weight SoftAdapt Loss tensor([0.0017, 0.0017, 0.0017, 0.0017, 0.4967, 0.4967], dtype=torch.float64)
[2024-12-25 21:58:38,370] [INFO] Epoch [22/2695], Step [126/910], Loss: 17.2912 (poly: 0.0596, lower: 0.0000, upper: 0.0002, cls_loss: 0.0000, line_iou: 0.0016, conf: 0.1944), s/iter: 0.0473, lr: 3.0e-04
[2024-12-25 21:58:38,431] [INFO] Epoch [22/2695], Step [127/910], Loss: 17.1560 (poly: 0.0083, lower: 0.0000, upper: 0.0000, cls_loss: 0.0000, line_iou: 0.0015, conf: 0.1136), s/iter: 0.0473, lr: 3.0e-04
[2024-12-25 21:58:38,481] [INFO] Epoch [22/2695], Step [128/910], Loss: 17.0232 (poly: 0.0451, lower: 0.0000, upper: 0.0001, cls_loss: 0.0000, line_iou: 0.0016, conf: 0.1135), s/iter: 0.0473, lr: 3.0e-04
[2024-12-25 21:58:38,539] [INFO] Epoch [22/2695], Step [129/910], Loss: 16.8922 (poly: 0.0026, lower: 0.0000, upper: 0.0000, cls_loss: 0.0000, line_iou: 0.0014, conf: 0.1136), s/iter: 0.0474, lr: 3.0e-04
[2024-12-25 21:58:38,583] [INFO] Epoch [22/2695], Step [130/910], Loss: 16.7631 (poly: 0.0028, lower: 0.0000, upper: 0.0000, cls_loss: 0.0000, line_iou: 0.0014, conf: 0.1135), s/iter: 0.0473, lr: 3.0e-04
[2024-12-25 21:58:38,629] [INFO] Epoch [22/2695], Step [131/910], Loss: 16.6361 (poly: 0.0080, lower: 0.0000, upper: 0.0000, cls_loss: 0.0000, line_iou: 0.0015, conf: 0.1136), s/iter: 0.0472, lr: 3.0e-04
[2024-12-25 21:58:38,682] [INFO] Epoch [22/2695], Step [132/910], Loss: 16.5110 (poly: 0.0022, lower: 0.0000, upper: 0.0000, cls_loss: 0.0000, line_iou: 0.0013, conf: 0.1135), s/iter: 0.0472, lr: 3.0e-04
[2024-12-25 21:58:38,729] [INFO] Epoch [22/2695], Step [133/910], Loss: 16.3894 (poly: 0.1197, lower: 0.0000, upper: 0.0000, cls_loss: 0.0000, line_iou: 0.0015, conf: 0.2257), s/iter: 0.0472, lr: 3.0e-04
[2024-12-25 21:58:38,779] [INFO] Epoch [22/2695], Step [134/910], Loss: 16.2686 (poly: 0.0024, lower: 0.0000, upper: 0.0000, cls_loss: 0.0000, line_iou: 0.0013, conf: 0.1945), s/iter: 0.0472, lr: 3.0e-04
[2024-12-25 21:58:38,803] [INFO] Weight SoftAdapt Loss tensor([0.4967, 0.0017, 0.0017, 0.0017, 0.0017, 0.4967], dtype=torch.float64)
[2024-12-25 21:58:38,828] [INFO] Epoch [22/2695], Step [135/910], Loss: 16.1513 (poly: 0.0042, lower: 0.0000, upper: 0.0000, cls_loss: 0.0000, line_iou: 0.4296, conf: 0.0004), s/iter: 0.0473, lr: 3.0e-04
[2024-12-25 21:58:38,873] [INFO] Epoch [22/2695], Step [136/910], Loss: 16.0367 (poly: 0.0701, lower: 0.0000, upper: 0.0002, cls_loss: 0.0000, line_iou: 0.4900, conf: 0.0006), s/iter: 0.0473, lr: 3.0e-04
[2024-12-25 21:58:38,921] [INFO] Epoch [22/2695], Step [137/910], Loss: 15.9237 (poly: 0.0668, lower: 0.0000, upper: 0.0002, cls_loss: 0.0000, line_iou: 0.4897, conf: 0.0006), s/iter: 0.0473, lr: 3.0e-04
[2024-12-25 21:58:38,970] [INFO] Epoch [22/2695], Step [138/910], Loss: 15.8110 (poly: 0.0030, lower: 0.0000, upper: 0.0000, cls_loss: 0.0000, line_iou: 0.3697, conf: 0.0004), s/iter: 0.0473, lr: 3.0e-04
[2024-12-25 21:58:39,014] [INFO] Epoch [22/2695], Step [139/910], Loss: 15.7011 (poly: 0.0976, lower: 0.0000, upper: 0.0000, cls_loss: 0.0000, line_iou: 0.4383, conf: 0.0008), s/iter: 0.0474, lr: 3.0e-04
[2024-12-25 21:58:39,061] [INFO] Epoch [22/2695], Step [140/910], Loss: 15.5918 (poly: 0.0027, lower: 0.0000, upper: 0.0000, cls_loss: 0.0000, line_iou: 0.3986, conf: 0.0004), s/iter: 0.0473, lr: 3.0e-04
[2024-12-25 21:58:39,104] [INFO] Epoch [22/2695], Step [141/910], Loss: 15.4851 (poly: 0.0547, lower: 0.0000, upper: 0.0001, cls_loss: 0.0000, line_iou: 0.4905, conf: 0.0004), s/iter: 0.0472, lr: 3.0e-04
[2024-12-25 21:58:39,150] [INFO] Epoch [22/2695], Step [142/910], Loss: 15.3786 (poly: 0.0034, lower: 0.0000, upper: 0.0000, cls_loss: 0.0000, line_iou: 0.3482, conf: 0.0006), s/iter: 0.0471, lr: 3.0e-04
[2024-12-25 21:58:39,204] [INFO] Epoch [22/2695], Step [143/910], Loss: 15.2738 (poly: 0.0024, lower: 0.0000, upper: 0.0000, cls_loss: 0.0000, line_iou: 0.4013, conf: 0.0004), s/iter: 0.0471, lr: 3.0e-04
[2024-12-25 21:58:39,230] [INFO] Weight SoftAdapt Loss tensor([0.4967, 0.0017, 0.0017, 0.0017, 0.4967, 0.0017], dtype=torch.float64)
[2024-12-25 21:58:39,262] [INFO] Epoch [22/2695], Step [144/910], Loss: 15.1715 (poly: 0.0000, lower: 0.0000, upper: 0.0000, cls_loss: 0.0000, line_iou: 0.4244, conf: 0.1134), s/iter: 0.0473, lr: 3.0e-04
[2024-12-25 21:58:39,308] [INFO] Epoch [22/2695], Step [145/910], Loss: 15.0705 (poly: 0.0000, lower: 0.0000, upper: 0.0000, cls_loss: 0.0000, line_iou: 0.4174, conf: 0.1133), s/iter: 0.0472, lr: 3.0e-04
[2024-12-25 21:58:39,354] [INFO] Epoch [22/2695], Step [146/910], Loss: 14.9708 (poly: 0.0000, lower: 0.0000, upper: 0.0000, cls_loss: 0.0000, line_iou: 0.4020, conf: 0.1133), s/iter: 0.0472, lr: 3.0e-04
[2024-12-25 21:58:39,408] [INFO] Epoch [22/2695], Step [147/910], Loss: 14.8726 (poly: 0.0000, lower: 0.0000, upper: 0.0000, cls_loss: 0.0000, line_iou: 0.4229, conf: 0.1134), s/iter: 0.0472, lr: 3.0e-04
[2024-12-25 21:58:39,456] [INFO] Epoch [22/2695], Step [148/910], Loss: 14.7763 (poly: 0.0002, lower: 0.0000, upper: 0.0001, cls_loss: 0.0000, line_iou: 0.4933, conf: 0.1133), s/iter: 0.0473, lr: 3.0e-04
[2024-12-25 21:58:39,504] [INFO] Epoch [22/2695], Step [149/910], Loss: 14.6807 (poly: 0.0000, lower: 0.0000, upper: 0.0000, cls_loss: 0.0000, line_iou: 0.4214, conf: 0.1133), s/iter: 0.0473, lr: 3.0e-04
[2024-12-25 21:58:39,558] [INFO] Epoch [22/2695], Step [150/910], Loss: 14.5874 (poly: 0.0002, lower: 0.0000, upper: 0.0002, cls_loss: 0.0000, line_iou: 0.4879, conf: 0.1945), s/iter: 0.0473, lr: 3.0e-04
[2024-12-25 21:58:39,606] [INFO] Epoch [22/2695], Step [151/910], Loss: 14.4955 (poly: 0.0004, lower: 0.0000, upper: 0.0001, cls_loss: 0.0000, line_iou: 0.4883, conf: 0.2257), s/iter: 0.0474, lr: 3.0e-04
[2024-12-25 21:58:39,652] [INFO] Epoch [22/2695], Step [152/910], Loss: 14.4049 (poly: 0.0005, lower: 0.0000, upper: 0.0001, cls_loss: 0.0000, line_iou: 0.4964, conf: 0.2257), s/iter: 0.0474, lr: 3.0e-04
[2024-12-25 21:58:39,676] [INFO] Weight SoftAdapt Loss tensor([0.0017, 0.0017, 0.0017, 0.0017, 0.4967, 0.4967], dtype=torch.float64)
[2024-12-25 21:58:39,701] [INFO] Epoch [22/2695], Step [153/910], Loss: 14.3115 (poly: 0.0036, lower: 0.0000, upper: 0.0000, cls_loss: 0.0000, line_iou: 0.0014, conf: 0.1133), s/iter: 0.0474, lr: 3.0e-04
[2024-12-25 21:58:39,749] [INFO] Epoch [22/2695], Step [154/910], Loss: 14.2193 (poly: 0.0048, lower: 0.0000, upper: 0.0000, cls_loss: 0.0000, line_iou: 0.0013, conf: 0.1132), s/iter: 0.0474, lr: 3.0e-04
[2024-12-25 21:58:39,794] [INFO] Epoch [22/2695], Step [155/910], Loss: 14.1293 (poly: 0.0642, lower: 0.0000, upper: 0.0002, cls_loss: 0.0000, line_iou: 0.0017, conf: 0.1945), s/iter: 0.0473, lr: 3.0e-04
[2024-12-25 21:58:39,839] [INFO] Epoch [22/2695], Step [156/910], Loss: 14.0403 (poly: 0.0488, lower: 0.0000, upper: 0.0001, cls_loss: 0.0000, line_iou: 0.0015, conf: 0.1945), s/iter: 0.0472, lr: 3.0e-04
[2024-12-25 21:58:39,883] [INFO] Epoch [22/2695], Step [157/910], Loss: 13.9531 (poly: 0.1299, lower: 0.0000, upper: 0.0003, cls_loss: 0.0000, line_iou: 0.0016, conf: 0.2255), s/iter: 0.0470, lr: 3.0e-04
[2024-12-25 21:58:39,927] [INFO] Epoch [22/2695], Step [158/910], Loss: 13.8656 (poly: 0.0062, lower: 0.0000, upper: 0.0000, cls_loss: 0.0000, line_iou: 0.0013, conf: 0.1132), s/iter: 0.0469, lr: 3.0e-04
[2024-12-25 21:58:39,979] [INFO] Epoch [22/2695], Step [159/910], Loss: 13.7805 (poly: 0.1132, lower: 0.0000, upper: 0.0000, cls_loss: 0.0000, line_iou: 0.0014, conf: 0.2255), s/iter: 0.0470, lr: 3.0e-04
[2024-12-25 21:58:40,036] [INFO] Epoch [22/2695], Step [160/910], Loss: 13.6966 (poly: 0.1298, lower: 0.0000, upper: 0.0003, cls_loss: 0.0000, line_iou: 0.0017, conf: 0.2255), s/iter: 0.0469, lr: 3.0e-04
[2024-12-25 21:58:40,081] [INFO] Epoch [22/2695], Step [161/910], Loss: 13.6123 (poly: 0.0026, lower: 0.0000, upper: 0.0000, cls_loss: 0.0000, line_iou: 0.0014, conf: 0.1132), s/iter: 0.0468, lr: 3.0e-04
[2024-12-25 21:58:40,106] [INFO] Weight SoftAdapt Loss tensor([0.4967, 0.0017, 0.0017, 0.0017, 0.0017, 0.4967], dtype=torch.float64)
[2024-12-25 21:58:40,143] [INFO] Epoch [22/2695], Step [162/910], Loss: 13.5316 (poly: 0.0606, lower: 0.0000, upper: 0.0001, cls_loss: 0.0000, line_iou: 0.4867, conf: 0.0006), s/iter: 0.0470, lr: 3.0e-04
[2024-12-25 21:58:40,200] [INFO] Epoch [22/2695], Step [163/910], Loss: 13.4520 (poly: 0.0853, lower: 0.0000, upper: 0.0001, cls_loss: 0.0000, line_iou: 0.4711, conf: 0.0006), s/iter: 0.0470, lr: 3.0e-04
[2024-12-25 21:58:40,253] [INFO] Epoch [22/2695], Step [164/910], Loss: 13.3738 (poly: 0.1340, lower: 0.0000, upper: 0.0001, cls_loss: 0.0000, line_iou: 0.4850, conf: 0.0008), s/iter: 0.0471, lr: 3.0e-04
[2024-12-25 21:58:40,308] [INFO] Epoch [22/2695], Step [165/910], Loss: 13.2962 (poly: 0.0830, lower: 0.0000, upper: 0.0002, cls_loss: 0.0000, line_iou: 0.4824, conf: 0.0006), s/iter: 0.0471, lr: 3.0e-04
[2024-12-25 21:58:40,355] [INFO] Epoch [22/2695], Step [166/910], Loss: 13.2194 (poly: 0.0655, lower: 0.0000, upper: 0.0001, cls_loss: 0.0000, line_iou: 0.4890, conf: 0.0006), s/iter: 0.0471, lr: 3.0e-04
[2024-12-25 21:58:40,406] [INFO] Epoch [22/2695], Step [167/910], Loss: 13.1427 (poly: 0.0023, lower: 0.0000, upper: 0.0000, cls_loss: 0.0000, line_iou: 0.3989, conf: 0.0004), s/iter: 0.0471, lr: 3.0e-04
[2024-12-25 21:58:40,453] [INFO] Epoch [22/2695], Step [168/910], Loss: 13.0668 (poly: 0.0041, lower: 0.0000, upper: 0.0000, cls_loss: 0.0000, line_iou: 0.3912, conf: 0.0004), s/iter: 0.0471, lr: 3.0e-04
[2024-12-25 21:58:40,502] [INFO] Epoch [22/2695], Step [169/910], Loss: 12.9930 (poly: 0.1238, lower: 0.0000, upper: 0.0000, cls_loss: 0.0000, line_iou: 0.4797, conf: 0.0008), s/iter: 0.0470, lr: 3.0e-04
[2024-12-25 21:58:40,550] [INFO] Epoch [22/2695], Step [170/910], Loss: 12.9190 (poly: 0.0032, lower: 0.0000, upper: 0.0000, cls_loss: 0.0000, line_iou: 0.4085, conf: 0.0006), s/iter: 0.0470, lr: 3.0e-04
[2024-12-25 21:58:40,576] [INFO] Weight SoftAdapt Loss tensor([0.4967, 0.0017, 0.0017, 0.0017, 0.4967, 0.0017], dtype=torch.float64)
[2024-12-25 21:58:40,600] [INFO] Epoch [22/2695], Step [171/910], Loss: 12.8470 (poly: 0.0000, lower: 0.0000, upper: 0.0000, cls_loss: 0.0000, line_iou: 0.4097, conf: 0.1945), s/iter: 0.0469, lr: 3.0e-04
[2024-12-25 21:58:40,645] [INFO] Epoch [22/2695], Step [172/910], Loss: 12.7761 (poly: 0.0001, lower: 0.0000, upper: 0.0001, cls_loss: 0.0000, line_iou: 0.4585, conf: 0.1946), s/iter: 0.0469, lr: 3.0e-04
[2024-12-25 21:58:40,698] [INFO] Epoch [22/2695], Step [173/910], Loss: 12.7056 (poly: 0.0001, lower: 0.0000, upper: 0.0001, cls_loss: 0.0000, line_iou: 0.4663, conf: 0.1131), s/iter: 0.0469, lr: 3.0e-04
[2024-12-25 21:58:40,756] [INFO] Epoch [22/2695], Step [174/910], Loss: 12.6368 (poly: 0.0004, lower: 0.0000, upper: 0.0003, cls_loss: 0.0000, line_iou: 0.4955, conf: 0.2254), s/iter: 0.0469, lr: 3.0e-04
[2024-12-25 21:58:40,800] [INFO] Epoch [22/2695], Step [175/910], Loss: 12.5678 (poly: 0.0000, lower: 0.0000, upper: 0.0001, cls_loss: 0.0000, line_iou: 0.4617, conf: 0.1131), s/iter: 0.0469, lr: 3.0e-04
[2024-12-25 21:58:40,846] [INFO] Epoch [22/2695], Step [176/910], Loss: 12.4998 (poly: 0.0001, lower: 0.0000, upper: 0.0001, cls_loss: 0.0000, line_iou: 0.4728, conf: 0.1131), s/iter: 0.0468, lr: 3.0e-04
[2024-12-25 21:58:40,891] [INFO] Epoch [22/2695], Step [177/910], Loss: 12.4321 (poly: 0.0000, lower: 0.0000, upper: 0.0000, cls_loss: 0.0000, line_iou: 0.4124, conf: 0.1130), s/iter: 0.0468, lr: 3.0e-04
[2024-12-25 21:58:40,936] [INFO] Epoch [22/2695], Step [178/910], Loss: 12.3652 (poly: 0.0000, lower: 0.0000, upper: 0.0000, cls_loss: 0.0000, line_iou: 0.4108, conf: 0.1130), s/iter: 0.0467, lr: 3.0e-04
[2024-12-25 21:58:40,982] [INFO] Epoch [22/2695], Step [179/910], Loss: 12.2998 (poly: 0.0004, lower: 0.0000, upper: 0.0000, cls_loss: 0.0000, line_iou: 0.4315, conf: 0.2254), s/iter: 0.0468, lr: 3.0e-04
[2024-12-25 21:58:41,004] [INFO] Weight SoftAdapt Loss tensor([0.0017, 0.0017, 0.0017, 0.0017, 0.4967, 0.4967], dtype=torch.float64)
[2024-12-25 21:58:41,030] [INFO] Epoch [22/2695], Step [180/910], Loss: 12.2326 (poly: 0.0028, lower: 0.0000, upper: 0.0000, cls_loss: 0.0000, line_iou: 0.0013, conf: 0.1945), s/iter: 0.0467, lr: 3.0e-04
[2024-12-25 21:58:41,086] [INFO] Epoch [22/2695], Step [181/910], Loss: 12.1657 (poly: 0.0093, lower: 0.0000, upper: 0.0000, cls_loss: 0.0000, line_iou: 0.0014, conf: 0.1131), s/iter: 0.0468, lr: 3.0e-04
[2024-12-25 21:58:41,138] [INFO] Epoch [22/2695], Step [182/910], Loss: 12.1002 (poly: 0.0565, lower: 0.0000, upper: 0.0002, cls_loss: 0.0000, line_iou: 0.0016, conf: 0.1945), s/iter: 0.0468, lr: 3.0e-04
[2024-12-25 21:58:41,188] [INFO] Epoch [22/2695], Step [183/910], Loss: 12.0348 (poly: 0.0061, lower: 0.0000, upper: 0.0000, cls_loss: 0.0000, line_iou: 0.0014, conf: 0.1130), s/iter: 0.0469, lr: 3.0e-04
[2024-12-25 21:58:41,236] [INFO] Epoch [22/2695], Step [184/910], Loss: 11.9706 (poly: 0.0333, lower: 0.0000, upper: 0.0002, cls_loss: 0.0000, line_iou: 0.0015, conf: 0.1944), s/iter: 0.0469, lr: 3.0e-04
[2024-12-25 21:58:41,282] [INFO] Epoch [22/2695], Step [185/910], Loss: 11.9065 (poly: 0.0060, lower: 0.0000, upper: 0.0000, cls_loss: 0.0000, line_iou: 0.0015, conf: 0.1130), s/iter: 0.0467, lr: 3.0e-04
[2024-12-25 21:58:41,326] [INFO] Epoch [22/2695], Step [186/910], Loss: 11.8432 (poly: 0.0076, lower: 0.0000, upper: 0.0000, cls_loss: 0.0000, line_iou: 0.0015, conf: 0.1130), s/iter: 0.0467, lr: 3.0e-04
[2024-12-25 21:58:41,372] [INFO] Epoch [22/2695], Step [187/910], Loss: 11.7805 (poly: 0.0147, lower: 0.0000, upper: 0.0001, cls_loss: 0.0000, line_iou: 0.0015, conf: 0.1130), s/iter: 0.0466, lr: 3.0e-04
[2024-12-25 21:58:41,425] [INFO] Epoch [22/2695], Step [188/910], Loss: 11.7198 (poly: 0.1415, lower: 0.0000, upper: 0.0001, cls_loss: 0.0000, line_iou: 0.0016, conf: 0.2253), s/iter: 0.0467, lr: 3.0e-04
[2024-12-25 21:58:41,449] [INFO] Weight SoftAdapt Loss tensor([0.4967, 0.0017, 0.0017, 0.0017, 0.0017, 0.4967], dtype=torch.float64)
[2024-12-25 21:58:41,481] [INFO] Epoch [22/2695], Step [189/910], Loss: 11.6603 (poly: 0.0096, lower: 0.0000, upper: 0.0000, cls_loss: 0.0000, line_iou: 0.4547, conf: 0.0004), s/iter: 0.0468, lr: 3.0e-04
[2024-12-25 21:58:41,530] [INFO] Epoch [22/2695], Step [190/910], Loss: 11.6014 (poly: 0.0125, lower: 0.0000, upper: 0.0001, cls_loss: 0.0000, line_iou: 0.4617, conf: 0.0004), s/iter: 0.0468, lr: 3.0e-04
[2024-12-25 21:58:41,578] [INFO] Epoch [22/2695], Step [191/910], Loss: 11.5430 (poly: 0.0060, lower: 0.0000, upper: 0.0000, cls_loss: 0.0000, line_iou: 0.4330, conf: 0.0006), s/iter: 0.0468, lr: 3.0e-04
[2024-12-25 21:58:41,666] [INFO] Epoch [22/2695], Step [192/910], Loss: 11.4858 (poly: 0.1259, lower: 0.0000, upper: 0.0000, cls_loss: 0.0000, line_iou: 0.4473, conf: 0.0008), s/iter: 0.0472, lr: 3.0e-04
[2024-12-25 21:58:41,794] [INFO] Epoch [22/2695], Step [193/910], Loss: 11.4285 (poly: 0.0031, lower: 0.0000, upper: 0.0000, cls_loss: 0.0000, line_iou: 0.4217, conf: 0.0004), s/iter: 0.0480, lr: 3.0e-04
[2024-12-25 21:58:41,903] [INFO] Epoch [22/2695], Step [194/910], Loss: 11.3725 (poly: 0.0743, lower: 0.0000, upper: 0.0002, cls_loss: 0.0000, line_iou: 0.4851, conf: 0.0006), s/iter: 0.0486, lr: 3.0e-04
[2024-12-25 21:58:41,997] [INFO] Epoch [22/2695], Step [195/910], Loss: 11.3165 (poly: 0.0042, lower: 0.0000, upper: 0.0000, cls_loss: 0.0000, line_iou: 0.4378, conf: 0.0004), s/iter: 0.0490, lr: 3.0e-04
[2024-12-25 21:58:42,112] [INFO] Epoch [22/2695], Step [196/910], Loss: 11.2611 (poly: 0.0244, lower: 0.0000, upper: 0.0001, cls_loss: 0.0000, line_iou: 0.4379, conf: 0.0006), s/iter: 0.0495, lr: 3.0e-04
[2024-12-25 21:58:42,212] [INFO] Epoch [22/2695], Step [197/910], Loss: 11.2062 (poly: 0.0043, lower: 0.0000, upper: 0.0000, cls_loss: 0.0000, line_iou: 0.4454, conf: 0.0004), s/iter: 0.0501, lr: 3.0e-04
[2024-12-25 21:58:42,271] [INFO] Weight SoftAdapt Loss tensor([0.4967, 0.0017, 0.0017, 0.0017, 0.4967, 0.0017], dtype=torch.float64)
[2024-12-25 21:58:42,329] [INFO] Epoch [22/2695], Step [198/910], Loss: 11.1531 (poly: 0.0003, lower: 0.0000, upper: 0.0002, cls_loss: 0.0000, line_iou: 0.4915, conf: 0.1944), s/iter: 0.0508, lr: 3.0e-04
[2024-12-25 21:58:42,442] [INFO] Epoch [22/2695], Step [199/910], Loss: 11.1004 (poly: 0.0004, lower: 0.0000, upper: 0.0000, cls_loss: 0.0000, line_iou: 0.4521, conf: 0.2252), s/iter: 0.0514, lr: 3.0e-04
[2024-12-25 21:58:42,540] [INFO] Epoch [22/2695], Step [200/910], Loss: 11.0477 (poly: 0.0000, lower: 0.0000, upper: 0.0000, cls_loss: 0.0000, line_iou: 0.4318, conf: 0.1129), s/iter: 0.0519, lr: 3.0e-04
[2024-12-25 21:58:42,647] [INFO] Epoch [22/2695], Step [201/910], Loss: 10.9953 (poly: 0.0000, lower: 0.0000, upper: 0.0000, cls_loss: 0.0000, line_iou: 0.4203, conf: 0.1128), s/iter: 0.0524, lr: 3.0e-04
[2024-12-25 21:58:42,749] [INFO] Epoch [22/2695], Step [202/910], Loss: 10.9438 (poly: 0.0000, lower: 0.0000, upper: 0.0000, cls_loss: 0.0000, line_iou: 0.4621, conf: 0.1128), s/iter: 0.0529, lr: 3.0e-04
[2024-12-25 21:58:42,850] [INFO] Epoch [22/2695], Step [203/910], Loss: 10.8932 (poly: 0.0004, lower: 0.0000, upper: 0.0001, cls_loss: 0.0000, line_iou: 0.4627, conf: 0.2253), s/iter: 0.0534, lr: 3.0e-04
[2024-12-25 21:58:42,965] [INFO] Epoch [22/2695], Step [204/910], Loss: 10.8427 (poly: 0.0000, lower: 0.0000, upper: 0.0000, cls_loss: 0.0000, line_iou: 0.3924, conf: 0.1944), s/iter: 0.0541, lr: 3.0e-04
[2024-12-25 21:58:43,082] [INFO] Epoch [22/2695], Step [205/910], Loss: 10.7924 (poly: 0.0000, lower: 0.0000, upper: 0.0000, cls_loss: 0.0000, line_iou: 0.4151, conf: 0.1128), s/iter: 0.0548, lr: 3.0e-04
[2024-12-25 21:58:43,182] [INFO] Epoch [22/2695], Step [206/910], Loss: 10.7435 (poly: 0.0004, lower: 0.0000, upper: 0.0001, cls_loss: 0.0000, line_iou: 0.4846, conf: 0.2253), s/iter: 0.0552, lr: 3.0e-04
[2024-12-25 21:58:43,245] [INFO] Weight SoftAdapt Loss tensor([0.0017, 0.0017, 0.0017, 0.0017, 0.4967, 0.4967], dtype=torch.float64)
[2024-12-25 21:58:43,308] [INFO] Epoch [22/2695], Step [207/910], Loss: 10.6921 (poly: 0.0046, lower: 0.0000, upper: 0.0000, cls_loss: 0.0000, line_iou: 0.0014, conf: 0.1128), s/iter: 0.0560, lr: 3.0e-04
[2024-12-25 21:58:43,426] [INFO] Epoch [22/2695], Step [208/910], Loss: 10.6413 (poly: 0.0061, lower: 0.0000, upper: 0.0000, cls_loss: 0.0000, line_iou: 0.0015, conf: 0.1128), s/iter: 0.0567, lr: 3.0e-04
[2024-12-25 21:58:43,541] [INFO] Epoch [22/2695], Step [209/910], Loss: 10.5910 (poly: 0.0060, lower: 0.0000, upper: 0.0000, cls_loss: 0.0000, line_iou: 0.0015, conf: 0.1128), s/iter: 0.0573, lr: 3.0e-04
[2024-12-25 21:58:43,654] [INFO] Epoch [22/2695], Step [210/910], Loss: 10.5421 (poly: 0.1009, lower: 0.0000, upper: 0.0000, cls_loss: 0.0000, line_iou: 0.0015, conf: 0.2252), s/iter: 0.0579, lr: 3.0e-04
[2024-12-25 21:58:43,745] [INFO] Epoch [22/2695], Step [211/910], Loss: 10.4927 (poly: 0.0035, lower: 0.0000, upper: 0.0000, cls_loss: 0.0000, line_iou: 0.0014, conf: 0.1128), s/iter: 0.0582, lr: 3.0e-04
[2024-12-25 21:58:43,855] [INFO] Epoch [22/2695], Step [212/910], Loss: 10.4442 (poly: 0.0075, lower: 0.0000, upper: 0.0000, cls_loss: 0.0000, line_iou: 0.0015, conf: 0.1945), s/iter: 0.0588, lr: 3.0e-04
[2024-12-25 21:58:43,977] [INFO] Epoch [22/2695], Step [213/910], Loss: 10.3957 (poly: 0.0046, lower: 0.0000, upper: 0.0000, cls_loss: 0.0000, line_iou: 0.0014, conf: 0.1128), s/iter: 0.0594, lr: 3.0e-04
[2024-12-25 21:58:44,082] [INFO] Epoch [22/2695], Step [214/910], Loss: 10.3477 (poly: 0.0057, lower: 0.0000, upper: 0.0000, cls_loss: 0.0000, line_iou: 0.0015, conf: 0.1128), s/iter: 0.0600, lr: 3.0e-04
[2024-12-25 21:58:44,184] [INFO] Epoch [22/2695], Step [215/910], Loss: 10.3008 (poly: 0.0784, lower: 0.0000, upper: 0.0002, cls_loss: 0.0000, line_iou: 0.0016, conf: 0.1944), s/iter: 0.0605, lr: 3.0e-04
[2024-12-25 21:58:44,251] [INFO] Weight SoftAdapt Loss tensor([0.4967, 0.0017, 0.0017, 0.0017, 0.0017, 0.4967], dtype=torch.float64)
[2024-12-25 21:58:44,310] [INFO] Epoch [22/2695], Step [216/910], Loss: 10.2558 (poly: 0.0979, lower: 0.0000, upper: 0.0000, cls_loss: 0.0000, line_iou: 0.4759, conf: 0.0008), s/iter: 0.0612, lr: 3.0e-04
[2024-12-25 21:58:44,432] [INFO] Epoch [22/2695], Step [217/910], Loss: 10.2108 (poly: 0.0128, lower: 0.0000, upper: 0.0000, cls_loss: 0.0000, line_iou: 0.4888, conf: 0.0004), s/iter: 0.0619, lr: 3.0e-04
[2024-12-25 21:58:44,543] [INFO] Epoch [22/2695], Step [218/910], Loss: 10.1661 (poly: 0.0081, lower: 0.0000, upper: 0.0000, cls_loss: 0.0000, line_iou: 0.4564, conf: 0.0006), s/iter: 0.0624, lr: 3.0e-04
[2024-12-25 21:58:44,677] [INFO] Epoch [22/2695], Step [219/910], Loss: 10.1222 (poly: 0.1020, lower: 0.0000, upper: 0.0001, cls_loss: 0.0000, line_iou: 0.4359, conf: 0.0008), s/iter: 0.0632, lr: 3.0e-04
[2024-12-25 21:58:44,791] [INFO] Epoch [22/2695], Step [220/910], Loss: 10.0791 (poly: 0.1410, lower: 0.0000, upper: 0.0002, cls_loss: 0.0000, line_iou: 0.4963, conf: 0.0008), s/iter: 0.0638, lr: 3.0e-04
[2024-12-25 21:58:44,922] [INFO] Epoch [22/2695], Step [221/910], Loss: 10.0354 (poly: 0.0052, lower: 0.0000, upper: 0.0000, cls_loss: 0.0000, line_iou: 0.4323, conf: 0.0004), s/iter: 0.0647, lr: 3.0e-04
[2024-12-25 21:58:45,041] [INFO] Epoch [22/2695], Step [222/910], Loss: 9.9923 (poly: 0.0065, lower: 0.0000, upper: 0.0000, cls_loss: 0.0000, line_iou: 0.4441, conf: 0.0004), s/iter: 0.0653, lr: 3.0e-04
[2024-12-25 21:58:45,164] [INFO] Epoch [22/2695], Step [223/910], Loss: 9.9503 (poly: 0.1427, lower: 0.0000, upper: 0.0002, cls_loss: 0.0000, line_iou: 0.4965, conf: 0.0008), s/iter: 0.0661, lr: 3.0e-04
[2024-12-25 21:58:45,281] [INFO] Epoch [22/2695], Step [224/910], Loss: 9.9079 (poly: 0.0057, lower: 0.0000, upper: 0.0000, cls_loss: 0.0000, line_iou: 0.4452, conf: 0.0004), s/iter: 0.0668, lr: 3.0e-04
[2024-12-25 21:58:45,342] [INFO] Weight SoftAdapt Loss tensor([0.4967, 0.0017, 0.0017, 0.0017, 0.4967, 0.0017], dtype=torch.float64)
[2024-12-25 21:58:45,395] [INFO] Epoch [22/2695], Step [225/910], Loss: 9.8664 (poly: 0.0000, lower: 0.0000, upper: 0.0000, cls_loss: 0.0000, line_iou: 0.4492, conf: 0.1126), s/iter: 0.0673, lr: 3.0e-04
[2024-12-25 21:58:45,515] [INFO] Epoch [22/2695], Step [226/910], Loss: 9.8252 (poly: 0.0000, lower: 0.0000, upper: 0.0000, cls_loss: 0.0000, line_iou: 0.4384, conf: 0.1126), s/iter: 0.0680, lr: 3.0e-04
[2024-12-25 21:58:45,618] [INFO] Epoch [22/2695], Step [227/910], Loss: 9.7844 (poly: 0.0000, lower: 0.0000, upper: 0.0000, cls_loss: 0.0000, line_iou: 0.4476, conf: 0.1126), s/iter: 0.0684, lr: 3.0e-04
[2024-12-25 21:58:45,704] [INFO] Epoch [22/2695], Step [228/910], Loss: 9.7444 (poly: 0.0004, lower: 0.0000, upper: 0.0001, cls_loss: 0.0000, line_iou: 0.4499, conf: 0.2250), s/iter: 0.0688, lr: 3.0e-04
[2024-12-25 21:58:45,801] [INFO] Epoch [22/2695], Step [229/910], Loss: 9.7042 (poly: 0.0000, lower: 0.0000, upper: 0.0000, cls_loss: 0.0000, line_iou: 0.4218, conf: 0.1126), s/iter: 0.0692, lr: 3.0e-04
[2024-12-25 21:58:45,888] [INFO] Epoch [22/2695], Step [230/910], Loss: 9.6645 (poly: 0.0000, lower: 0.0000, upper: 0.0000, cls_loss: 0.0000, line_iou: 0.4586, conf: 0.1126), s/iter: 0.0696, lr: 3.0e-04
[2024-12-25 21:58:45,982] [INFO] Epoch [22/2695], Step [231/910], Loss: 9.6249 (poly: 0.0000, lower: 0.0000, upper: 0.0000, cls_loss: 0.0000, line_iou: 0.4145, conf: 0.1126), s/iter: 0.0701, lr: 3.0e-04
[2024-12-25 21:58:46,086] [INFO] Epoch [22/2695], Step [232/910], Loss: 9.5858 (poly: 0.0000, lower: 0.0000, upper: 0.0000, cls_loss: 0.0000, line_iou: 0.4469, conf: 0.1125), s/iter: 0.0705, lr: 3.0e-04
[2024-12-25 21:58:46,187] [INFO] Epoch [22/2695], Step [233/910], Loss: 9.5469 (poly: 0.0000, lower: 0.0000, upper: 0.0000, cls_loss: 0.0000, line_iou: 0.4090, conf: 0.1125), s/iter: 0.0711, lr: 3.0e-04
[2024-12-25 21:58:46,231] [INFO] Weight SoftAdapt Loss tensor([0.0017, 0.0017, 0.0017, 0.0017, 0.4967, 0.4967], dtype=torch.float64)
[2024-12-25 21:58:46,279] [INFO] Epoch [22/2695], Step [234/910], Loss: 9.5075 (poly: 0.1000, lower: 0.0000, upper: 0.0000, cls_loss: 0.0000, line_iou: 0.0015, conf: 0.2250), s/iter: 0.0715, lr: 3.0e-04
[2024-12-25 21:58:46,389] [INFO] Epoch [22/2695], Step [235/910], Loss: 9.4684 (poly: 0.0943, lower: 0.0000, upper: 0.0000, cls_loss: 0.0000, line_iou: 0.0015, conf: 0.2249), s/iter: 0.0721, lr: 3.0e-04
[2024-12-25 21:58:46,499] [INFO] Epoch [22/2695], Step [236/910], Loss: 9.4289 (poly: 0.0125, lower: 0.0000, upper: 0.0001, cls_loss: 0.0000, line_iou: 0.0014, conf: 0.1125), s/iter: 0.0727, lr: 3.0e-04
[2024-12-25 21:58:46,618] [INFO] Epoch [22/2695], Step [237/910], Loss: 9.3906 (poly: 0.1280, lower: 0.0000, upper: 0.0001, cls_loss: 0.0000, line_iou: 0.0016, conf: 0.2249), s/iter: 0.0734, lr: 3.0e-04
[2024-12-25 21:58:46,736] [INFO] Epoch [22/2695], Step [238/910], Loss: 9.3521 (poly: 0.0459, lower: 0.0000, upper: 0.0001, cls_loss: 0.0000, line_iou: 0.0015, conf: 0.1944), s/iter: 0.0740, lr: 3.0e-04
[2024-12-25 21:58:46,836] [INFO] Epoch [22/2695], Step [239/910], Loss: 9.3135 (poly: 0.0056, lower: 0.0000, upper: 0.0000, cls_loss: 0.0000, line_iou: 0.0015, conf: 0.1124), s/iter: 0.0745, lr: 3.0e-04
[2024-12-25 21:58:46,937] [INFO] Epoch [22/2695], Step [240/910], Loss: 9.2752 (poly: 0.0033, lower: 0.0000, upper: 0.0000, cls_loss: 0.0000, line_iou: 0.0014, conf: 0.1125), s/iter: 0.0751, lr: 3.0e-04
[2024-12-25 21:58:47,038] [INFO] Epoch [22/2695], Step [241/910], Loss: 9.2372 (poly: 0.0052, lower: 0.0000, upper: 0.0000, cls_loss: 0.0000, line_iou: 0.0014, conf: 0.1124), s/iter: 0.0756, lr: 3.0e-04
[2024-12-25 21:58:47,151] [INFO] Epoch [22/2695], Step [242/910], Loss: 9.1997 (poly: 0.0568, lower: 0.0000, upper: 0.0001, cls_loss: 0.0000, line_iou: 0.0017, conf: 0.1124), s/iter: 0.0763, lr: 3.0e-04
[2024-12-25 21:58:47,208] [INFO] Weight SoftAdapt Loss tensor([0.4967, 0.0017, 0.0017, 0.0017, 0.0017, 0.4967], dtype=torch.float64)
[2024-12-25 21:58:47,272] [INFO] Epoch [22/2695], Step [243/910], Loss: 9.1635 (poly: 0.0025, lower: 0.0000, upper: 0.0000, cls_loss: 0.0000, line_iou: 0.4016, conf: 0.0004), s/iter: 0.0769, lr: 3.0e-04
[2024-12-25 21:58:47,366] [INFO] Epoch [22/2695], Step [244/910], Loss: 9.1278 (poly: 0.0031, lower: 0.0000, upper: 0.0000, cls_loss: 0.0000, line_iou: 0.4308, conf: 0.0004), s/iter: 0.0773, lr: 3.0e-04
[2024-12-25 21:58:47,473] [INFO] Epoch [22/2695], Step [245/910], Loss: 9.0930 (poly: 0.1278, lower: 0.0000, upper: 0.0001, cls_loss: 0.0000, line_iou: 0.4804, conf: 0.0007), s/iter: 0.0779, lr: 3.0e-04
[2024-12-25 21:58:47,582] [INFO] Epoch [22/2695], Step [246/910], Loss: 9.0585 (poly: 0.1227, lower: 0.0000, upper: 0.0003, cls_loss: 0.0000, line_iou: 0.4867, conf: 0.0007), s/iter: 0.0785, lr: 3.0e-04
[2024-12-25 21:58:47,710] [INFO] Epoch [22/2695], Step [247/910], Loss: 9.0235 (poly: 0.0037, lower: 0.0000, upper: 0.0000, cls_loss: 0.0000, line_iou: 0.3989, conf: 0.0006), s/iter: 0.0792, lr: 3.0e-04
[2024-12-25 21:58:47,844] [INFO] Epoch [22/2695], Step [248/910], Loss: 8.9889 (poly: 0.0046, lower: 0.0000, upper: 0.0000, cls_loss: 0.0000, line_iou: 0.4497, conf: 0.0004), s/iter: 0.0800, lr: 3.0e-04
[2024-12-25 21:58:47,965] [INFO] Epoch [22/2695], Step [249/910], Loss: 8.9549 (poly: 0.0949, lower: 0.0000, upper: 0.0000, cls_loss: 0.0000, line_iou: 0.4116, conf: 0.0007), s/iter: 0.0807, lr: 3.0e-04
[2024-12-25 21:58:48,072] [INFO] Epoch [22/2695], Step [250/910], Loss: 8.9206 (poly: 0.0036, lower: 0.0000, upper: 0.0000, cls_loss: 0.0000, line_iou: 0.3937, conf: 0.0004), s/iter: 0.0812, lr: 3.0e-04
[2024-12-25 21:58:48,191] [INFO] Epoch [22/2695], Step [251/910], Loss: 8.8875 (poly: 0.1285, lower: 0.0000, upper: 0.0001, cls_loss: 0.0000, line_iou: 0.4869, conf: 0.0007), s/iter: 0.0819, lr: 3.0e-04
[2024-12-25 21:58:48,248] [INFO] Weight SoftAdapt Loss tensor([0.4967, 0.0017, 0.0017, 0.0017, 0.4967, 0.0017], dtype=torch.float64)
[2024-12-25 21:58:48,312] [INFO] Epoch [22/2695], Step [252/910], Loss: 8.8551 (poly: 0.0004, lower: 0.0000, upper: 0.0001, cls_loss: 0.0000, line_iou: 0.4876, conf: 0.2248), s/iter: 0.0826, lr: 3.0e-04
[2024-12-25 21:58:48,415] [INFO] Epoch [22/2695], Step [253/910], Loss: 8.8220 (poly: 0.0000, lower: 0.0000, upper: 0.0000, cls_loss: 0.0000, line_iou: 0.3744, conf: 0.1123), s/iter: 0.0831, lr: 3.0e-04
[2024-12-25 21:58:48,513] [INFO] Epoch [22/2695], Step [254/910], Loss: 8.7894 (poly: 0.0000, lower: 0.0000, upper: 0.0000, cls_loss: 0.0000, line_iou: 0.4282, conf: 0.1123), s/iter: 0.0836, lr: 3.0e-04
[2024-12-25 21:58:48,611] [INFO] Epoch [22/2695], Step [255/910], Loss: 8.7570 (poly: 0.0000, lower: 0.0000, upper: 0.0000, cls_loss: 0.0000, line_iou: 0.4012, conf: 0.1122), s/iter: 0.0841, lr: 3.0e-04
[2024-12-25 21:58:48,715] [INFO] Epoch [22/2695], Step [256/910], Loss: 8.7248 (poly: 0.0000, lower: 0.0000, upper: 0.0000, cls_loss: 0.0000, line_iou: 0.4220, conf: 0.1123), s/iter: 0.0847, lr: 3.0e-04
[2024-12-25 21:58:48,800] [INFO] Epoch [22/2695], Step [257/910], Loss: 8.6931 (poly: 0.0000, lower: 0.0000, upper: 0.0000, cls_loss: 0.0000, line_iou: 0.3793, conf: 0.1946), s/iter: 0.0851, lr: 3.0e-04
[2024-12-25 21:58:48,909] [INFO] Epoch [22/2695], Step [258/910], Loss: 8.6621 (poly: 0.0003, lower: 0.0000, upper: 0.0000, cls_loss: 0.0000, line_iou: 0.4516, conf: 0.2247), s/iter: 0.0858, lr: 3.0e-04
[2024-12-25 21:58:49,020] [INFO] Epoch [22/2695], Step [259/910], Loss: 8.6306 (poly: 0.0000, lower: 0.0000, upper: 0.0000, cls_loss: 0.0000, line_iou: 0.4106, conf: 0.1122), s/iter: 0.0863, lr: 3.0e-04
[2024-12-25 21:58:49,143] [INFO] Epoch [22/2695], Step [260/910], Loss: 8.5995 (poly: 0.0000, lower: 0.0000, upper: 0.0000, cls_loss: 0.0000, line_iou: 0.4293, conf: 0.1122), s/iter: 0.0870, lr: 3.0e-04
[2024-12-25 21:58:49,208] [INFO] Weight SoftAdapt Loss tensor([0.0017, 0.0017, 0.0017, 0.0017, 0.4967, 0.4967], dtype=torch.float64)
[2024-12-25 21:58:49,274] [INFO] Epoch [22/2695], Step [261/910], Loss: 8.5670 (poly: 0.0030, lower: 0.0000, upper: 0.0000, cls_loss: 0.0000, line_iou: 0.0014, conf: 0.1122), s/iter: 0.0878, lr: 3.0e-04
[2024-12-25 21:58:49,387] [INFO] Epoch [22/2695], Step [262/910], Loss: 8.5356 (poly: 0.1133, lower: 0.0000, upper: 0.0003, cls_loss: 0.0000, line_iou: 0.0016, conf: 0.2247), s/iter: 0.0883, lr: 3.0e-04
[2024-12-25 21:58:49,483] [INFO] Epoch [22/2695], Step [263/910], Loss: 8.5045 (poly: 0.1320, lower: 0.0000, upper: 0.0001, cls_loss: 0.0000, line_iou: 0.0016, conf: 0.2247), s/iter: 0.0887, lr: 3.0e-04
[2024-12-25 21:58:49,602] [INFO] Epoch [22/2695], Step [264/910], Loss: 8.4729 (poly: 0.0530, lower: 0.0000, upper: 0.0001, cls_loss: 0.0000, line_iou: 0.0016, conf: 0.1122), s/iter: 0.0893, lr: 3.0e-04
[2024-12-25 21:58:49,711] [INFO] Epoch [22/2695], Step [265/910], Loss: 8.4414 (poly: 0.0045, lower: 0.0000, upper: 0.0000, cls_loss: 0.0000, line_iou: 0.0014, conf: 0.1122), s/iter: 0.0898, lr: 3.0e-04
[2024-12-25 21:58:49,810] [INFO] Epoch [22/2695], Step [266/910], Loss: 8.4105 (poly: 0.0291, lower: 0.0000, upper: 0.0001, cls_loss: 0.0000, line_iou: 0.0015, conf: 0.1946), s/iter: 0.0903, lr: 3.0e-04
[2024-12-25 21:58:49,922] [INFO] Epoch [22/2695], Step [267/910], Loss: 8.3795 (poly: 0.0063, lower: 0.0000, upper: 0.0000, cls_loss: 0.0000, line_iou: 0.0014, conf: 0.1122), s/iter: 0.0909, lr: 3.0e-04
[2024-12-25 21:58:50,048] [INFO] Epoch [22/2695], Step [268/910], Loss: 8.3496 (poly: 0.1374, lower: 0.0000, upper: 0.0001, cls_loss: 0.0000, line_iou: 0.0016, conf: 0.2246), s/iter: 0.0916, lr: 3.0e-04
[2024-12-25 21:58:50,179] [INFO] Epoch [22/2695], Step [269/910], Loss: 8.3200 (poly: 0.1682, lower: 0.0000, upper: 0.0001, cls_loss: 0.0000, line_iou: 0.0016, conf: 0.2246), s/iter: 0.0924, lr: 3.0e-04
[2024-12-25 21:58:50,248] [INFO] Weight SoftAdapt Loss tensor([0.4967, 0.0017, 0.0017, 0.0017, 0.0017, 0.4967], dtype=torch.float64)
[2024-12-25 21:58:50,304] [INFO] Epoch [22/2695], Step [270/910], Loss: 8.2911 (poly: 0.1032, lower: 0.0000, upper: 0.0000, cls_loss: 0.0000, line_iou: 0.4223, conf: 0.0007), s/iter: 0.0932, lr: 3.0e-04
[2024-12-25 21:58:50,404] [INFO] Epoch [22/2695], Step [271/910], Loss: 8.2628 (poly: 0.1244, lower: 0.0000, upper: 0.0001, cls_loss: 0.0000, line_iou: 0.4923, conf: 0.0006), s/iter: 0.0936, lr: 3.0e-04
[2024-12-25 21:58:50,499] [INFO] Epoch [22/2695], Step [272/910], Loss: 8.2344 (poly: 0.1105, lower: 0.0000, upper: 0.0000, cls_loss: 0.0000, line_iou: 0.4313, conf: 0.0007), s/iter: 0.0941, lr: 3.0e-04
[2024-12-25 21:58:50,592] [INFO] Epoch [22/2695], Step [273/910], Loss: 8.2063 (poly: 0.0977, lower: 0.0000, upper: 0.0000, cls_loss: 0.0000, line_iou: 0.4644, conf: 0.0007), s/iter: 0.0945, lr: 3.0e-04
[2024-12-25 21:58:50,714] [INFO] Epoch [22/2695], Step [274/910], Loss: 8.1779 (poly: 0.0035, lower: 0.0000, upper: 0.0000, cls_loss: 0.0000, line_iou: 0.4001, conf: 0.0004), s/iter: 0.0951, lr: 3.0e-04
[2024-12-25 21:58:50,812] [INFO] Epoch [22/2695], Step [275/910], Loss: 8.1501 (poly: 0.0996, lower: 0.0000, upper: 0.0000, cls_loss: 0.0000, line_iou: 0.4541, conf: 0.0007), s/iter: 0.0957, lr: 3.0e-04
[2024-12-25 21:58:50,908] [INFO] Epoch [22/2695], Step [276/910], Loss: 8.1224 (poly: 0.0507, lower: 0.0000, upper: 0.0001, cls_loss: 0.0000, line_iou: 0.4573, conf: 0.0006), s/iter: 0.0962, lr: 3.0e-04
[2024-12-25 21:58:50,994] [INFO] Epoch [22/2695], Step [277/910], Loss: 8.0949 (poly: 0.0448, lower: 0.0000, upper: 0.0001, cls_loss: 0.0000, line_iou: 0.4542, conf: 0.0006), s/iter: 0.0966, lr: 3.0e-04
[2024-12-25 21:58:51,092] [INFO] Epoch [22/2695], Step [278/910], Loss: 8.0671 (poly: 0.0045, lower: 0.0000, upper: 0.0000, cls_loss: 0.0000, line_iou: 0.3585, conf: 0.0006), s/iter: 0.0971, lr: 3.0e-04
[2024-12-25 21:58:51,158] [INFO] Weight SoftAdapt Loss tensor([0.4967, 0.0017, 0.0017, 0.0017, 0.4967, 0.0017], dtype=torch.float64)
[2024-12-25 21:58:51,210] [INFO] Epoch [22/2695], Step [279/910], Loss: 8.0403 (poly: 0.0000, lower: 0.0000, upper: 0.0000, cls_loss: 0.0000, line_iou: 0.4607, conf: 0.1120), s/iter: 0.0977, lr: 3.0e-04
[2024-12-25 21:58:51,317] [INFO] Epoch [22/2695], Step [280/910], Loss: 8.0134 (poly: 0.0000, lower: 0.0000, upper: 0.0000, cls_loss: 0.0000, line_iou: 0.4184, conf: 0.1120), s/iter: 0.0983, lr: 3.0e-04
[2024-12-25 21:58:51,415] [INFO] Epoch [22/2695], Step [281/910], Loss: 7.9868 (poly: 0.0000, lower: 0.0000, upper: 0.0000, cls_loss: 0.0000, line_iou: 0.4205, conf: 0.1120), s/iter: 0.0987, lr: 3.0e-04
[2024-12-25 21:58:51,527] [INFO] Epoch [22/2695], Step [282/910], Loss: 7.9607 (poly: 0.0000, lower: 0.0000, upper: 0.0000, cls_loss: 0.0000, line_iou: 0.4350, conf: 0.1948), s/iter: 0.0993, lr: 3.0e-04
[2024-12-25 21:58:51,630] [INFO] Epoch [22/2695], Step [283/910], Loss: 7.9348 (poly: 0.0003, lower: 0.0000, upper: 0.0000, cls_loss: 0.0000, line_iou: 0.4100, conf: 0.2243), s/iter: 0.0998, lr: 3.0e-04
[2024-12-25 21:58:51,728] [INFO] Epoch [22/2695], Step [284/910], Loss: 7.9090 (poly: 0.0000, lower: 0.0000, upper: 0.0000, cls_loss: 0.0000, line_iou: 0.3957, conf: 0.1948), s/iter: 0.1003, lr: 3.0e-04
[2024-12-25 21:58:51,825] [INFO] Epoch [22/2695], Step [285/910], Loss: 7.8837 (poly: 0.0004, lower: 0.0000, upper: 0.0001, cls_loss: 0.0000, line_iou: 0.4884, conf: 0.2244), s/iter: 0.1008, lr: 3.0e-04
[2024-12-25 21:58:51,938] [INFO] Epoch [22/2695], Step [286/910], Loss: 7.8580 (poly: 0.0000, lower: 0.0000, upper: 0.0000, cls_loss: 0.0000, line_iou: 0.4121, conf: 0.1119), s/iter: 0.1014, lr: 3.0e-04
[2024-12-25 21:58:52,036] [INFO] Epoch [22/2695], Step [287/910], Loss: 7.8328 (poly: 0.0000, lower: 0.0000, upper: 0.0000, cls_loss: 0.0000, line_iou: 0.4210, conf: 0.1947), s/iter: 0.1020, lr: 3.0e-04
[2024-12-25 21:58:52,090] [INFO] Weight SoftAdapt Loss tensor([0.0017, 0.0017, 0.0017, 0.0017, 0.4967, 0.4967], dtype=torch.float64)
[2024-12-25 21:58:52,142] [INFO] Epoch [22/2695], Step [288/910], Loss: 7.8060 (poly: 0.0032, lower: 0.0000, upper: 0.0000, cls_loss: 0.0000, line_iou: 0.0014, conf: 0.1119), s/iter: 0.1025, lr: 3.0e-04
[2024-12-25 21:58:52,250] [INFO] Epoch [22/2695], Step [289/910], Loss: 7.7794 (poly: 0.0051, lower: 0.0000, upper: 0.0000, cls_loss: 0.0000, line_iou: 0.0014, conf: 0.1119), s/iter: 0.1030, lr: 3.0e-04
[2024-12-25 21:58:52,342] [INFO] Epoch [22/2695], Step [290/910], Loss: 7.7530 (poly: 0.0065, lower: 0.0000, upper: 0.0000, cls_loss: 0.0000, line_iou: 0.0014, conf: 0.1119), s/iter: 0.1034, lr: 3.0e-04
[2024-12-25 21:58:52,442] [INFO] Epoch [22/2695], Step [291/910], Loss: 7.7267 (poly: 0.0061, lower: 0.0000, upper: 0.0000, cls_loss: 0.0000, line_iou: 0.0015, conf: 0.1119), s/iter: 0.1038, lr: 3.0e-04
[2024-12-25 21:58:52,541] [INFO] Epoch [22/2695], Step [292/910], Loss: 7.7011 (poly: 0.0556, lower: 0.0000, upper: 0.0001, cls_loss: 0.0000, line_iou: 0.0016, conf: 0.1947), s/iter: 0.1039, lr: 3.0e-04
[2024-12-25 21:58:52,653] [INFO] Epoch [22/2695], Step [293/910], Loss: 7.6755 (poly: 0.0057, lower: 0.0000, upper: 0.0000, cls_loss: 0.0000, line_iou: 0.0012, conf: 0.1947), s/iter: 0.1038, lr: 3.0e-04
[2024-12-25 21:58:52,765] [INFO] Epoch [22/2695], Step [294/910], Loss: 7.6498 (poly: 0.0048, lower: 0.0000, upper: 0.0000, cls_loss: 0.0000, line_iou: 0.0014, conf: 0.1119), s/iter: 0.1038, lr: 3.0e-04
[2024-12-25 21:58:52,875] [INFO] Epoch [22/2695], Step [295/910], Loss: 7.6250 (poly: 0.0961, lower: 0.0000, upper: 0.0000, cls_loss: 0.0000, line_iou: 0.0014, conf: 0.2242), s/iter: 0.1039, lr: 3.0e-04
[2024-12-25 21:58:52,977] [INFO] Epoch [22/2695], Step [296/910], Loss: 7.5996 (poly: 0.0065, lower: 0.0000, upper: 0.0000, cls_loss: 0.0000, line_iou: 0.0014, conf: 0.1118), s/iter: 0.1038, lr: 3.0e-04
[2024-12-25 21:58:53,030] [INFO] Weight SoftAdapt Loss tensor([0.4967, 0.0017, 0.0017, 0.0017, 0.0017, 0.4967], dtype=torch.float64)
[2024-12-25 21:58:53,093] [INFO] Epoch [22/2695], Step [297/910], Loss: 7.5759 (poly: 0.0665, lower: 0.0000, upper: 0.0001, cls_loss: 0.0000, line_iou: 0.4866, conf: 0.0006), s/iter: 0.1040, lr: 3.0e-04
[2024-12-25 21:58:53,184] [INFO] Epoch [22/2695], Step [298/910], Loss: 7.5520 (poly: 0.0055, lower: 0.0000, upper: 0.0000, cls_loss: 0.0000, line_iou: 0.4551, conf: 0.0004), s/iter: 0.1037, lr: 3.0e-04
[2024-12-25 21:58:53,274] [INFO] Epoch [22/2695], Step [299/910], Loss: 7.5286 (poly: 0.1104, lower: 0.0000, upper: 0.0001, cls_loss: 0.0000, line_iou: 0.4488, conf: 0.0007), s/iter: 0.1035, lr: 3.0e-04
[2024-12-25 21:58:53,370] [INFO] Epoch [22/2695], Step [300/910], Loss: 7.5056 (poly: 0.1229, lower: 0.0000, upper: 0.0004, cls_loss: 0.0000, line_iou: 0.4907, conf: 0.0007), s/iter: 0.1035, lr: 3.0e-04
[2024-12-25 21:58:53,478] [INFO] Epoch [22/2695], Step [301/910], Loss: 7.4827 (poly: 0.1297, lower: 0.0000, upper: 0.0002, cls_loss: 0.0000, line_iou: 0.4900, conf: 0.0007), s/iter: 0.1035, lr: 3.0e-04
[2024-12-25 21:58:53,598] [INFO] Epoch [22/2695], Step [302/910], Loss: 7.4593 (poly: 0.0069, lower: 0.0000, upper: 0.0000, cls_loss: 0.0000, line_iou: 0.3915, conf: 0.0004), s/iter: 0.1037, lr: 3.0e-04
[2024-12-25 21:58:53,709] [INFO] Epoch [22/2695], Step [303/910], Loss: 7.4364 (poly: 0.0960, lower: 0.0000, upper: 0.0001, cls_loss: 0.0000, line_iou: 0.4434, conf: 0.0007), s/iter: 0.1038, lr: 3.0e-04
[2024-12-25 21:58:53,798] [INFO] Epoch [22/2695], Step [304/910], Loss: 7.4138 (poly: 0.0588, lower: 0.0000, upper: 0.0001, cls_loss: 0.0000, line_iou: 0.4875, conf: 0.0006), s/iter: 0.1035, lr: 3.0e-04
[2024-12-25 21:58:53,915] [INFO] Epoch [22/2695], Step [305/910], Loss: 7.3910 (poly: 0.0535, lower: 0.0000, upper: 0.0001, cls_loss: 0.0000, line_iou: 0.4093, conf: 0.0004), s/iter: 0.1036, lr: 3.0e-04
[2024-12-25 21:58:53,979] [INFO] Weight SoftAdapt Loss tensor([0.4967, 0.0017, 0.0017, 0.0017, 0.4967, 0.0017], dtype=torch.float64)
[2024-12-25 21:58:54,051] [INFO] Epoch [22/2695], Step [306/910], Loss: 7.3690 (poly: 0.0002, lower: 0.0000, upper: 0.0002, cls_loss: 0.0000, line_iou: 0.4675, conf: 0.1946), s/iter: 0.1039, lr: 3.0e-04
[2024-12-25 21:58:54,165] [INFO] Epoch [22/2695], Step [307/910], Loss: 7.3467 (poly: 0.0000, lower: 0.0000, upper: 0.0000, cls_loss: 0.0000, line_iou: 0.4245, conf: 0.1118), s/iter: 0.1038, lr: 3.0e-04
[2024-12-25 21:58:54,281] [INFO] Epoch [22/2695], Step [308/910], Loss: 7.3245 (poly: 0.0000, lower: 0.0000, upper: 0.0000, cls_loss: 0.0000, line_iou: 0.3926, conf: 0.1118), s/iter: 0.1038, lr: 3.0e-04
[2024-12-25 21:58:54,397] [INFO] Epoch [22/2695], Step [309/910], Loss: 7.3024 (poly: 0.0000, lower: 0.0000, upper: 0.0000, cls_loss: 0.0000, line_iou: 0.3756, conf: 0.1118), s/iter: 0.1038, lr: 3.0e-04
[2024-12-25 21:58:54,507] [INFO] Epoch [22/2695], Step [310/910], Loss: 7.2810 (poly: 0.0002, lower: 0.0000, upper: 0.0002, cls_loss: 0.0000, line_iou: 0.4623, conf: 0.1946), s/iter: 0.1037, lr: 3.0e-04
[2024-12-25 21:58:54,617] [INFO] Epoch [22/2695], Step [311/910], Loss: 7.2593 (poly: 0.0000, lower: 0.0000, upper: 0.0000, cls_loss: 0.0000, line_iou: 0.4193, conf: 0.1117), s/iter: 0.1040, lr: 3.0e-04
[2024-12-25 21:58:54,733] [INFO] Epoch [22/2695], Step [312/910], Loss: 7.2375 (poly: 0.0000, lower: 0.0000, upper: 0.0000, cls_loss: 0.0000, line_iou: 0.3646, conf: 0.1118), s/iter: 0.1040, lr: 3.0e-04
[2024-12-25 21:58:54,824] [INFO] Epoch [22/2695], Step [313/910], Loss: 7.2165 (poly: 0.0002, lower: 0.0000, upper: 0.0001, cls_loss: 0.0000, line_iou: 0.4625, conf: 0.1946), s/iter: 0.1037, lr: 3.0e-04
[2024-12-25 21:58:54,922] [INFO] Epoch [22/2695], Step [314/910], Loss: 7.1954 (poly: 0.0000, lower: 0.0000, upper: 0.0000, cls_loss: 0.0000, line_iou: 0.4771, conf: 0.1117), s/iter: 0.1037, lr: 3.0e-04
[2024-12-25 21:58:54,969] [INFO] Weight SoftAdapt Loss tensor([0.0017, 0.0017, 0.0017, 0.0017, 0.4967, 0.4967], dtype=torch.float64)
[2024-12-25 21:58:55,022] [INFO] Epoch [22/2695], Step [315/910], Loss: 7.1733 (poly: 0.0470, lower: 0.0000, upper: 0.0001, cls_loss: 0.0000, line_iou: 0.0016, conf: 0.1945), s/iter: 0.1037, lr: 3.0e-04
[2024-12-25 21:58:55,155] [INFO] Epoch [22/2695], Step [316/910], Loss: 7.1510 (poly: 0.0032, lower: 0.0000, upper: 0.0000, cls_loss: 0.0000, line_iou: 0.0014, conf: 0.1117), s/iter: 0.1037, lr: 3.0e-04
[2024-12-25 21:58:55,247] [INFO] Epoch [22/2695], Step [317/910], Loss: 7.1295 (poly: 0.1226, lower: 0.0000, upper: 0.0002, cls_loss: 0.0000, line_iou: 0.0016, conf: 0.2242), s/iter: 0.1035, lr: 3.0e-04
[2024-12-25 21:58:55,362] [INFO] Epoch [22/2695], Step [318/910], Loss: 7.1082 (poly: 0.1316, lower: 0.0000, upper: 0.0004, cls_loss: 0.0000, line_iou: 0.0016, conf: 0.2242), s/iter: 0.1035, lr: 3.0e-04
[2024-12-25 21:58:55,487] [INFO] Epoch [22/2695], Step [319/910], Loss: 7.0871 (poly: 0.1275, lower: 0.0000, upper: 0.0004, cls_loss: 0.0000, line_iou: 0.0016, conf: 0.2242), s/iter: 0.1034, lr: 3.0e-04
[2024-12-25 21:58:55,593] [INFO] Epoch [22/2695], Step [320/910], Loss: 7.0653 (poly: 0.0063, lower: 0.0000, upper: 0.0000, cls_loss: 0.0000, line_iou: 0.0014, conf: 0.1116), s/iter: 0.1033, lr: 3.0e-04
[2024-12-25 21:58:55,725] [INFO] Epoch [22/2695], Step [321/910], Loss: 7.0436 (poly: 0.0021, lower: 0.0000, upper: 0.0000, cls_loss: 0.0000, line_iou: 0.0014, conf: 0.1117), s/iter: 0.1034, lr: 3.0e-04
[2024-12-25 21:58:55,848] [INFO] Epoch [22/2695], Step [322/910], Loss: 7.0224 (poly: 0.0235, lower: 0.0000, upper: 0.0000, cls_loss: 0.0000, line_iou: 0.0015, conf: 0.1945), s/iter: 0.1034, lr: 3.0e-04
[2024-12-25 21:58:55,968] [INFO] Epoch [22/2695], Step [323/910], Loss: 7.0011 (poly: 0.0031, lower: 0.0000, upper: 0.0000, cls_loss: 0.0000, line_iou: 0.0015, conf: 0.1116), s/iter: 0.1034, lr: 3.0e-04
[2024-12-25 21:58:56,019] [INFO] Weight SoftAdapt Loss tensor([0.4967, 0.0017, 0.0017, 0.0017, 0.0017, 0.4967], dtype=torch.float64)
[2024-12-25 21:58:56,070] [INFO] Epoch [22/2695], Step [324/910], Loss: 6.9807 (poly: 0.0029, lower: 0.0000, upper: 0.0000, cls_loss: 0.0000, line_iou: 0.3970, conf: 0.0006), s/iter: 0.1032, lr: 3.0e-04
[2024-12-25 21:58:56,177] [INFO] Epoch [22/2695], Step [325/910], Loss: 6.9609 (poly: 0.1030, lower: 0.0000, upper: 0.0000, cls_loss: 0.0000, line_iou: 0.4399, conf: 0.0007), s/iter: 0.1032, lr: 3.0e-04
[2024-12-25 21:58:56,306] [INFO] Epoch [22/2695], Step [326/910], Loss: 6.9412 (poly: 0.1145, lower: 0.0000, upper: 0.0000, cls_loss: 0.0000, line_iou: 0.4416, conf: 0.0007), s/iter: 0.1032, lr: 3.0e-04
[2024-12-25 21:58:56,410] [INFO] Epoch [22/2695], Step [327/910], Loss: 6.9213 (poly: 0.0029, lower: 0.0000, upper: 0.0000, cls_loss: 0.0000, line_iou: 0.4146, conf: 0.0004), s/iter: 0.1033, lr: 3.0e-04
[2024-12-25 21:58:56,503] [INFO] Epoch [22/2695], Step [328/910], Loss: 6.9014 (poly: 0.0033, lower: 0.0000, upper: 0.0000, cls_loss: 0.0000, line_iou: 0.4041, conf: 0.0006), s/iter: 0.1033, lr: 3.0e-04
[2024-12-25 21:58:56,617] [INFO] Epoch [22/2695], Step [329/910], Loss: 6.8817 (poly: 0.0036, lower: 0.0000, upper: 0.0000, cls_loss: 0.0000, line_iou: 0.4137, conf: 0.0004), s/iter: 0.1035, lr: 3.0e-04
[2024-12-25 21:58:56,734] [INFO] Epoch [22/2695], Step [330/910], Loss: 6.8621 (poly: 0.0035, lower: 0.0000, upper: 0.0000, cls_loss: 0.0000, line_iou: 0.4060, conf: 0.0004), s/iter: 0.1038, lr: 3.0e-04
[2024-12-25 21:58:56,854] [INFO] Epoch [22/2695], Step [331/910], Loss: 6.8432 (poly: 0.1233, lower: 0.0000, upper: 0.0002, cls_loss: 0.0000, line_iou: 0.4908, conf: 0.0007), s/iter: 0.1040, lr: 3.0e-04
[2024-12-25 21:58:56,960] [INFO] Epoch [22/2695], Step [332/910], Loss: 6.8240 (poly: 0.0045, lower: 0.0000, upper: 0.0000, cls_loss: 0.0000, line_iou: 0.4474, conf: 0.0004), s/iter: 0.1040, lr: 3.0e-04
[2024-12-25 21:58:57,027] [INFO] Weight SoftAdapt Loss tensor([0.4967, 0.0017, 0.0017, 0.0017, 0.4967, 0.0017], dtype=torch.float64)
[2024-12-25 21:58:57,088] [INFO] Epoch [22/2695], Step [333/910], Loss: 6.8056 (poly: 0.0002, lower: 0.0000, upper: 0.0001, cls_loss: 0.0000, line_iou: 0.4939, conf: 0.1945), s/iter: 0.1043, lr: 3.0e-04
[2024-12-25 21:58:57,188] [INFO] Epoch [22/2695], Step [334/910], Loss: 6.7868 (poly: 0.0000, lower: 0.0000, upper: 0.0000, cls_loss: 0.0000, line_iou: 0.4143, conf: 0.1115), s/iter: 0.1044, lr: 3.0e-04
[2024-12-25 21:58:57,307] [INFO] Epoch [22/2695], Step [335/910], Loss: 6.7681 (poly: 0.0000, lower: 0.0000, upper: 0.0000, cls_loss: 0.0000, line_iou: 0.4228, conf: 0.1116), s/iter: 0.1044, lr: 3.0e-04
[2024-12-25 21:58:57,437] [INFO] Epoch [22/2695], Step [336/910], Loss: 6.7495 (poly: 0.0000, lower: 0.0000, upper: 0.0000, cls_loss: 0.0000, line_iou: 0.4244, conf: 0.1116), s/iter: 0.1046, lr: 3.0e-04
[2024-12-25 21:58:57,566] [INFO] Epoch [22/2695], Step [337/910], Loss: 6.7316 (poly: 0.0004, lower: 0.0000, upper: 0.0002, cls_loss: 0.0000, line_iou: 0.4893, conf: 0.2241), s/iter: 0.1047, lr: 3.0e-04
[2024-12-25 21:58:57,681] [INFO] Epoch [22/2695], Step [338/910], Loss: 6.7138 (poly: 0.0004, lower: 0.0000, upper: 0.0002, cls_loss: 0.0000, line_iou: 0.4894, conf: 0.2240), s/iter: 0.1047, lr: 3.0e-04
[2024-12-25 21:58:57,806] [INFO] Epoch [22/2695], Step [339/910], Loss: 6.6960 (poly: 0.0002, lower: 0.0000, upper: 0.0001, cls_loss: 0.0000, line_iou: 0.4755, conf: 0.1944), s/iter: 0.1049, lr: 3.0e-04
[2024-12-25 21:58:57,925] [INFO] Epoch [22/2695], Step [340/910], Loss: 6.6784 (poly: 0.0004, lower: 0.0000, upper: 0.0002, cls_loss: 0.0000, line_iou: 0.4919, conf: 0.2240), s/iter: 0.1051, lr: 3.0e-04
[2024-12-25 21:58:58,059] [INFO] Epoch [22/2695], Step [341/910], Loss: 6.6604 (poly: 0.0000, lower: 0.0000, upper: 0.0001, cls_loss: 0.0000, line_iou: 0.4173, conf: 0.1115), s/iter: 0.1054, lr: 3.0e-04
[2024-12-25 21:58:58,122] [INFO] Weight SoftAdapt Loss tensor([0.0017, 0.0017, 0.0017, 0.0017, 0.4967, 0.4967], dtype=torch.float64)
[2024-12-25 21:58:58,186] [INFO] Epoch [22/2695], Step [342/910], Loss: 6.6413 (poly: 0.0033, lower: 0.0000, upper: 0.0000, cls_loss: 0.0000, line_iou: 0.0014, conf: 0.1115), s/iter: 0.1055, lr: 3.0e-04
[2024-12-25 21:58:58,322] [INFO] Epoch [22/2695], Step [343/910], Loss: 6.6229 (poly: 0.1245, lower: 0.0000, upper: 0.0000, cls_loss: 0.0000, line_iou: 0.0015, conf: 0.2240), s/iter: 0.1057, lr: 3.0e-04
[2024-12-25 21:58:58,454] [INFO] Epoch [22/2695], Step [344/910], Loss: 6.6040 (poly: 0.0147, lower: 0.0000, upper: 0.0001, cls_loss: 0.0000, line_iou: 0.0014, conf: 0.1115), s/iter: 0.1060, lr: 3.0e-04
[2024-12-25 21:58:58,563] [INFO] Epoch [22/2695], Step [345/910], Loss: 6.5852 (poly: 0.0040, lower: 0.0000, upper: 0.0000, cls_loss: 0.0000, line_iou: 0.0015, conf: 0.1115), s/iter: 0.1061, lr: 3.0e-04
[2024-12-25 21:58:58,682] [INFO] Epoch [22/2695], Step [346/910], Loss: 6.5665 (poly: 0.0035, lower: 0.0000, upper: 0.0000, cls_loss: 0.0000, line_iou: 0.0014, conf: 0.1115), s/iter: 0.1062, lr: 3.0e-04
[2024-12-25 21:58:58,782] [INFO] Epoch [22/2695], Step [347/910], Loss: 6.5486 (poly: 0.1183, lower: 0.0000, upper: 0.0002, cls_loss: 0.0000, line_iou: 0.0016, conf: 0.2239), s/iter: 0.1059, lr: 3.0e-04
[2024-12-25 21:58:58,884] [INFO] Epoch [22/2695], Step [348/910], Loss: 6.5305 (poly: 0.0568, lower: 0.0000, upper: 0.0001, cls_loss: 0.0000, line_iou: 0.0016, conf: 0.1944), s/iter: 0.1056, lr: 3.0e-04
[2024-12-25 21:58:58,991] [INFO] Epoch [22/2695], Step [349/910], Loss: 6.5128 (poly: 0.1210, lower: 0.0000, upper: 0.0002, cls_loss: 0.0000, line_iou: 0.0016, conf: 0.2239), s/iter: 0.1055, lr: 3.0e-04
[2024-12-25 21:58:59,102] [INFO] Epoch [22/2695], Step [350/910], Loss: 6.4945 (poly: 0.0031, lower: 0.0000, upper: 0.0000, cls_loss: 0.0000, line_iou: 0.0013, conf: 0.1114), s/iter: 0.1055, lr: 3.0e-04
[2024-12-25 21:58:59,150] [INFO] Weight SoftAdapt Loss tensor([0.4967, 0.0017, 0.0017, 0.0017, 0.0017, 0.4967], dtype=torch.float64)
[2024-12-25 21:58:59,211] [INFO] Epoch [22/2695], Step [351/910], Loss: 6.4776 (poly: 0.0733, lower: 0.0000, upper: 0.0002, cls_loss: 0.0000, line_iou: 0.4852, conf: 0.0007), s/iter: 0.1054, lr: 3.0e-04
[2024-12-25 21:58:59,339] [INFO] Epoch [22/2695], Step [352/910], Loss: 6.4609 (poly: 0.1184, lower: 0.0000, upper: 0.0002, cls_loss: 0.0000, line_iou: 0.4929, conf: 0.0007), s/iter: 0.1055, lr: 3.0e-04
[2024-12-25 21:58:59,459] [INFO] Epoch [22/2695], Step [353/910], Loss: 6.4439 (poly: 0.0043, lower: 0.0000, upper: 0.0000, cls_loss: 0.0000, line_iou: 0.4429, conf: 0.0004), s/iter: 0.1056, lr: 3.0e-04
[2024-12-25 21:58:59,575] [INFO] Epoch [22/2695], Step [354/910], Loss: 6.4274 (poly: 0.1266, lower: 0.0000, upper: 0.0002, cls_loss: 0.0000, line_iou: 0.4900, conf: 0.0007), s/iter: 0.1058, lr: 3.0e-04
[2024-12-25 21:58:59,679] [INFO] Epoch [22/2695], Step [355/910], Loss: 6.4111 (poly: 0.1204, lower: 0.0000, upper: 0.0002, cls_loss: 0.0000, line_iou: 0.4890, conf: 0.0007), s/iter: 0.1059, lr: 3.0e-04
[2024-12-25 21:58:59,779] [INFO] Epoch [22/2695], Step [356/910], Loss: 6.3946 (poly: 0.0999, lower: 0.0000, upper: 0.0001, cls_loss: 0.0000, line_iou: 0.4495, conf: 0.0007), s/iter: 0.1058, lr: 3.0e-04
[2024-12-25 21:58:59,881] [INFO] Epoch [22/2695], Step [357/910], Loss: 6.3779 (poly: 0.0044, lower: 0.0000, upper: 0.0000, cls_loss: 0.0000, line_iou: 0.4348, conf: 0.0004), s/iter: 0.1060, lr: 3.0e-04
[2024-12-25 21:58:59,982] [INFO] Epoch [22/2695], Step [358/910], Loss: 6.3616 (poly: 0.0767, lower: 0.0000, upper: 0.0000, cls_loss: 0.0000, line_iou: 0.4772, conf: 0.0006), s/iter: 0.1059, lr: 3.0e-04
[2024-12-25 21:59:00,111] [INFO] Epoch [22/2695], Step [359/910], Loss: 6.3451 (poly: 0.0043, lower: 0.0000, upper: 0.0000, cls_loss: 0.0000, line_iou: 0.4248, conf: 0.0004), s/iter: 0.1060, lr: 3.0e-04
[2024-12-25 21:59:00,181] [INFO] Weight SoftAdapt Loss tensor([0.4967, 0.0017, 0.0017, 0.0017, 0.4967, 0.0017], dtype=torch.float64)
[2024-12-25 21:59:00,239] [INFO] Epoch [22/2695], Step [360/910], Loss: 6.3290 (poly: 0.0000, lower: 0.0000, upper: 0.0000, cls_loss: 0.0000, line_iou: 0.4423, conf: 0.1113), s/iter: 0.1061, lr: 3.0e-04
[2024-12-25 21:59:00,354] [INFO] Epoch [22/2695], Step [361/910], Loss: 6.3128 (poly: 0.0000, lower: 0.0000, upper: 0.0000, cls_loss: 0.0000, line_iou: 0.3660, conf: 0.1113), s/iter: 0.1059, lr: 3.0e-04
[2024-12-25 21:59:00,468] [INFO] Epoch [22/2695], Step [362/910], Loss: 6.2969 (poly: 0.0000, lower: 0.0000, upper: 0.0000, cls_loss: 0.0000, line_iou: 0.4232, conf: 0.1113), s/iter: 0.1059, lr: 3.0e-04
[2024-12-25 21:59:00,560] [INFO] Epoch [22/2695], Step [363/910], Loss: 6.2810 (poly: 0.0000, lower: 0.0000, upper: 0.0002, cls_loss: 0.0000, line_iou: 0.4412, conf: 0.1113), s/iter: 0.1059, lr: 3.0e-04
[2024-12-25 21:59:00,680] [INFO] Epoch [22/2695], Step [364/910], Loss: 6.2657 (poly: 0.0002, lower: 0.0000, upper: 0.0001, cls_loss: 0.0000, line_iou: 0.4871, conf: 0.1945), s/iter: 0.1059, lr: 3.0e-04
[2024-12-25 21:59:00,812] [INFO] Epoch [22/2695], Step [365/910], Loss: 6.2499 (poly: 0.0000, lower: 0.0000, upper: 0.0000, cls_loss: 0.0000, line_iou: 0.4018, conf: 0.1113), s/iter: 0.1062, lr: 3.0e-04
[2024-12-25 21:59:00,936] [INFO] Epoch [22/2695], Step [366/910], Loss: 6.2345 (poly: 0.0000, lower: 0.0000, upper: 0.0000, cls_loss: 0.0000, line_iou: 0.4027, conf: 0.1946), s/iter: 0.1064, lr: 3.0e-04
[2024-12-25 21:59:01,023] [INFO] Epoch [22/2695], Step [367/910], Loss: 6.2189 (poly: 0.0000, lower: 0.0000, upper: 0.0000, cls_loss: 0.0000, line_iou: 0.4036, conf: 0.1113), s/iter: 0.1061, lr: 3.0e-04
[2024-12-25 21:59:01,115] [INFO] Epoch [22/2695], Step [368/910], Loss: 6.2034 (poly: 0.0000, lower: 0.0000, upper: 0.0000, cls_loss: 0.0000, line_iou: 0.4208, conf: 0.1113), s/iter: 0.1058, lr: 3.0e-04
[2024-12-25 21:59:01,170] [INFO] Weight SoftAdapt Loss tensor([0.0017, 0.0017, 0.0017, 0.0017, 0.4967, 0.4967], dtype=torch.float64)
[2024-12-25 21:59:01,229] [INFO] Epoch [22/2695], Step [369/910], Loss: 6.1871 (poly: 0.0548, lower: 0.0000, upper: 0.0001, cls_loss: 0.0000, line_iou: 0.0016, conf: 0.1112), s/iter: 0.1057, lr: 3.0e-04
[2024-12-25 21:59:01,330] [INFO] Epoch [22/2695], Step [370/910], Loss: 6.1713 (poly: 0.1393, lower: 0.0000, upper: 0.0001, cls_loss: 0.0000, line_iou: 0.0016, conf: 0.2237), s/iter: 0.1055, lr: 3.0e-04
[2024-12-25 21:59:01,435] [INFO] Epoch [22/2695], Step [371/910], Loss: 6.1550 (poly: 0.0038, lower: 0.0000, upper: 0.0000, cls_loss: 0.0000, line_iou: 0.0014, conf: 0.1113), s/iter: 0.1055, lr: 3.0e-04
[2024-12-25 21:59:01,540] [INFO] Epoch [22/2695], Step [372/910], Loss: 6.1388 (poly: 0.0026, lower: 0.0000, upper: 0.0000, cls_loss: 0.0000, line_iou: 0.0013, conf: 0.1112), s/iter: 0.1056, lr: 3.0e-04
[2024-12-25 21:59:01,637] [INFO] Epoch [22/2695], Step [373/910], Loss: 6.1226 (poly: 0.0036, lower: 0.0000, upper: 0.0000, cls_loss: 0.0000, line_iou: 0.0014, conf: 0.1112), s/iter: 0.1056, lr: 3.0e-04
[2024-12-25 21:59:01,721] [INFO] Epoch [22/2695], Step [374/910], Loss: 6.1069 (poly: 0.0636, lower: 0.0000, upper: 0.0002, cls_loss: 0.0000, line_iou: 0.0016, conf: 0.1945), s/iter: 0.1053, lr: 3.0e-04
[2024-12-25 21:59:01,830] [INFO] Epoch [22/2695], Step [375/910], Loss: 6.0915 (poly: 0.0942, lower: 0.0000, upper: 0.0001, cls_loss: 0.0000, line_iou: 0.0015, conf: 0.2237), s/iter: 0.1054, lr: 3.0e-04
[2024-12-25 21:59:01,949] [INFO] Epoch [22/2695], Step [376/910], Loss: 6.0760 (poly: 0.0708, lower: 0.0000, upper: 0.0002, cls_loss: 0.0000, line_iou: 0.0016, conf: 0.1946), s/iter: 0.1056, lr: 3.0e-04
[2024-12-25 21:59:02,039] [INFO] Epoch [22/2695], Step [377/910], Loss: 6.0606 (poly: 0.0631, lower: 0.0000, upper: 0.0002, cls_loss: 0.0000, line_iou: 0.0016, conf: 0.1945), s/iter: 0.1056, lr: 3.0e-04
[2024-12-25 21:59:02,085] [INFO] Weight SoftAdapt Loss tensor([0.4967, 0.0017, 0.0017, 0.0017, 0.0017, 0.4967], dtype=torch.float64)
[2024-12-25 21:59:02,134] [INFO] Epoch [22/2695], Step [378/910], Loss: 6.0456 (poly: 0.0026, lower: 0.0000, upper: 0.0000, cls_loss: 0.0000, line_iou: 0.4043, conf: 0.0004), s/iter: 0.1056, lr: 3.0e-04
[2024-12-25 21:59:02,234] [INFO] Epoch [22/2695], Step [379/910], Loss: 6.0307 (poly: 0.0037, lower: 0.0000, upper: 0.0001, cls_loss: 0.0000, line_iou: 0.3676, conf: 0.0006), s/iter: 0.1054, lr: 3.0e-04
[2024-12-25 21:59:02,351] [INFO] Epoch [22/2695], Step [380/910], Loss: 6.0164 (poly: 0.1275, lower: 0.0000, upper: 0.0001, cls_loss: 0.0000, line_iou: 0.4871, conf: 0.0007), s/iter: 0.1055, lr: 3.0e-04
[2024-12-25 21:59:02,455] [INFO] Epoch [22/2695], Step [381/910], Loss: 6.0018 (poly: 0.0034, lower: 0.0000, upper: 0.0000, cls_loss: 0.0000, line_iou: 0.4276, conf: 0.0004), s/iter: 0.1056, lr: 3.0e-04
[2024-12-25 21:59:02,545] [INFO] Epoch [22/2695], Step [382/910], Loss: 5.9877 (poly: 0.1366, lower: 0.0000, upper: 0.0001, cls_loss: 0.0000, line_iou: 0.4749, conf: 0.0007), s/iter: 0.1054, lr: 3.0e-04
[2024-12-25 21:59:02,660] [INFO] Epoch [22/2695], Step [383/910], Loss: 5.9730 (poly: 0.0023, lower: 0.0000, upper: 0.0000, cls_loss: 0.0000, line_iou: 0.3865, conf: 0.0004), s/iter: 0.1055, lr: 3.0e-04
[2024-12-25 21:59:02,750] [INFO] Epoch [22/2695], Step [384/910], Loss: 5.9585 (poly: 0.0027, lower: 0.0000, upper: 0.0000, cls_loss: 0.0000, line_iou: 0.4029, conf: 0.0004), s/iter: 0.1054, lr: 3.0e-04
[2024-12-25 21:59:02,849] [INFO] Epoch [22/2695], Step [385/910], Loss: 5.9442 (poly: 0.0085, lower: 0.0000, upper: 0.0000, cls_loss: 0.0000, line_iou: 0.4230, conf: 0.0006), s/iter: 0.1054, lr: 3.0e-04
[2024-12-25 21:59:02,970] [INFO] Epoch [22/2695], Step [386/910], Loss: 5.9304 (poly: 0.1393, lower: 0.0000, upper: 0.0001, cls_loss: 0.0000, line_iou: 0.4871, conf: 0.0007), s/iter: 0.1055, lr: 3.0e-04
[2024-12-25 21:59:03,020] [INFO] Weight SoftAdapt Loss tensor([0.4967, 0.0017, 0.0017, 0.0017, 0.4967, 0.0017], dtype=torch.float64)
[2024-12-25 21:59:03,071] [INFO] Epoch [22/2695], Step [387/910], Loss: 5.9169 (poly: 0.0004, lower: 0.0000, upper: 0.0001, cls_loss: 0.0000, line_iou: 0.4758, conf: 0.2236), s/iter: 0.1055, lr: 3.0e-04
[2024-12-25 21:59:03,164] [INFO] Epoch [22/2695], Step [388/910], Loss: 5.9034 (poly: 0.0002, lower: 0.0000, upper: 0.0002, cls_loss: 0.0000, line_iou: 0.4878, conf: 0.1944), s/iter: 0.1054, lr: 3.0e-04
[2024-12-25 21:59:03,275] [INFO] Epoch [22/2695], Step [389/910], Loss: 5.8900 (poly: 0.0004, lower: 0.0000, upper: 0.0001, cls_loss: 0.0000, line_iou: 0.4792, conf: 0.2236), s/iter: 0.1055, lr: 3.0e-04
[2024-12-25 21:59:03,382] [INFO] Epoch [22/2695], Step [390/910], Loss: 5.8767 (poly: 0.0004, lower: 0.0000, upper: 0.0001, cls_loss: 0.0000, line_iou: 0.4844, conf: 0.2236), s/iter: 0.1056, lr: 3.0e-04
[2024-12-25 21:59:03,486] [INFO] Epoch [22/2695], Step [391/910], Loss: 5.8634 (poly: 0.0001, lower: 0.0000, upper: 0.0001, cls_loss: 0.0000, line_iou: 0.4500, conf: 0.1943), s/iter: 0.1057, lr: 3.0e-04
[2024-12-25 21:59:03,606] [INFO] Epoch [22/2695], Step [392/910], Loss: 5.8501 (poly: 0.0003, lower: 0.0000, upper: 0.0000, cls_loss: 0.0000, line_iou: 0.4521, conf: 0.2236), s/iter: 0.1059, lr: 3.0e-04
[2024-12-25 21:59:03,715] [INFO] Epoch [22/2695], Step [393/910], Loss: 5.8366 (poly: 0.0000, lower: 0.0000, upper: 0.0000, cls_loss: 0.0000, line_iou: 0.4230, conf: 0.1110), s/iter: 0.1059, lr: 3.0e-04
[2024-12-25 21:59:03,828] [INFO] Epoch [22/2695], Step [394/910], Loss: 5.8230 (poly: 0.0000, lower: 0.0000, upper: 0.0000, cls_loss: 0.0000, line_iou: 0.3694, conf: 0.1110), s/iter: 0.1059, lr: 3.0e-04
[2024-12-25 21:59:03,925] [INFO] Epoch [22/2695], Step [395/910], Loss: 5.8100 (poly: 0.0003, lower: 0.0000, upper: 0.0001, cls_loss: 0.0000, line_iou: 0.4439, conf: 0.2235), s/iter: 0.1058, lr: 3.0e-04
[2024-12-25 21:59:03,969] [INFO] Weight SoftAdapt Loss tensor([0.0017, 0.0017, 0.0017, 0.0017, 0.4967, 0.4967], dtype=torch.float64)
[2024-12-25 21:59:04,020] [INFO] Epoch [22/2695], Step [396/910], Loss: 5.7956 (poly: 0.0055, lower: 0.0000, upper: 0.0000, cls_loss: 0.0000, line_iou: 0.0015, conf: 0.1110), s/iter: 0.1057, lr: 3.0e-04
[2024-12-25 21:59:04,116] [INFO] Epoch [22/2695], Step [397/910], Loss: 5.7814 (poly: 0.0314, lower: 0.0000, upper: 0.0001, cls_loss: 0.0000, line_iou: 0.0015, conf: 0.1110), s/iter: 0.1055, lr: 3.0e-04
[2024-12-25 21:59:04,221] [INFO] Epoch [22/2695], Step [398/910], Loss: 5.7672 (poly: 0.0172, lower: 0.0000, upper: 0.0000, cls_loss: 0.0000, line_iou: 0.0017, conf: 0.1110), s/iter: 0.1057, lr: 3.0e-04
[2024-12-25 21:59:04,329] [INFO] Epoch [22/2695], Step [399/910], Loss: 5.7530 (poly: 0.0091, lower: 0.0000, upper: 0.0000, cls_loss: 0.0000, line_iou: 0.0015, conf: 0.1110), s/iter: 0.1059, lr: 3.0e-04
[2024-12-25 21:59:04,428] [INFO] Epoch [22/2695], Step [400/910], Loss: 5.7395 (poly: 0.1212, lower: 0.0000, upper: 0.0002, cls_loss: 0.0000, line_iou: 0.0016, conf: 0.2235), s/iter: 0.1059, lr: 3.0e-04
[2024-12-25 21:59:04,519] [INFO] Epoch [22/2695], Step [401/910], Loss: 5.7260 (poly: 0.1192, lower: 0.0000, upper: 0.0001, cls_loss: 0.0000, line_iou: 0.0016, conf: 0.2234), s/iter: 0.1057, lr: 3.0e-04
[2024-12-25 21:59:04,643] [INFO] Epoch [22/2695], Step [402/910], Loss: 5.7126 (poly: 0.0980, lower: 0.0000, upper: 0.0000, cls_loss: 0.0000, line_iou: 0.0015, conf: 0.2234), s/iter: 0.1058, lr: 3.0e-04
[2024-12-25 21:59:04,750] [INFO] Epoch [22/2695], Step [403/910], Loss: 5.6987 (poly: 0.0047, lower: 0.0000, upper: 0.0000, cls_loss: 0.0000, line_iou: 0.0014, conf: 0.1109), s/iter: 0.1057, lr: 3.0e-04
[2024-12-25 21:59:04,836] [INFO] Epoch [22/2695], Step [404/910], Loss: 5.6849 (poly: 0.0055, lower: 0.0000, upper: 0.0000, cls_loss: 0.0000, line_iou: 0.0015, conf: 0.1109), s/iter: 0.1057, lr: 3.0e-04
[2024-12-25 21:59:04,886] [INFO] Weight SoftAdapt Loss tensor([0.4967, 0.0017, 0.0017, 0.0017, 0.0017, 0.4967], dtype=torch.float64)
[2024-12-25 21:59:04,952] [INFO] Epoch [22/2695], Step [405/910], Loss: 5.6720 (poly: 0.0033, lower: 0.0000, upper: 0.0000, cls_loss: 0.0000, line_iou: 0.4456, conf: 0.0004), s/iter: 0.1057, lr: 3.0e-04
[2024-12-25 21:59:05,068] [INFO] Epoch [22/2695], Step [406/910], Loss: 5.6595 (poly: 0.1232, lower: 0.0000, upper: 0.0001, cls_loss: 0.0000, line_iou: 0.4906, conf: 0.0007), s/iter: 0.1055, lr: 3.0e-04
[2024-12-25 21:59:05,185] [INFO] Epoch [22/2695], Step [407/910], Loss: 5.6467 (poly: 0.0037, lower: 0.0000, upper: 0.0000, cls_loss: 0.0000, line_iou: 0.4306, conf: 0.0004), s/iter: 0.1055, lr: 3.0e-04
[2024-12-25 21:59:05,290] [INFO] Epoch [22/2695], Step [408/910], Loss: 5.6339 (poly: 0.0028, lower: 0.0000, upper: 0.0000, cls_loss: 0.0000, line_iou: 0.4412, conf: 0.0004), s/iter: 0.1053, lr: 3.0e-04
[2024-12-25 21:59:05,383] [INFO] Epoch [22/2695], Step [409/910], Loss: 5.6212 (poly: 0.0082, lower: 0.0000, upper: 0.0000, cls_loss: 0.0000, line_iou: 0.4320, conf: 0.0004), s/iter: 0.1051, lr: 3.0e-04
[2024-12-25 21:59:05,473] [INFO] Epoch [22/2695], Step [410/910], Loss: 5.6084 (poly: 0.0029, lower: 0.0000, upper: 0.0000, cls_loss: 0.0000, line_iou: 0.3490, conf: 0.0006), s/iter: 0.1050, lr: 3.0e-04
[2024-12-25 21:59:05,569] [INFO] Epoch [22/2695], Step [411/910], Loss: 5.5963 (poly: 0.1400, lower: 0.0000, upper: 0.0001, cls_loss: 0.0000, line_iou: 0.4885, conf: 0.0007), s/iter: 0.1048, lr: 3.0e-04
[2024-12-25 21:59:05,686] [INFO] Epoch [22/2695], Step [412/910], Loss: 5.5840 (poly: 0.0708, lower: 0.0000, upper: 0.0002, cls_loss: 0.0000, line_iou: 0.4882, conf: 0.0006), s/iter: 0.1048, lr: 3.0e-04
[2024-12-25 21:59:05,804] [INFO] Epoch [22/2695], Step [413/910], Loss: 5.5718 (poly: 0.0553, lower: 0.0000, upper: 0.0002, cls_loss: 0.0000, line_iou: 0.4797, conf: 0.0006), s/iter: 0.1051, lr: 3.0e-04
[2024-12-25 21:59:05,861] [INFO] Weight SoftAdapt Loss tensor([0.4967, 0.0017, 0.0017, 0.0017, 0.4967, 0.0017], dtype=torch.float64)
[2024-12-25 21:59:05,912] [INFO] Epoch [22/2695], Step [414/910], Loss: 5.5598 (poly: 0.0002, lower: 0.0000, upper: 0.0001, cls_loss: 0.0000, line_iou: 0.4967, conf: 0.1108), s/iter: 0.1052, lr: 3.0e-04
[2024-12-25 21:59:06,015] [INFO] Epoch [22/2695], Step [415/910], Loss: 5.5479 (poly: 0.0001, lower: 0.0000, upper: 0.0000, cls_loss: 0.0000, line_iou: 0.4236, conf: 0.1945), s/iter: 0.1052, lr: 3.0e-04
[2024-12-25 21:59:06,121] [INFO] Epoch [22/2695], Step [416/910], Loss: 5.5358 (poly: 0.0000, lower: 0.0000, upper: 0.0000, cls_loss: 0.0000, line_iou: 0.3835, conf: 0.1109), s/iter: 0.1049, lr: 3.0e-04
[2024-12-25 21:59:06,215] [INFO] Epoch [22/2695], Step [417/910], Loss: 5.5239 (poly: 0.0000, lower: 0.0000, upper: 0.0000, cls_loss: 0.0000, line_iou: 0.3870, conf: 0.1945), s/iter: 0.1049, lr: 3.0e-04
[2024-12-25 21:59:06,302] [INFO] Epoch [22/2695], Step [418/910], Loss: 5.5120 (poly: 0.0000, lower: 0.0000, upper: 0.0000, cls_loss: 0.0000, line_iou: 0.4481, conf: 0.1108), s/iter: 0.1046, lr: 3.0e-04
[2024-12-25 21:59:06,398] [INFO] Epoch [22/2695], Step [419/910], Loss: 5.5003 (poly: 0.0000, lower: 0.0000, upper: 0.0000, cls_loss: 0.0000, line_iou: 0.4767, conf: 0.1108), s/iter: 0.1044, lr: 3.0e-04
[2024-12-25 21:59:06,497] [INFO] Epoch [22/2695], Step [420/910], Loss: 5.4884 (poly: 0.0000, lower: 0.0000, upper: 0.0000, cls_loss: 0.0000, line_iou: 0.4226, conf: 0.1108), s/iter: 0.1043, lr: 3.0e-04
[2024-12-25 21:59:06,584] [INFO] Epoch [22/2695], Step [421/910], Loss: 5.4769 (poly: 0.0001, lower: 0.0000, upper: 0.0001, cls_loss: 0.0000, line_iou: 0.4331, conf: 0.1945), s/iter: 0.1039, lr: 3.0e-04
[2024-12-25 21:59:06,673] [INFO] Epoch [22/2695], Step [422/910], Loss: 5.4652 (poly: 0.0000, lower: 0.0000, upper: 0.0000, cls_loss: 0.0000, line_iou: 0.4569, conf: 0.1107), s/iter: 0.1035, lr: 3.0e-04
[2024-12-25 21:59:06,735] [INFO] Weight SoftAdapt Loss tensor([0.0017, 0.0017, 0.0017, 0.0017, 0.4967, 0.4967], dtype=torch.float64)
[2024-12-25 21:59:06,788] [INFO] Epoch [22/2695], Step [423/910], Loss: 5.4526 (poly: 0.0044, lower: 0.0000, upper: 0.0000, cls_loss: 0.0000, line_iou: 0.0014, conf: 0.1108), s/iter: 0.1035, lr: 3.0e-04
[2024-12-25 21:59:06,907] [INFO] Epoch [22/2695], Step [424/910], Loss: 5.4400 (poly: 0.0064, lower: 0.0000, upper: 0.0000, cls_loss: 0.0000, line_iou: 0.0015, conf: 0.1107), s/iter: 0.1037, lr: 3.0e-04
[2024-12-25 21:59:07,004] [INFO] Epoch [22/2695], Step [425/910], Loss: 5.4280 (poly: 0.1255, lower: 0.0000, upper: 0.0002, cls_loss: 0.0000, line_iou: 0.0017, conf: 0.2232), s/iter: 0.1036, lr: 3.0e-04
[2024-12-25 21:59:07,107] [INFO] Epoch [22/2695], Step [426/910], Loss: 5.4156 (poly: 0.0070, lower: 0.0000, upper: 0.0000, cls_loss: 0.0000, line_iou: 0.0014, conf: 0.1107), s/iter: 0.1033, lr: 3.0e-04
[2024-12-25 21:59:07,196] [INFO] Epoch [22/2695], Step [427/910], Loss: 5.4032 (poly: 0.0087, lower: 0.0000, upper: 0.0000, cls_loss: 0.0000, line_iou: 0.0016, conf: 0.1107), s/iter: 0.1032, lr: 3.0e-04
[2024-12-25 21:59:07,295] [INFO] Epoch [22/2695], Step [428/910], Loss: 5.3911 (poly: 0.0501, lower: 0.0000, upper: 0.0001, cls_loss: 0.0000, line_iou: 0.0016, conf: 0.1945), s/iter: 0.1033, lr: 3.0e-04
[2024-12-25 21:59:07,411] [INFO] Epoch [22/2695], Step [429/910], Loss: 5.3793 (poly: 0.0985, lower: 0.0000, upper: 0.0001, cls_loss: 0.0000, line_iou: 0.0015, conf: 0.2231), s/iter: 0.1033, lr: 3.0e-04
[2024-12-25 21:59:07,495] [INFO] Epoch [22/2695], Step [430/910], Loss: 5.3676 (poly: 0.1127, lower: 0.0000, upper: 0.0003, cls_loss: 0.0000, line_iou: 0.0016, conf: 0.2231), s/iter: 0.1030, lr: 3.0e-04
[2024-12-25 21:59:07,583] [INFO] Epoch [22/2695], Step [431/910], Loss: 5.3554 (poly: 0.0040, lower: 0.0000, upper: 0.0000, cls_loss: 0.0000, line_iou: 0.0014, conf: 0.1106), s/iter: 0.1027, lr: 3.0e-04
[2024-12-25 21:59:07,631] [INFO] Weight SoftAdapt Loss tensor([0.4967, 0.0017, 0.0017, 0.0017, 0.0017, 0.4967], dtype=torch.float64)
[2024-12-25 21:59:07,685] [INFO] Epoch [22/2695], Step [432/910], Loss: 5.3441 (poly: 0.0219, lower: 0.0000, upper: 0.0000, cls_loss: 0.0000, line_iou: 0.4542, conf: 0.0006), s/iter: 0.1026, lr: 3.0e-04
[2024-12-25 21:59:07,777] [INFO] Epoch [22/2695], Step [433/910], Loss: 5.3327 (poly: 0.0038, lower: 0.0000, upper: 0.0000, cls_loss: 0.0000, line_iou: 0.4098, conf: 0.0006), s/iter: 0.1023, lr: 3.0e-04
[2024-12-25 21:59:07,868] [INFO] Epoch [22/2695], Step [434/910], Loss: 5.3215 (poly: 0.0039, lower: 0.0000, upper: 0.0000, cls_loss: 0.0000, line_iou: 0.4361, conf: 0.0004), s/iter: 0.1022, lr: 3.0e-04
[2024-12-25 21:59:07,960] [INFO] Epoch [22/2695], Step [435/910], Loss: 5.3103 (poly: 0.0047, lower: 0.0000, upper: 0.0000, cls_loss: 0.0000, line_iou: 0.4496, conf: 0.0004), s/iter: 0.1019, lr: 3.0e-04
[2024-12-25 21:59:08,063] [INFO] Epoch [22/2695], Step [436/910], Loss: 5.2991 (poly: 0.0045, lower: 0.0000, upper: 0.0000, cls_loss: 0.0000, line_iou: 0.4352, conf: 0.0006), s/iter: 0.1016, lr: 3.0e-04
[2024-12-25 21:59:08,169] [INFO] Epoch [22/2695], Step [437/910], Loss: 5.2883 (poly: 0.1015, lower: 0.0000, upper: 0.0000, cls_loss: 0.0000, line_iou: 0.4595, conf: 0.0007), s/iter: 0.1014, lr: 3.0e-04
[2024-12-25 21:59:08,264] [INFO] Epoch [22/2695], Step [438/910], Loss: 5.2775 (poly: 0.1131, lower: 0.0000, upper: 0.0000, cls_loss: 0.0000, line_iou: 0.4571, conf: 0.0007), s/iter: 0.1012, lr: 3.0e-04
[2024-12-25 21:59:08,365] [INFO] Epoch [22/2695], Step [439/910], Loss: 5.2665 (poly: 0.0063, lower: 0.0000, upper: 0.0000, cls_loss: 0.0000, line_iou: 0.4296, conf: 0.0004), s/iter: 0.1010, lr: 3.0e-04
[2024-12-25 21:59:08,477] [INFO] Epoch [22/2695], Step [440/910], Loss: 5.2558 (poly: 0.1172, lower: 0.0000, upper: 0.0000, cls_loss: 0.0000, line_iou: 0.4530, conf: 0.0007), s/iter: 0.1010, lr: 3.0e-04
[2024-12-25 21:59:08,543] [INFO] Weight SoftAdapt Loss tensor([0.4967, 0.0017, 0.0017, 0.0017, 0.4967, 0.0017], dtype=torch.float64)
[2024-12-25 21:59:08,601] [INFO] Epoch [22/2695], Step [441/910], Loss: 5.2451 (poly: 0.0000, lower: 0.0000, upper: 0.0000, cls_loss: 0.0000, line_iou: 0.4462, conf: 0.1106), s/iter: 0.1009, lr: 3.0e-04
[2024-12-25 21:59:08,716] [INFO] Epoch [22/2695], Step [442/910], Loss: 5.2345 (poly: 0.0000, lower: 0.0000, upper: 0.0000, cls_loss: 0.0000, line_iou: 0.4335, conf: 0.1105), s/iter: 0.1007, lr: 3.0e-04
[2024-12-25 21:59:08,812] [INFO] Epoch [22/2695], Step [443/910], Loss: 5.2243 (poly: 0.0004, lower: 0.0000, upper: 0.0001, cls_loss: 0.0000, line_iou: 0.4808, conf: 0.2230), s/iter: 0.1004, lr: 3.0e-04
[2024-12-25 21:59:08,914] [INFO] Epoch [22/2695], Step [444/910], Loss: 5.2141 (poly: 0.0005, lower: 0.0000, upper: 0.0001, cls_loss: 0.0000, line_iou: 0.4870, conf: 0.2230), s/iter: 0.1001, lr: 3.0e-04
[2024-12-25 21:59:09,049] [INFO] Epoch [22/2695], Step [445/910], Loss: 5.2040 (poly: 0.0002, lower: 0.0000, upper: 0.0002, cls_loss: 0.0000, line_iou: 0.4872, conf: 0.2230), s/iter: 0.1003, lr: 3.0e-04
[2024-12-25 21:59:09,154] [INFO] Epoch [22/2695], Step [446/910], Loss: 5.1936 (poly: 0.0000, lower: 0.0000, upper: 0.0000, cls_loss: 0.0000, line_iou: 0.4593, conf: 0.1105), s/iter: 0.1002, lr: 3.0e-04
[2024-12-25 21:59:09,249] [INFO] Epoch [22/2695], Step [447/910], Loss: 5.1835 (poly: 0.0003, lower: 0.0000, upper: 0.0002, cls_loss: 0.0000, line_iou: 0.4878, conf: 0.1946), s/iter: 0.1002, lr: 3.0e-04
[2024-12-25 21:59:09,347] [INFO] Epoch [22/2695], Step [448/910], Loss: 5.1734 (poly: 0.0000, lower: 0.0000, upper: 0.0001, cls_loss: 0.0000, line_iou: 0.4428, conf: 0.1946), s/iter: 0.1001, lr: 3.0e-04
[2024-12-25 21:59:09,481] [INFO] Epoch [22/2695], Step [449/910], Loss: 5.1634 (poly: 0.0005, lower: 0.0000, upper: 0.0002, cls_loss: 0.0000, line_iou: 0.4923, conf: 0.2229), s/iter: 0.1004, lr: 3.0e-04
[2024-12-25 21:59:09,543] [INFO] Weight SoftAdapt Loss tensor([0.0017, 0.0017, 0.0017, 0.0017, 0.4967, 0.4967], dtype=torch.float64)
[2024-12-25 21:59:09,598] [INFO] Epoch [22/2695], Step [450/910], Loss: 5.1522 (poly: 0.0055, lower: 0.0000, upper: 0.0000, cls_loss: 0.0000, line_iou: 0.0015, conf: 0.1105), s/iter: 0.1004, lr: 3.0e-04
[2024-12-25 21:59:09,688] [INFO] Epoch [22/2695], Step [451/910], Loss: 5.1411 (poly: 0.0075, lower: 0.0000, upper: 0.0000, cls_loss: 0.0000, line_iou: 0.0015, conf: 0.1105), s/iter: 0.1003, lr: 3.0e-04
[2024-12-25 21:59:09,797] [INFO] Epoch [22/2695], Step [452/910], Loss: 5.1303 (poly: 0.0667, lower: 0.0000, upper: 0.0002, cls_loss: 0.0000, line_iou: 0.0016, conf: 0.1946), s/iter: 0.1001, lr: 3.0e-04
[2024-12-25 21:59:09,911] [INFO] Epoch [22/2695], Step [453/910], Loss: 5.1192 (poly: 0.0052, lower: 0.0000, upper: 0.0000, cls_loss: 0.0000, line_iou: 0.0015, conf: 0.1105), s/iter: 0.1000, lr: 3.0e-04
[2024-12-25 21:59:10,020] [INFO] Epoch [22/2695], Step [454/910], Loss: 5.1084 (poly: 0.0035, lower: 0.0000, upper: 0.0000, cls_loss: 0.0000, line_iou: 0.0014, conf: 0.1946), s/iter: 0.0999, lr: 3.0e-04
[2024-12-25 21:59:10,109] [INFO] Epoch [22/2695], Step [455/910], Loss: 5.0979 (poly: 0.1027, lower: 0.0000, upper: 0.0000, cls_loss: 0.0000, line_iou: 0.0015, conf: 0.2229), s/iter: 0.0998, lr: 3.0e-04
[2024-12-25 21:59:10,215] [INFO] Epoch [22/2695], Step [456/910], Loss: 5.0869 (poly: 0.0085, lower: 0.0000, upper: 0.0000, cls_loss: 0.0000, line_iou: 0.0015, conf: 0.1105), s/iter: 0.0999, lr: 3.0e-04
[2024-12-25 21:59:10,307] [INFO] Epoch [22/2695], Step [457/910], Loss: 5.0761 (poly: 0.0046, lower: 0.0000, upper: 0.0000, cls_loss: 0.0000, line_iou: 0.0014, conf: 0.1104), s/iter: 0.0998, lr: 3.0e-04
[2024-12-25 21:59:10,405] [INFO] Epoch [22/2695], Step [458/910], Loss: 5.0653 (poly: 0.0087, lower: 0.0000, upper: 0.0000, cls_loss: 0.0000, line_iou: 0.0015, conf: 0.1105), s/iter: 0.0998, lr: 3.0e-04
[2024-12-25 21:59:10,466] [INFO] Weight SoftAdapt Loss tensor([0.4967, 0.0017, 0.0017, 0.0017, 0.0017, 0.4967], dtype=torch.float64)
[2024-12-25 21:59:10,526] [INFO] Epoch [22/2695], Step [459/910], Loss: 5.0552 (poly: 0.0049, lower: 0.0000, upper: 0.0000, cls_loss: 0.0000, line_iou: 0.4337, conf: 0.0004), s/iter: 0.0997, lr: 3.0e-04
[2024-12-25 21:59:10,642] [INFO] Epoch [22/2695], Step [460/910], Loss: 5.0454 (poly: 0.1090, lower: 0.0000, upper: 0.0000, cls_loss: 0.0000, line_iou: 0.4356, conf: 0.0007), s/iter: 0.0995, lr: 3.0e-04
[2024-12-25 21:59:10,760] [INFO] Epoch [22/2695], Step [461/910], Loss: 5.0353 (poly: 0.0046, lower: 0.0000, upper: 0.0000, cls_loss: 0.0000, line_iou: 0.4123, conf: 0.0004), s/iter: 0.0996, lr: 3.0e-04
[2024-12-25 21:59:10,862] [INFO] Epoch [22/2695], Step [462/910], Loss: 5.0257 (poly: 0.0680, lower: 0.0000, upper: 0.0002, cls_loss: 0.0000, line_iou: 0.4967, conf: 0.0006), s/iter: 0.0995, lr: 3.0e-04
[2024-12-25 21:59:10,960] [INFO] Epoch [22/2695], Step [463/910], Loss: 5.0157 (poly: 0.0042, lower: 0.0000, upper: 0.0000, cls_loss: 0.0000, line_iou: 0.4316, conf: 0.0004), s/iter: 0.0995, lr: 3.0e-04
[2024-12-25 21:59:11,068] [INFO] Epoch [22/2695], Step [464/910], Loss: 5.0061 (poly: 0.1044, lower: 0.0000, upper: 0.0000, cls_loss: 0.0000, line_iou: 0.4448, conf: 0.0007), s/iter: 0.0994, lr: 3.0e-04
[2024-12-25 21:59:11,179] [INFO] Epoch [22/2695], Step [465/910], Loss: 4.9963 (poly: 0.0041, lower: 0.0000, upper: 0.0000, cls_loss: 0.0000, line_iou: 0.4171, conf: 0.0004), s/iter: 0.0992, lr: 3.0e-04
[2024-12-25 21:59:11,290] [INFO] Epoch [22/2695], Step [466/910], Loss: 4.9865 (poly: 0.0058, lower: 0.0000, upper: 0.0000, cls_loss: 0.0000, line_iou: 0.4349, conf: 0.0004), s/iter: 0.0991, lr: 3.0e-04
[2024-12-25 21:59:11,390] [INFO] Epoch [22/2695], Step [467/910], Loss: 4.9768 (poly: 0.0077, lower: 0.0000, upper: 0.0000, cls_loss: 0.0000, line_iou: 0.4433, conf: 0.0004), s/iter: 0.0992, lr: 3.0e-04
[2024-12-25 21:59:11,446] [INFO] Weight SoftAdapt Loss tensor([0.4967, 0.0017, 0.0017, 0.0017, 0.4967, 0.0017], dtype=torch.float64)
[2024-12-25 21:59:11,496] [INFO] Epoch [22/2695], Step [468/910], Loss: 4.9672 (poly: 0.0000, lower: 0.0000, upper: 0.0000, cls_loss: 0.0000, line_iou: 0.4091, conf: 0.1104), s/iter: 0.0993, lr: 3.0e-04
[2024-12-25 21:59:11,602] [INFO] Epoch [22/2695], Step [469/910], Loss: 4.9580 (poly: 0.0003, lower: 0.0000, upper: 0.0000, cls_loss: 0.0000, line_iou: 0.4295, conf: 0.2229), s/iter: 0.0992, lr: 3.0e-04
[2024-12-25 21:59:11,702] [INFO] Epoch [22/2695], Step [470/910], Loss: 4.9486 (poly: 0.0000, lower: 0.0000, upper: 0.0000, cls_loss: 0.0000, line_iou: 0.4263, conf: 0.1104), s/iter: 0.0992, lr: 3.0e-04
[2024-12-25 21:59:11,817] [INFO] Epoch [22/2695], Step [471/910], Loss: 4.9392 (poly: 0.0000, lower: 0.0000, upper: 0.0000, cls_loss: 0.0000, line_iou: 0.4023, conf: 0.1103), s/iter: 0.0994, lr: 3.0e-04
[2024-12-25 21:59:11,927] [INFO] Epoch [22/2695], Step [472/910], Loss: 4.9303 (poly: 0.0004, lower: 0.0000, upper: 0.0001, cls_loss: 0.0000, line_iou: 0.4917, conf: 0.2228), s/iter: 0.0994, lr: 3.0e-04
[2024-12-25 21:59:12,036] [INFO] Epoch [22/2695], Step [473/910], Loss: 4.9209 (poly: 0.0000, lower: 0.0000, upper: 0.0000, cls_loss: 0.0000, line_iou: 0.3837, conf: 0.1103), s/iter: 0.0995, lr: 3.0e-04
[2024-12-25 21:59:12,132] [INFO] Epoch [22/2695], Step [474/910], Loss: 4.9119 (poly: 0.0003, lower: 0.0000, upper: 0.0000, cls_loss: 0.0000, line_iou: 0.4230, conf: 0.2227), s/iter: 0.0996, lr: 3.0e-04
[2024-12-25 21:59:12,245] [INFO] Epoch [22/2695], Step [475/910], Loss: 4.9026 (poly: 0.0000, lower: 0.0000, upper: 0.0000, cls_loss: 0.0000, line_iou: 0.3854, conf: 0.1103), s/iter: 0.0997, lr: 3.0e-04
[2024-12-25 21:59:12,343] [INFO] Epoch [22/2695], Step [476/910], Loss: 4.8938 (poly: 0.0004, lower: 0.0000, upper: 0.0002, cls_loss: 0.0000, line_iou: 0.4891, conf: 0.2227), s/iter: 0.0995, lr: 3.0e-04
[2024-12-25 21:59:12,416] [INFO] Weight SoftAdapt Loss tensor([0.0017, 0.0017, 0.0017, 0.0017, 0.4967, 0.4967], dtype=torch.float64)
[2024-12-25 21:59:12,475] [INFO] Epoch [22/2695], Step [477/910], Loss: 4.8839 (poly: 0.0084, lower: 0.0000, upper: 0.0000, cls_loss: 0.0000, line_iou: 0.0013, conf: 0.1946), s/iter: 0.0999, lr: 3.0e-04
[2024-12-25 21:59:12,574] [INFO] Epoch [22/2695], Step [478/910], Loss: 4.8740 (poly: 0.0034, lower: 0.0000, upper: 0.0000, cls_loss: 0.0000, line_iou: 0.0013, conf: 0.1102), s/iter: 0.0999, lr: 3.0e-04
[2024-12-25 21:59:12,663] [INFO] Epoch [22/2695], Step [479/910], Loss: 4.8640 (poly: 0.0057, lower: 0.0000, upper: 0.0000, cls_loss: 0.0000, line_iou: 0.0014, conf: 0.1102), s/iter: 0.0998, lr: 3.0e-04
[2024-12-25 21:59:12,784] [INFO] Epoch [22/2695], Step [480/910], Loss: 4.8542 (poly: 0.0128, lower: 0.0000, upper: 0.0000, cls_loss: 0.0000, line_iou: 0.0015, conf: 0.1103), s/iter: 0.0999, lr: 3.0e-04
[2024-12-25 21:59:12,888] [INFO] Epoch [22/2695], Step [481/910], Loss: 4.8443 (poly: 0.0031, lower: 0.0000, upper: 0.0000, cls_loss: 0.0000, line_iou: 0.0014, conf: 0.1103), s/iter: 0.0999, lr: 3.0e-04
[2024-12-25 21:59:12,983] [INFO] Epoch [22/2695], Step [482/910], Loss: 4.8349 (poly: 0.1065, lower: 0.0000, upper: 0.0000, cls_loss: 0.0000, line_iou: 0.0013, conf: 0.2225), s/iter: 0.0999, lr: 3.0e-04
[2024-12-25 21:59:13,078] [INFO] Epoch [22/2695], Step [483/910], Loss: 4.8253 (poly: 0.0034, lower: 0.0000, upper: 0.0000, cls_loss: 0.0000, line_iou: 0.0013, conf: 0.1947), s/iter: 0.0997, lr: 3.0e-04
[2024-12-25 21:59:13,185] [INFO] Epoch [22/2695], Step [484/910], Loss: 4.8161 (poly: 0.1175, lower: 0.0000, upper: 0.0000, cls_loss: 0.0000, line_iou: 0.0013, conf: 0.2225), s/iter: 0.0999, lr: 3.0e-04
[2024-12-25 21:59:13,275] [INFO] Epoch [22/2695], Step [485/910], Loss: 4.8066 (poly: 0.0023, lower: 0.0000, upper: 0.0000, cls_loss: 0.0000, line_iou: 0.0012, conf: 0.1947), s/iter: 0.0998, lr: 3.0e-04
[2024-12-25 21:59:13,340] [INFO] Weight SoftAdapt Loss tensor([0.4967, 0.0017, 0.0017, 0.0017, 0.0017, 0.4967], dtype=torch.float64)
[2024-12-25 21:59:13,389] [INFO] Epoch [22/2695], Step [486/910], Loss: 4.7975 (poly: 0.0024, lower: 0.0000, upper: 0.0000, cls_loss: 0.0000, line_iou: 0.3872, conf: 0.0004), s/iter: 0.0997, lr: 3.0e-04
[2024-12-25 21:59:13,501] [INFO] Epoch [22/2695], Step [487/910], Loss: 4.7883 (poly: 0.0020, lower: 0.0000, upper: 0.0000, cls_loss: 0.0000, line_iou: 0.3394, conf: 0.0006), s/iter: 0.0998, lr: 3.0e-04
[2024-12-25 21:59:13,612] [INFO] Epoch [22/2695], Step [488/910], Loss: 4.7794 (poly: 0.0037, lower: 0.0000, upper: 0.0000, cls_loss: 0.0000, line_iou: 0.4254, conf: 0.0004), s/iter: 0.1000, lr: 3.0e-04
[2024-12-25 21:59:13,700] [INFO] Epoch [22/2695], Step [489/910], Loss: 4.7706 (poly: 0.0426, lower: 0.0000, upper: 0.0001, cls_loss: 0.0000, line_iou: 0.4576, conf: 0.0006), s/iter: 0.0998, lr: 3.0e-04
[2024-12-25 21:59:13,808] [INFO] Epoch [22/2695], Step [490/910], Loss: 4.7620 (poly: 0.0909, lower: 0.0000, upper: 0.0001, cls_loss: 0.0000, line_iou: 0.4365, conf: 0.0007), s/iter: 0.0998, lr: 3.0e-04
[2024-12-25 21:59:13,916] [INFO] Epoch [22/2695], Step [491/910], Loss: 4.7531 (poly: 0.0075, lower: 0.0000, upper: 0.0000, cls_loss: 0.0000, line_iou: 0.4045, conf: 0.0004), s/iter: 0.0998, lr: 3.0e-04
[2024-12-25 21:59:14,037] [INFO] Epoch [22/2695], Step [492/910], Loss: 4.7444 (poly: 0.0187, lower: 0.0000, upper: 0.0001, cls_loss: 0.0000, line_iou: 0.4322, conf: 0.0004), s/iter: 0.0998, lr: 3.0e-04
[2024-12-25 21:59:14,136] [INFO] Epoch [22/2695], Step [493/910], Loss: 4.7356 (poly: 0.0060, lower: 0.0000, upper: 0.0000, cls_loss: 0.0000, line_iou: 0.4112, conf: 0.0006), s/iter: 0.0997, lr: 3.0e-04
[2024-12-25 21:59:14,240] [INFO] Epoch [22/2695], Step [494/910], Loss: 4.7269 (poly: 0.0042, lower: 0.0000, upper: 0.0000, cls_loss: 0.0000, line_iou: 0.4416, conf: 0.0004), s/iter: 0.0996, lr: 3.0e-04
[2024-12-25 21:59:14,292] [INFO] Weight SoftAdapt Loss tensor([0.4967, 0.0017, 0.0017, 0.0017, 0.4967, 0.0017], dtype=torch.float64)
[2024-12-25 21:59:14,349] [INFO] Epoch [22/2695], Step [495/910], Loss: 4.7188 (poly: 0.0004, lower: 0.0000, upper: 0.0001, cls_loss: 0.0000, line_iou: 0.4782, conf: 0.2223), s/iter: 0.0997, lr: 3.0e-04
[2024-12-25 21:59:14,460] [INFO] Epoch [22/2695], Step [496/910], Loss: 4.7103 (poly: 0.0000, lower: 0.0000, upper: 0.0000, cls_loss: 0.0000, line_iou: 0.4125, conf: 0.1101), s/iter: 0.0999, lr: 3.0e-04
[2024-12-25 21:59:14,556] [INFO] Epoch [22/2695], Step [497/910], Loss: 4.7021 (poly: 0.0000, lower: 0.0000, upper: 0.0000, cls_loss: 0.0000, line_iou: 0.4115, conf: 0.1946), s/iter: 0.0998, lr: 3.0e-04
[2024-12-25 21:59:14,638] [INFO] Epoch [22/2695], Step [498/910], Loss: 4.6939 (poly: 0.0004, lower: 0.0000, upper: 0.0000, cls_loss: 0.0000, line_iou: 0.4020, conf: 0.2224), s/iter: 0.0996, lr: 3.0e-04
[2024-12-25 21:59:14,739] [INFO] Epoch [22/2695], Step [499/910], Loss: 4.6856 (poly: 0.0000, lower: 0.0000, upper: 0.0000, cls_loss: 0.0000, line_iou: 0.3581, conf: 0.1946), s/iter: 0.0995, lr: 3.0e-04
[2024-12-25 21:59:14,828] [INFO] Epoch [22/2695], Step [500/910], Loss: 4.6773 (poly: 0.0000, lower: 0.0000, upper: 0.0000, cls_loss: 0.0000, line_iou: 0.4214, conf: 0.1101), s/iter: 0.0994, lr: 3.0e-04
[2024-12-25 21:59:14,937] [INFO] Epoch [22/2695], Step [501/910], Loss: 4.6690 (poly: 0.0000, lower: 0.0000, upper: 0.0000, cls_loss: 0.0000, line_iou: 0.4345, conf: 0.1101), s/iter: 0.0996, lr: 3.0e-04
[2024-12-25 21:59:15,026] [INFO] Epoch [22/2695], Step [502/910], Loss: 4.6608 (poly: 0.0000, lower: 0.0000, upper: 0.0000, cls_loss: 0.0000, line_iou: 0.4321, conf: 0.1101), s/iter: 0.0993, lr: 3.0e-04
[2024-12-25 21:59:15,124] [INFO] Epoch [22/2695], Step [503/910], Loss: 4.6526 (poly: 0.0000, lower: 0.0000, upper: 0.0000, cls_loss: 0.0000, line_iou: 0.4384, conf: 0.1101), s/iter: 0.0992, lr: 3.0e-04
[2024-12-25 21:59:15,170] [INFO] Weight SoftAdapt Loss tensor([0.0017, 0.0017, 0.0017, 0.0017, 0.4967, 0.4967], dtype=torch.float64)
[2024-12-25 21:59:15,220] [INFO] Epoch [22/2695], Step [504/910], Loss: 4.6441 (poly: 0.1298, lower: 0.0000, upper: 0.0000, cls_loss: 0.0000, line_iou: 0.0016, conf: 0.2224), s/iter: 0.0993, lr: 3.0e-04
[2024-12-25 21:59:15,311] [INFO] Epoch [22/2695], Step [505/910], Loss: 4.6351 (poly: 0.0069, lower: 0.0000, upper: 0.0000, cls_loss: 0.0000, line_iou: 0.0013, conf: 0.1100), s/iter: 0.0990, lr: 3.0e-04
[2024-12-25 21:59:15,402] [INFO] Epoch [22/2695], Step [506/910], Loss: 4.6266 (poly: 0.1127, lower: 0.0000, upper: 0.0002, cls_loss: 0.0000, line_iou: 0.0017, conf: 0.2223), s/iter: 0.0988, lr: 3.0e-04
[2024-12-25 21:59:15,505] [INFO] Epoch [22/2695], Step [507/910], Loss: 4.6178 (poly: 0.0082, lower: 0.0000, upper: 0.0000, cls_loss: 0.0000, line_iou: 0.0015, conf: 0.1100), s/iter: 0.0987, lr: 3.0e-04
[2024-12-25 21:59:15,610] [INFO] Epoch [22/2695], Step [508/910], Loss: 4.6089 (poly: 0.0066, lower: 0.0000, upper: 0.0000, cls_loss: 0.0000, line_iou: 0.0015, conf: 0.1100), s/iter: 0.0987, lr: 3.0e-04
[2024-12-25 21:59:15,718] [INFO] Epoch [22/2695], Step [509/910], Loss: 4.6001 (poly: 0.0113, lower: 0.0000, upper: 0.0000, cls_loss: 0.0000, line_iou: 0.0016, conf: 0.1100), s/iter: 0.0989, lr: 3.0e-04
[2024-12-25 21:59:15,824] [INFO] Epoch [22/2695], Step [510/910], Loss: 4.5913 (poly: 0.0063, lower: 0.0000, upper: 0.0000, cls_loss: 0.0000, line_iou: 0.0014, conf: 0.1099), s/iter: 0.0990, lr: 3.0e-04
[2024-12-25 21:59:15,947] [INFO] Epoch [22/2695], Step [511/910], Loss: 4.5825 (poly: 0.0052, lower: 0.0000, upper: 0.0000, cls_loss: 0.0000, line_iou: 0.0013, conf: 0.1099), s/iter: 0.0993, lr: 3.0e-04
[2024-12-25 21:59:16,027] [INFO] Epoch [22/2695], Step [512/910], Loss: 4.5743 (poly: 0.1233, lower: 0.0000, upper: 0.0002, cls_loss: 0.0000, line_iou: 0.0016, conf: 0.2222), s/iter: 0.0990, lr: 3.0e-04
[2024-12-25 21:59:16,079] [INFO] Weight SoftAdapt Loss tensor([0.4967, 0.0017, 0.0017, 0.0017, 0.0017, 0.4967], dtype=torch.float64)
[2024-12-25 21:59:16,129] [INFO] Epoch [22/2695], Step [513/910], Loss: 4.5662 (poly: 0.0024, lower: 0.0000, upper: 0.0000, cls_loss: 0.0000, line_iou: 0.4167, conf: 0.0004), s/iter: 0.0988, lr: 3.0e-04
[2024-12-25 21:59:16,251] [INFO] Epoch [22/2695], Step [514/910], Loss: 4.5581 (poly: 0.0033, lower: 0.0000, upper: 0.0000, cls_loss: 0.0000, line_iou: 0.4237, conf: 0.0004), s/iter: 0.0989, lr: 3.0e-04
[2024-12-25 21:59:16,361] [INFO] Epoch [22/2695], Step [515/910], Loss: 4.5505 (poly: 0.1547, lower: 0.0000, upper: 0.0001, cls_loss: 0.0000, line_iou: 0.4920, conf: 0.0007), s/iter: 0.0990, lr: 3.0e-04
[2024-12-25 21:59:16,500] [INFO] Epoch [22/2695], Step [516/910], Loss: 4.5427 (poly: 0.1086, lower: 0.0000, upper: 0.0000, cls_loss: 0.0000, line_iou: 0.4279, conf: 0.0007), s/iter: 0.0993, lr: 3.0e-04
[2024-12-25 21:59:16,601] [INFO] Epoch [22/2695], Step [517/910], Loss: 4.5348 (poly: 0.0047, lower: 0.0000, upper: 0.0000, cls_loss: 0.0000, line_iou: 0.4321, conf: 0.0004), s/iter: 0.0994, lr: 3.0e-04
[2024-12-25 21:59:16,703] [INFO] Epoch [22/2695], Step [518/910], Loss: 4.5273 (poly: 0.1508, lower: 0.0000, upper: 0.0001, cls_loss: 0.0000, line_iou: 0.4878, conf: 0.0007), s/iter: 0.0996, lr: 3.0e-04
[2024-12-25 21:59:16,825] [INFO] Epoch [22/2695], Step [519/910], Loss: 4.5194 (poly: 0.0026, lower: 0.0000, upper: 0.0000, cls_loss: 0.0000, line_iou: 0.4058, conf: 0.0004), s/iter: 0.0998, lr: 3.0e-04
[2024-12-25 21:59:16,921] [INFO] Epoch [22/2695], Step [520/910], Loss: 4.5114 (poly: 0.0025, lower: 0.0000, upper: 0.0000, cls_loss: 0.0000, line_iou: 0.3973, conf: 0.0004), s/iter: 0.0998, lr: 3.0e-04
[2024-12-25 21:59:17,035] [INFO] Epoch [22/2695], Step [521/910], Loss: 4.5035 (poly: 0.0033, lower: 0.0000, upper: 0.0000, cls_loss: 0.0000, line_iou: 0.3900, conf: 0.0004), s/iter: 0.1000, lr: 3.0e-04
[2024-12-25 21:59:17,087] [INFO] Weight SoftAdapt Loss tensor([0.4967, 0.0017, 0.0017, 0.0017, 0.4967, 0.0017], dtype=torch.float64)
[2024-12-25 21:59:17,138] [INFO] Epoch [22/2695], Step [522/910], Loss: 4.4960 (poly: 0.0000, lower: 0.0000, upper: 0.0000, cls_loss: 0.0000, line_iou: 0.3624, conf: 0.1947), s/iter: 0.1002, lr: 3.0e-04
[2024-12-25 21:59:17,242] [INFO] Epoch [22/2695], Step [523/910], Loss: 4.4883 (poly: 0.0000, lower: 0.0000, upper: 0.0000, cls_loss: 0.0000, line_iou: 0.3971, conf: 0.1098), s/iter: 0.1000, lr: 3.0e-04
[2024-12-25 21:59:17,354] [INFO] Epoch [22/2695], Step [524/910], Loss: 4.4811 (poly: 0.0004, lower: 0.0000, upper: 0.0001, cls_loss: 0.0000, line_iou: 0.4958, conf: 0.2221), s/iter: 0.1000, lr: 3.0e-04
[2024-12-25 21:59:17,455] [INFO] Epoch [22/2695], Step [525/910], Loss: 4.4736 (poly: 0.0000, lower: 0.0000, upper: 0.0000, cls_loss: 0.0000, line_iou: 0.4106, conf: 0.1098), s/iter: 0.1000, lr: 3.0e-04
[2024-12-25 21:59:17,562] [INFO] Epoch [22/2695], Step [526/910], Loss: 4.4661 (poly: 0.0000, lower: 0.0000, upper: 0.0000, cls_loss: 0.0000, line_iou: 0.4342, conf: 0.1098), s/iter: 0.1000, lr: 3.0e-04
[2024-12-25 21:59:17,674] [INFO] Epoch [22/2695], Step [527/910], Loss: 4.4586 (poly: 0.0000, lower: 0.0000, upper: 0.0000, cls_loss: 0.0000, line_iou: 0.3872, conf: 0.1098), s/iter: 0.1003, lr: 3.0e-04
[2024-12-25 21:59:17,782] [INFO] Epoch [22/2695], Step [528/910], Loss: 4.4511 (poly: 0.0000, lower: 0.0000, upper: 0.0000, cls_loss: 0.0000, line_iou: 0.3973, conf: 0.1098), s/iter: 0.1003, lr: 3.0e-04
[2024-12-25 21:59:17,886] [INFO] Epoch [22/2695], Step [529/910], Loss: 4.4437 (poly: 0.0000, lower: 0.0000, upper: 0.0000, cls_loss: 0.0000, line_iou: 0.4181, conf: 0.1097), s/iter: 0.1002, lr: 3.0e-04
[2024-12-25 21:59:17,980] [INFO] Epoch [22/2695], Step [530/910], Loss: 4.4366 (poly: 0.0002, lower: 0.0000, upper: 0.0002, cls_loss: 0.0000, line_iou: 0.4733, conf: 0.1947), s/iter: 0.1003, lr: 3.0e-04
[2024-12-25 21:59:18,042] [INFO] Weight SoftAdapt Loss tensor([0.0017, 0.0017, 0.0017, 0.0017, 0.4967, 0.4967], dtype=torch.float64)
[2024-12-25 21:59:18,096] [INFO] Epoch [22/2695], Step [531/910], Loss: 4.4284 (poly: 0.0026, lower: 0.0000, upper: 0.0000, cls_loss: 0.0000, line_iou: 0.0013, conf: 0.1098), s/iter: 0.1006, lr: 3.0e-04
[2024-12-25 21:59:18,213] [INFO] Epoch [22/2695], Step [532/910], Loss: 4.4203 (poly: 0.0029, lower: 0.0000, upper: 0.0000, cls_loss: 0.0000, line_iou: 0.0013, conf: 0.1097), s/iter: 0.1007, lr: 3.0e-04
[2024-12-25 21:59:18,319] [INFO] Epoch [22/2695], Step [533/910], Loss: 4.4122 (poly: 0.0050, lower: 0.0000, upper: 0.0000, cls_loss: 0.0000, line_iou: 0.0014, conf: 0.1097), s/iter: 0.1009, lr: 3.0e-04
[2024-12-25 21:59:18,430] [INFO] Epoch [22/2695], Step [534/910], Loss: 4.4042 (poly: 0.0028, lower: 0.0000, upper: 0.0000, cls_loss: 0.0000, line_iou: 0.0013, conf: 0.1097), s/iter: 0.1011, lr: 3.0e-04
[2024-12-25 21:59:18,534] [INFO] Epoch [22/2695], Step [535/910], Loss: 4.3966 (poly: 0.1284, lower: 0.0000, upper: 0.0001, cls_loss: 0.0000, line_iou: 0.0016, conf: 0.2220), s/iter: 0.1012, lr: 3.0e-04
[2024-12-25 21:59:18,648] [INFO] Epoch [22/2695], Step [536/910], Loss: 4.3886 (poly: 0.0037, lower: 0.0000, upper: 0.0000, cls_loss: 0.0000, line_iou: 0.0012, conf: 0.1097), s/iter: 0.1013, lr: 3.0e-04
[2024-12-25 21:59:18,750] [INFO] Epoch [22/2695], Step [537/910], Loss: 4.3807 (poly: 0.0050, lower: 0.0000, upper: 0.0000, cls_loss: 0.0000, line_iou: 0.0014, conf: 0.1096), s/iter: 0.1013, lr: 3.0e-04
[2024-12-25 21:59:18,858] [INFO] Epoch [22/2695], Step [538/910], Loss: 4.3728 (poly: 0.0038, lower: 0.0000, upper: 0.0000, cls_loss: 0.0000, line_iou: 0.0014, conf: 0.1096), s/iter: 0.1014, lr: 3.0e-04
[2024-12-25 21:59:18,969] [INFO] Epoch [22/2695], Step [539/910], Loss: 4.3651 (poly: 0.0727, lower: 0.0000, upper: 0.0002, cls_loss: 0.0000, line_iou: 0.0016, conf: 0.1948), s/iter: 0.1015, lr: 3.0e-04
[2024-12-25 21:59:19,031] [INFO] Weight SoftAdapt Loss tensor([0.4967, 0.0017, 0.0017, 0.0017, 0.0017, 0.4967], dtype=torch.float64)
[2024-12-25 21:59:19,088] [INFO] Epoch [22/2695], Step [540/910], Loss: 4.3579 (poly: 0.0038, lower: 0.0000, upper: 0.0000, cls_loss: 0.0000, line_iou: 0.4372, conf: 0.0004), s/iter: 0.1016, lr: 3.0e-04
[2024-12-25 21:59:19,175] [INFO] Epoch [22/2695], Step [541/910], Loss: 4.3509 (poly: 0.1230, lower: 0.0000, upper: 0.0000, cls_loss: 0.0000, line_iou: 0.4516, conf: 0.0007), s/iter: 0.1012, lr: 3.0e-04
[2024-12-25 21:59:19,279] [INFO] Epoch [22/2695], Step [542/910], Loss: 4.3438 (poly: 0.0168, lower: 0.0000, upper: 0.0002, cls_loss: 0.0000, line_iou: 0.4817, conf: 0.0004), s/iter: 0.1011, lr: 3.0e-04
[2024-12-25 21:59:19,372] [INFO] Epoch [22/2695], Step [543/910], Loss: 4.3369 (poly: 0.1325, lower: 0.0000, upper: 0.0000, cls_loss: 0.0000, line_iou: 0.4900, conf: 0.0007), s/iter: 0.1011, lr: 3.0e-04
[2024-12-25 21:59:19,465] [INFO] Epoch [22/2695], Step [544/910], Loss: 4.3298 (poly: 0.0045, lower: 0.0000, upper: 0.0000, cls_loss: 0.0000, line_iou: 0.4441, conf: 0.0004), s/iter: 0.1010, lr: 3.0e-04
[2024-12-25 21:59:19,573] [INFO] Epoch [22/2695], Step [545/910], Loss: 4.3228 (poly: 0.0974, lower: 0.0000, upper: 0.0000, cls_loss: 0.0000, line_iou: 0.4338, conf: 0.0007), s/iter: 0.1008, lr: 3.0e-04
[2024-12-25 21:59:19,664] [INFO] Epoch [22/2695], Step [546/910], Loss: 4.3157 (poly: 0.0044, lower: 0.0000, upper: 0.0000, cls_loss: 0.0000, line_iou: 0.4448, conf: 0.0004), s/iter: 0.1006, lr: 3.0e-04
[2024-12-25 21:59:19,776] [INFO] Epoch [22/2695], Step [547/910], Loss: 4.3085 (poly: 0.0055, lower: 0.0000, upper: 0.0000, cls_loss: 0.0000, line_iou: 0.3786, conf: 0.0006), s/iter: 0.1008, lr: 3.0e-04
[2024-12-25 21:59:19,896] [INFO] Epoch [22/2695], Step [548/910], Loss: 4.3014 (poly: 0.0048, lower: 0.0000, upper: 0.0000, cls_loss: 0.0000, line_iou: 0.4219, conf: 0.0004), s/iter: 0.1010, lr: 3.0e-04
[2024-12-25 21:59:19,953] [INFO] Weight SoftAdapt Loss tensor([0.4967, 0.0017, 0.0017, 0.0017, 0.4967, 0.0017], dtype=torch.float64)
[2024-12-25 21:59:20,026] [INFO] Epoch [22/2695], Step [549/910], Loss: 4.2948 (poly: 0.0003, lower: 0.0000, upper: 0.0000, cls_loss: 0.0000, line_iou: 0.4276, conf: 0.2219), s/iter: 0.1009, lr: 3.0e-04
[2024-12-25 21:59:20,141] [INFO] Epoch [22/2695], Step [550/910], Loss: 4.2879 (poly: 0.0000, lower: 0.0000, upper: 0.0000, cls_loss: 0.0000, line_iou: 0.4036, conf: 0.1095), s/iter: 0.1009, lr: 3.0e-04
[2024-12-25 21:59:20,257] [INFO] Epoch [22/2695], Step [551/910], Loss: 4.2813 (poly: 0.0003, lower: 0.0000, upper: 0.0000, cls_loss: 0.0000, line_iou: 0.4295, conf: 0.2218), s/iter: 0.1011, lr: 3.0e-04
[2024-12-25 21:59:20,372] [INFO] Epoch [22/2695], Step [552/910], Loss: 4.2746 (poly: 0.0000, lower: 0.0000, upper: 0.0000, cls_loss: 0.0000, line_iou: 0.3949, conf: 0.1948), s/iter: 0.1012, lr: 3.0e-04
[2024-12-25 21:59:20,474] [INFO] Epoch [22/2695], Step [553/910], Loss: 4.2678 (poly: 0.0000, lower: 0.0000, upper: 0.0000, cls_loss: 0.0000, line_iou: 0.4071, conf: 0.1095), s/iter: 0.1011, lr: 3.0e-04
[2024-12-25 21:59:20,572] [INFO] Epoch [22/2695], Step [554/910], Loss: 4.2613 (poly: 0.0003, lower: 0.0000, upper: 0.0001, cls_loss: 0.0000, line_iou: 0.4503, conf: 0.2219), s/iter: 0.1010, lr: 3.0e-04
[2024-12-25 21:59:20,671] [INFO] Epoch [22/2695], Step [555/910], Loss: 4.2549 (poly: 0.0004, lower: 0.0000, upper: 0.0001, cls_loss: 0.0000, line_iou: 0.4880, conf: 0.2218), s/iter: 0.1011, lr: 3.0e-04
[2024-12-25 21:59:20,779] [INFO] Epoch [22/2695], Step [556/910], Loss: 4.2481 (poly: 0.0000, lower: 0.0000, upper: 0.0000, cls_loss: 0.0000, line_iou: 0.3625, conf: 0.1094), s/iter: 0.1011, lr: 3.0e-04
[2024-12-25 21:59:20,885] [INFO] Epoch [22/2695], Step [557/910], Loss: 4.2415 (poly: 0.0000, lower: 0.0000, upper: 0.0000, cls_loss: 0.0000, line_iou: 0.4200, conf: 0.1094), s/iter: 0.1012, lr: 3.0e-04
[2024-12-25 21:59:20,941] [INFO] Weight SoftAdapt Loss tensor([0.0017, 0.0017, 0.0017, 0.0017, 0.4967, 0.4967], dtype=torch.float64)
[2024-12-25 21:59:21,004] [INFO] Epoch [22/2695], Step [558/910], Loss: 4.2345 (poly: 0.1264, lower: 0.0000, upper: 0.0001, cls_loss: 0.0000, line_iou: 0.0016, conf: 0.2218), s/iter: 0.1014, lr: 3.0e-04
[2024-12-25 21:59:21,100] [INFO] Epoch [22/2695], Step [559/910], Loss: 4.2271 (poly: 0.0024, lower: 0.0000, upper: 0.0000, cls_loss: 0.0000, line_iou: 0.0014, conf: 0.1094), s/iter: 0.1012, lr: 3.0e-04
[2024-12-25 21:59:21,216] [INFO] Epoch [22/2695], Step [560/910], Loss: 4.2198 (poly: 0.0035, lower: 0.0000, upper: 0.0000, cls_loss: 0.0000, line_iou: 0.0014, conf: 0.1094), s/iter: 0.1012, lr: 3.0e-04
[2024-12-25 21:59:21,336] [INFO] Epoch [22/2695], Step [561/910], Loss: 4.2129 (poly: 0.1240, lower: 0.0000, upper: 0.0001, cls_loss: 0.0000, line_iou: 0.0016, conf: 0.2218), s/iter: 0.1012, lr: 3.0e-04
[2024-12-25 21:59:21,429] [INFO] Epoch [22/2695], Step [562/910], Loss: 4.2056 (poly: 0.0066, lower: 0.0000, upper: 0.0000, cls_loss: 0.0000, line_iou: 0.0014, conf: 0.1094), s/iter: 0.1011, lr: 3.0e-04
[2024-12-25 21:59:21,534] [INFO] Epoch [22/2695], Step [563/910], Loss: 4.1987 (poly: 0.1216, lower: 0.0000, upper: 0.0001, cls_loss: 0.0000, line_iou: 0.0016, conf: 0.2216), s/iter: 0.1012, lr: 3.0e-04
[2024-12-25 21:59:21,637] [INFO] Epoch [22/2695], Step [564/910], Loss: 4.1915 (poly: 0.0263, lower: 0.0000, upper: 0.0001, cls_loss: 0.0000, line_iou: 0.0016, conf: 0.1093), s/iter: 0.1011, lr: 3.0e-04
[2024-12-25 21:59:21,735] [INFO] Epoch [22/2695], Step [565/910], Loss: 4.1843 (poly: 0.0064, lower: 0.0000, upper: 0.0000, cls_loss: 0.0000, line_iou: 0.0014, conf: 0.1093), s/iter: 0.1010, lr: 3.0e-04
[2024-12-25 21:59:21,833] [INFO] Epoch [22/2695], Step [566/910], Loss: 4.1773 (poly: 0.0039, lower: 0.0000, upper: 0.0000, cls_loss: 0.0000, line_iou: 0.0014, conf: 0.1949), s/iter: 0.1009, lr: 3.0e-04
[2024-12-25 21:59:21,892] [INFO] Weight SoftAdapt Loss tensor([0.4967, 0.0017, 0.0017, 0.0017, 0.0017, 0.4967], dtype=torch.float64)
[2024-12-25 21:59:21,959] [INFO] Epoch [22/2695], Step [567/910], Loss: 4.1707 (poly: 0.0077, lower: 0.0000, upper: 0.0000, cls_loss: 0.0000, line_iou: 0.4405, conf: 0.0004), s/iter: 0.1011, lr: 3.0e-04
[2024-12-25 21:59:22,088] [INFO] Epoch [22/2695], Step [568/910], Loss: 4.1642 (poly: 0.0079, lower: 0.0000, upper: 0.0000, cls_loss: 0.0000, line_iou: 0.4488, conf: 0.0004), s/iter: 0.1014, lr: 3.0e-04
[2024-12-25 21:59:22,206] [INFO] Epoch [22/2695], Step [569/910], Loss: 4.1576 (poly: 0.0075, lower: 0.0000, upper: 0.0000, cls_loss: 0.0000, line_iou: 0.4303, conf: 0.0004), s/iter: 0.1015, lr: 3.0e-04
[2024-12-25 21:59:22,323] [INFO] Epoch [22/2695], Step [570/910], Loss: 4.1513 (poly: 0.0869, lower: 0.0000, upper: 0.0000, cls_loss: 0.0000, line_iou: 0.4441, conf: 0.0007), s/iter: 0.1016, lr: 3.0e-04
[2024-12-25 21:59:22,431] [INFO] Epoch [22/2695], Step [571/910], Loss: 4.1447 (poly: 0.0056, lower: 0.0000, upper: 0.0000, cls_loss: 0.0000, line_iou: 0.4009, conf: 0.0004), s/iter: 0.1015, lr: 3.0e-04
[2024-12-25 21:59:22,538] [INFO] Epoch [22/2695], Step [572/910], Loss: 4.1385 (poly: 0.1087, lower: 0.0000, upper: 0.0002, cls_loss: 0.0000, line_iou: 0.4909, conf: 0.0007), s/iter: 0.1015, lr: 3.0e-04
[2024-12-25 21:59:22,661] [INFO] Epoch [22/2695], Step [573/910], Loss: 4.1322 (poly: 0.0903, lower: 0.0000, upper: 0.0000, cls_loss: 0.0000, line_iou: 0.4409, conf: 0.0007), s/iter: 0.1016, lr: 3.0e-04
[2024-12-25 21:59:22,782] [INFO] Epoch [22/2695], Step [574/910], Loss: 4.1257 (poly: 0.0042, lower: 0.0000, upper: 0.0000, cls_loss: 0.0000, line_iou: 0.4154, conf: 0.0006), s/iter: 0.1019, lr: 3.0e-04
[2024-12-25 21:59:22,894] [INFO] Epoch [22/2695], Step [575/910], Loss: 4.1193 (poly: 0.0058, lower: 0.0000, upper: 0.0000, cls_loss: 0.0000, line_iou: 0.4008, conf: 0.0006), s/iter: 0.1018, lr: 3.0e-04
[2024-12-25 21:59:22,960] [INFO] Weight SoftAdapt Loss tensor([0.4967, 0.0017, 0.0017, 0.0017, 0.4967, 0.0017], dtype=torch.float64)
[2024-12-25 21:59:23,026] [INFO] Epoch [22/2695], Step [576/910], Loss: 4.1130 (poly: 0.0000, lower: 0.0000, upper: 0.0000, cls_loss: 0.0000, line_iou: 0.3996, conf: 0.1092), s/iter: 0.1022, lr: 3.0e-04
[2024-12-25 21:59:23,125] [INFO] Epoch [22/2695], Step [577/910], Loss: 4.1068 (poly: 0.0000, lower: 0.0000, upper: 0.0000, cls_loss: 0.0000, line_iou: 0.4250, conf: 0.1093), s/iter: 0.1018, lr: 3.0e-04
[2024-12-25 21:59:23,230] [INFO] Epoch [22/2695], Step [578/910], Loss: 4.1009 (poly: 0.0003, lower: 0.0000, upper: 0.0001, cls_loss: 0.0000, line_iou: 0.4580, conf: 0.2214), s/iter: 0.1019, lr: 3.0e-04
[2024-12-25 21:59:23,317] [INFO] Epoch [22/2695], Step [579/910], Loss: 4.0947 (poly: 0.0000, lower: 0.0000, upper: 0.0000, cls_loss: 0.0000, line_iou: 0.4268, conf: 0.1092), s/iter: 0.1019, lr: 3.0e-04
[2024-12-25 21:59:23,428] [INFO] Epoch [22/2695], Step [580/910], Loss: 4.0889 (poly: 0.0005, lower: 0.0000, upper: 0.0001, cls_loss: 0.0000, line_iou: 0.4835, conf: 0.2214), s/iter: 0.1018, lr: 3.0e-04
[2024-12-25 21:59:23,534] [INFO] Epoch [22/2695], Step [581/910], Loss: 4.0830 (poly: 0.0004, lower: 0.0000, upper: 0.0001, cls_loss: 0.0000, line_iou: 0.4847, conf: 0.2214), s/iter: 0.1018, lr: 3.0e-04
[2024-12-25 21:59:23,636] [INFO] Epoch [22/2695], Step [582/910], Loss: 4.0773 (poly: 0.0005, lower: 0.0000, upper: 0.0001, cls_loss: 0.0000, line_iou: 0.4907, conf: 0.2213), s/iter: 0.1019, lr: 3.0e-04
[2024-12-25 21:59:23,752] [INFO] Epoch [22/2695], Step [583/910], Loss: 4.0714 (poly: 0.0002, lower: 0.0000, upper: 0.0002, cls_loss: 0.0000, line_iou: 0.4828, conf: 0.1951), s/iter: 0.1021, lr: 3.0e-04
[2024-12-25 21:59:23,858] [INFO] Epoch [22/2695], Step [584/910], Loss: 4.0653 (poly: 0.0000, lower: 0.0000, upper: 0.0000, cls_loss: 0.0000, line_iou: 0.4093, conf: 0.1091), s/iter: 0.1021, lr: 3.0e-04
[2024-12-25 21:59:23,923] [INFO] Weight SoftAdapt Loss tensor([0.0017, 0.0017, 0.0017, 0.0017, 0.4967, 0.4967], dtype=torch.float64)
[2024-12-25 21:59:23,980] [INFO] Epoch [22/2695], Step [585/910], Loss: 4.0590 (poly: 0.1287, lower: 0.0000, upper: 0.0000, cls_loss: 0.0000, line_iou: 0.0015, conf: 0.2213), s/iter: 0.1024, lr: 3.0e-04
[2024-12-25 21:59:24,091] [INFO] Epoch [22/2695], Step [586/910], Loss: 4.0527 (poly: 0.1538, lower: 0.0000, upper: 0.0000, cls_loss: 0.0000, line_iou: 0.0016, conf: 0.2213), s/iter: 0.1024, lr: 3.0e-04
[2024-12-25 21:59:24,190] [INFO] Epoch [22/2695], Step [587/910], Loss: 4.0464 (poly: 0.1209, lower: 0.0000, upper: 0.0000, cls_loss: 0.0000, line_iou: 0.0016, conf: 0.2213), s/iter: 0.1023, lr: 3.0e-04
[2024-12-25 21:59:24,283] [INFO] Epoch [22/2695], Step [588/910], Loss: 4.0399 (poly: 0.0575, lower: 0.0000, upper: 0.0002, cls_loss: 0.0000, line_iou: 0.0017, conf: 0.1951), s/iter: 0.1021, lr: 3.0e-04
[2024-12-25 21:59:24,392] [INFO] Epoch [22/2695], Step [589/910], Loss: 4.0333 (poly: 0.0065, lower: 0.0000, upper: 0.0000, cls_loss: 0.0000, line_iou: 0.0014, conf: 0.1091), s/iter: 0.1022, lr: 3.0e-04
[2024-12-25 21:59:24,490] [INFO] Epoch [22/2695], Step [590/910], Loss: 4.0270 (poly: 0.1009, lower: 0.0000, upper: 0.0000, cls_loss: 0.0000, line_iou: 0.0015, conf: 0.2213), s/iter: 0.1021, lr: 3.0e-04
[2024-12-25 21:59:24,581] [INFO] Epoch [22/2695], Step [591/910], Loss: 4.0206 (poly: 0.0605, lower: 0.0000, upper: 0.0002, cls_loss: 0.0000, line_iou: 0.0016, conf: 0.1951), s/iter: 0.1020, lr: 3.0e-04
[2024-12-25 21:59:24,667] [INFO] Epoch [22/2695], Step [592/910], Loss: 4.0144 (poly: 0.1222, lower: 0.0000, upper: 0.0000, cls_loss: 0.0000, line_iou: 0.0016, conf: 0.2212), s/iter: 0.1016, lr: 3.0e-04
[2024-12-25 21:59:24,757] [INFO] Epoch [22/2695], Step [593/910], Loss: 4.0078 (poly: 0.0064, lower: 0.0000, upper: 0.0000, cls_loss: 0.0000, line_iou: 0.0014, conf: 0.1090), s/iter: 0.1016, lr: 3.0e-04
[2024-12-25 21:59:24,818] [INFO] Weight SoftAdapt Loss tensor([0.4967, 0.0017, 0.0017, 0.0017, 0.0017, 0.4967], dtype=torch.float64)
[2024-12-25 21:59:24,869] [INFO] Epoch [22/2695], Step [594/910], Loss: 4.0018 (poly: 0.0052, lower: 0.0000, upper: 0.0000, cls_loss: 0.0000, line_iou: 0.4003, conf: 0.0007), s/iter: 0.1017, lr: 3.0e-04
[2024-12-25 21:59:24,963] [INFO] Epoch [22/2695], Step [595/910], Loss: 3.9958 (poly: 0.0127, lower: 0.0000, upper: 0.0001, cls_loss: 0.0000, line_iou: 0.4067, conf: 0.0007), s/iter: 0.1015, lr: 3.0e-04
[2024-12-25 21:59:25,074] [INFO] Epoch [22/2695], Step [596/910], Loss: 3.9900 (poly: 0.0628, lower: 0.0000, upper: 0.0002, cls_loss: 0.0000, line_iou: 0.4876, conf: 0.0007), s/iter: 0.1015, lr: 3.0e-04
[2024-12-25 21:59:25,173] [INFO] Epoch [22/2695], Step [597/910], Loss: 3.9840 (poly: 0.0041, lower: 0.0000, upper: 0.0000, cls_loss: 0.0000, line_iou: 0.3938, conf: 0.0007), s/iter: 0.1015, lr: 3.0e-04
[2024-12-25 21:59:25,268] [INFO] Epoch [22/2695], Step [598/910], Loss: 3.9780 (poly: 0.0039, lower: 0.0000, upper: 0.0000, cls_loss: 0.0000, line_iou: 0.3949, conf: 0.0004), s/iter: 0.1017, lr: 3.0e-04
[2024-12-25 21:59:25,373] [INFO] Epoch [22/2695], Step [599/910], Loss: 3.9720 (poly: 0.0028, lower: 0.0000, upper: 0.0000, cls_loss: 0.0000, line_iou: 0.3893, conf: 0.0004), s/iter: 0.1017, lr: 3.0e-04
[2024-12-25 21:59:25,476] [INFO] Epoch [22/2695], Step [600/910], Loss: 3.9661 (poly: 0.0049, lower: 0.0000, upper: 0.0000, cls_loss: 0.0000, line_iou: 0.4174, conf: 0.0004), s/iter: 0.1018, lr: 3.0e-04
[2024-12-25 21:59:25,609] [INFO] Epoch [22/2695], Step [601/910], Loss: 3.9602 (poly: 0.0058, lower: 0.0000, upper: 0.0000, cls_loss: 0.0000, line_iou: 0.4299, conf: 0.0004), s/iter: 0.1020, lr: 3.0e-04
[2024-12-25 21:59:25,730] [INFO] Epoch [22/2695], Step [602/910], Loss: 3.9545 (poly: 0.0438, lower: 0.0000, upper: 0.0001, cls_loss: 0.0000, line_iou: 0.4604, conf: 0.0007), s/iter: 0.1023, lr: 3.0e-04
[2024-12-25 21:59:25,784] [INFO] Weight SoftAdapt Loss tensor([0.4967, 0.0017, 0.0017, 0.0017, 0.4967, 0.0017], dtype=torch.float64)
[2024-12-25 21:59:25,837] [INFO] Epoch [22/2695], Step [603/910], Loss: 3.9491 (poly: 0.0003, lower: 0.0000, upper: 0.0001, cls_loss: 0.0000, line_iou: 0.4761, conf: 0.2209), s/iter: 0.1024, lr: 3.0e-04
[2024-12-25 21:59:25,940] [INFO] Epoch [22/2695], Step [604/910], Loss: 3.9434 (poly: 0.0000, lower: 0.0000, upper: 0.0000, cls_loss: 0.0000, line_iou: 0.4325, conf: 0.1089), s/iter: 0.1025, lr: 3.0e-04
[2024-12-25 21:59:26,055] [INFO] Epoch [22/2695], Step [605/910], Loss: 3.9378 (poly: 0.0000, lower: 0.0000, upper: 0.0000, cls_loss: 0.0000, line_iou: 0.4549, conf: 0.1089), s/iter: 0.1027, lr: 3.0e-04
[2024-12-25 21:59:26,150] [INFO] Epoch [22/2695], Step [606/910], Loss: 3.9325 (poly: 0.0003, lower: 0.0000, upper: 0.0001, cls_loss: 0.0000, line_iou: 0.4613, conf: 0.2209), s/iter: 0.1027, lr: 3.0e-04
[2024-12-25 21:59:26,271] [INFO] Epoch [22/2695], Step [607/910], Loss: 3.9272 (poly: 0.0004, lower: 0.0000, upper: 0.0003, cls_loss: 0.0000, line_iou: 0.4963, conf: 0.2209), s/iter: 0.1029, lr: 3.0e-04
[2024-12-25 21:59:26,388] [INFO] Epoch [22/2695], Step [608/910], Loss: 3.9216 (poly: 0.0000, lower: 0.0000, upper: 0.0000, cls_loss: 0.0000, line_iou: 0.4646, conf: 0.1089), s/iter: 0.1030, lr: 3.0e-04
[2024-12-25 21:59:26,498] [INFO] Epoch [22/2695], Step [609/910], Loss: 3.9161 (poly: 0.0000, lower: 0.0000, upper: 0.0000, cls_loss: 0.0000, line_iou: 0.4366, conf: 0.1090), s/iter: 0.1030, lr: 3.0e-04
[2024-12-25 21:59:26,614] [INFO] Epoch [22/2695], Step [610/910], Loss: 3.9107 (poly: 0.0000, lower: 0.0000, upper: 0.0000, cls_loss: 0.0000, line_iou: 0.4172, conf: 0.1952), s/iter: 0.1031, lr: 3.0e-04
[2024-12-25 21:59:26,718] [INFO] Epoch [22/2695], Step [611/910], Loss: 3.9054 (poly: 0.0003, lower: 0.0000, upper: 0.0000, cls_loss: 0.0000, line_iou: 0.4437, conf: 0.2208), s/iter: 0.1029, lr: 3.0e-04
[2024-12-25 21:59:26,767] [INFO] Weight SoftAdapt Loss tensor([0.0017, 0.0017, 0.0017, 0.0017, 0.4967, 0.4967], dtype=torch.float64)
[2024-12-25 21:59:26,828] [INFO] Epoch [22/2695], Step [612/910], Loss: 3.8992 (poly: 0.0025, lower: 0.0000, upper: 0.0000, cls_loss: 0.0000, line_iou: 0.0014, conf: 0.1089), s/iter: 0.1032, lr: 3.0e-04
[2024-12-25 21:59:26,941] [INFO] Epoch [22/2695], Step [613/910], Loss: 3.8931 (poly: 0.0035, lower: 0.0000, upper: 0.0000, cls_loss: 0.0000, line_iou: 0.0012, conf: 0.1952), s/iter: 0.1033, lr: 3.0e-04
[2024-12-25 21:59:27,046] [INFO] Epoch [22/2695], Step [614/910], Loss: 3.8874 (poly: 0.1200, lower: 0.0000, upper: 0.0001, cls_loss: 0.0000, line_iou: 0.0016, conf: 0.2207), s/iter: 0.1031, lr: 3.0e-04
[2024-12-25 21:59:27,133] [INFO] Epoch [22/2695], Step [615/910], Loss: 3.8816 (poly: 0.1067, lower: 0.0000, upper: 0.0001, cls_loss: 0.0000, line_iou: 0.0016, conf: 0.2208), s/iter: 0.1029, lr: 3.0e-04
[2024-12-25 21:59:27,228] [INFO] Epoch [22/2695], Step [616/910], Loss: 3.8754 (poly: 0.0029, lower: 0.0000, upper: 0.0000, cls_loss: 0.0000, line_iou: 0.0013, conf: 0.1089), s/iter: 0.1024, lr: 3.0e-04
[2024-12-25 21:59:27,348] [INFO] Epoch [22/2695], Step [617/910], Loss: 3.8698 (poly: 0.1370, lower: 0.0000, upper: 0.0001, cls_loss: 0.0000, line_iou: 0.0017, conf: 0.2206), s/iter: 0.1026, lr: 3.0e-04
[2024-12-25 21:59:27,450] [INFO] Epoch [22/2695], Step [618/910], Loss: 3.8637 (poly: 0.0032, lower: 0.0000, upper: 0.0000, cls_loss: 0.0000, line_iou: 0.0014, conf: 0.1089), s/iter: 0.1026, lr: 3.0e-04
[2024-12-25 21:59:27,538] [INFO] Epoch [22/2695], Step [619/910], Loss: 3.8579 (poly: 0.0937, lower: 0.0000, upper: 0.0000, cls_loss: 0.0000, line_iou: 0.0014, conf: 0.2206), s/iter: 0.1023, lr: 3.0e-04
[2024-12-25 21:59:27,631] [INFO] Epoch [22/2695], Step [620/910], Loss: 3.8519 (poly: 0.0035, lower: 0.0000, upper: 0.0000, cls_loss: 0.0000, line_iou: 0.0014, conf: 0.1089), s/iter: 0.1023, lr: 3.0e-04
[2024-12-25 21:59:27,690] [INFO] Weight SoftAdapt Loss tensor([0.4967, 0.0017, 0.0017, 0.0017, 0.0017, 0.4967], dtype=torch.float64)
[2024-12-25 21:59:27,741] [INFO] Epoch [22/2695], Step [621/910], Loss: 3.8464 (poly: 0.0063, lower: 0.0000, upper: 0.0000, cls_loss: 0.0000, line_iou: 0.4196, conf: 0.0004), s/iter: 0.1022, lr: 3.0e-04
[2024-12-25 21:59:27,858] [INFO] Epoch [22/2695], Step [622/910], Loss: 3.8408 (poly: 0.0043, lower: 0.0000, upper: 0.0000, cls_loss: 0.0000, line_iou: 0.3736, conf: 0.0007), s/iter: 0.1024, lr: 3.0e-04
[2024-12-25 21:59:27,973] [INFO] Epoch [22/2695], Step [623/910], Loss: 3.8354 (poly: 0.0042, lower: 0.0000, upper: 0.0000, cls_loss: 0.0000, line_iou: 0.4349, conf: 0.0004), s/iter: 0.1025, lr: 3.0e-04
[2024-12-25 21:59:28,085] [INFO] Epoch [22/2695], Step [624/910], Loss: 3.8299 (poly: 0.0037, lower: 0.0000, upper: 0.0000, cls_loss: 0.0000, line_iou: 0.4013, conf: 0.0004), s/iter: 0.1025, lr: 3.0e-04
[2024-12-25 21:59:28,189] [INFO] Epoch [22/2695], Step [625/910], Loss: 3.8246 (poly: 0.0196, lower: 0.0000, upper: 0.0001, cls_loss: 0.0000, line_iou: 0.4947, conf: 0.0004), s/iter: 0.1025, lr: 3.0e-04
[2024-12-25 21:59:28,301] [INFO] Epoch [22/2695], Step [626/910], Loss: 3.8191 (poly: 0.0061, lower: 0.0000, upper: 0.0000, cls_loss: 0.0000, line_iou: 0.4328, conf: 0.0004), s/iter: 0.1025, lr: 3.0e-04
[2024-12-25 21:59:28,419] [INFO] Epoch [22/2695], Step [627/910], Loss: 3.8137 (poly: 0.0049, lower: 0.0000, upper: 0.0000, cls_loss: 0.0000, line_iou: 0.4037, conf: 0.0004), s/iter: 0.1026, lr: 3.0e-04
[2024-12-25 21:59:28,534] [INFO] Epoch [22/2695], Step [628/910], Loss: 3.8085 (poly: 0.0987, lower: 0.0000, upper: 0.0001, cls_loss: 0.0000, line_iou: 0.4680, conf: 0.0007), s/iter: 0.1026, lr: 3.0e-04
[2024-12-25 21:59:28,657] [INFO] Epoch [22/2695], Step [629/910], Loss: 3.8032 (poly: 0.0091, lower: 0.0000, upper: 0.0000, cls_loss: 0.0000, line_iou: 0.4443, conf: 0.0007), s/iter: 0.1028, lr: 3.0e-04
[2024-12-25 21:59:28,723] [INFO] Weight SoftAdapt Loss tensor([0.4967, 0.0017, 0.0017, 0.0017, 0.4967, 0.0017], dtype=torch.float64)
[2024-12-25 21:59:28,783] [INFO] Epoch [22/2695], Step [630/910], Loss: 3.7982 (poly: 0.0000, lower: 0.0000, upper: 0.0000, cls_loss: 0.0000, line_iou: 0.4510, conf: 0.1953), s/iter: 0.1031, lr: 3.0e-04
[2024-12-25 21:59:28,886] [INFO] Epoch [22/2695], Step [631/910], Loss: 3.7932 (poly: 0.0000, lower: 0.0000, upper: 0.0000, cls_loss: 0.0000, line_iou: 0.4455, conf: 0.1953), s/iter: 0.1030, lr: 3.0e-04
[2024-12-25 21:59:28,985] [INFO] Epoch [22/2695], Step [632/910], Loss: 3.7882 (poly: 0.0000, lower: 0.0000, upper: 0.0000, cls_loss: 0.0000, line_iou: 0.4192, conf: 0.1953), s/iter: 0.1028, lr: 3.0e-04
[2024-12-25 21:59:29,100] [INFO] Epoch [22/2695], Step [633/910], Loss: 3.7833 (poly: 0.0004, lower: 0.0000, upper: 0.0000, cls_loss: 0.0000, line_iou: 0.4870, conf: 0.2204), s/iter: 0.1029, lr: 3.0e-04
[2024-12-25 21:59:29,245] [INFO] Epoch [22/2695], Step [634/910], Loss: 3.7782 (poly: 0.0000, lower: 0.0000, upper: 0.0000, cls_loss: 0.0000, line_iou: 0.4269, conf: 0.1088), s/iter: 0.1032, lr: 3.0e-04
[2024-12-25 21:59:29,369] [INFO] Epoch [22/2695], Step [635/910], Loss: 3.7733 (poly: 0.0004, lower: 0.0000, upper: 0.0001, cls_loss: 0.0000, line_iou: 0.4881, conf: 0.2204), s/iter: 0.1034, lr: 3.0e-04
[2024-12-25 21:59:29,478] [INFO] Epoch [22/2695], Step [636/910], Loss: 3.7684 (poly: 0.0003, lower: 0.0000, upper: 0.0000, cls_loss: 0.0000, line_iou: 0.4401, conf: 0.2204), s/iter: 0.1034, lr: 3.0e-04
[2024-12-25 21:59:29,578] [INFO] Epoch [22/2695], Step [637/910], Loss: 3.7634 (poly: 0.0000, lower: 0.0000, upper: 0.0000, cls_loss: 0.0000, line_iou: 0.4350, conf: 0.1087), s/iter: 0.1034, lr: 3.0e-04
[2024-12-25 21:59:29,689] [INFO] Epoch [22/2695], Step [638/910], Loss: 3.7583 (poly: 0.0000, lower: 0.0000, upper: 0.0000, cls_loss: 0.0000, line_iou: 0.4323, conf: 0.1087), s/iter: 0.1034, lr: 3.0e-04
[2024-12-25 21:59:29,746] [INFO] Weight SoftAdapt Loss tensor([0.0017, 0.0017, 0.0017, 0.0017, 0.4967, 0.4967], dtype=torch.float64)
[2024-12-25 21:59:29,803] [INFO] Epoch [22/2695], Step [639/910], Loss: 3.7528 (poly: 0.0031, lower: 0.0000, upper: 0.0001, cls_loss: 0.0000, line_iou: 0.0013, conf: 0.1952), s/iter: 0.1034, lr: 3.0e-04
[2024-12-25 21:59:29,923] [INFO] Epoch [22/2695], Step [640/910], Loss: 3.7471 (poly: 0.0047, lower: 0.0000, upper: 0.0000, cls_loss: 0.0000, line_iou: 0.0014, conf: 0.1087), s/iter: 0.1034, lr: 3.0e-04
[2024-12-25 21:59:30,031] [INFO] Epoch [22/2695], Step [641/910], Loss: 3.7414 (poly: 0.0052, lower: 0.0000, upper: 0.0000, cls_loss: 0.0000, line_iou: 0.0013, conf: 0.1087), s/iter: 0.1036, lr: 3.0e-04
[2024-12-25 21:59:30,147] [INFO] Epoch [22/2695], Step [642/910], Loss: 3.7358 (poly: 0.0047, lower: 0.0000, upper: 0.0000, cls_loss: 0.0000, line_iou: 0.0015, conf: 0.1087), s/iter: 0.1037, lr: 3.0e-04
[2024-12-25 21:59:30,272] [INFO] Epoch [22/2695], Step [643/910], Loss: 3.7304 (poly: 0.0680, lower: 0.0000, upper: 0.0002, cls_loss: 0.0000, line_iou: 0.0016, conf: 0.1952), s/iter: 0.1040, lr: 3.0e-04
[2024-12-25 21:59:30,393] [INFO] Epoch [22/2695], Step [644/910], Loss: 3.7249 (poly: 0.0048, lower: 0.0000, upper: 0.0000, cls_loss: 0.0000, line_iou: 0.0014, conf: 0.1952), s/iter: 0.1043, lr: 3.0e-04
[2024-12-25 21:59:30,524] [INFO] Epoch [22/2695], Step [645/910], Loss: 3.7193 (poly: 0.0026, lower: 0.0000, upper: 0.0000, cls_loss: 0.0000, line_iou: 0.0013, conf: 0.1087), s/iter: 0.1045, lr: 3.0e-04
[2024-12-25 21:59:30,639] [INFO] Epoch [22/2695], Step [646/910], Loss: 3.7139 (poly: 0.0681, lower: 0.0000, upper: 0.0002, cls_loss: 0.0000, line_iou: 0.0016, conf: 0.1952), s/iter: 0.1047, lr: 3.0e-04
[2024-12-25 21:59:30,765] [INFO] Epoch [22/2695], Step [647/910], Loss: 3.7087 (poly: 0.1257, lower: 0.0000, upper: 0.0001, cls_loss: 0.0000, line_iou: 0.0016, conf: 0.2203), s/iter: 0.1049, lr: 3.0e-04
[2024-12-25 21:59:30,835] [INFO] Weight SoftAdapt Loss tensor([0.4967, 0.0017, 0.0017, 0.0017, 0.0017, 0.4967], dtype=torch.float64)
[2024-12-25 21:59:30,888] [INFO] Epoch [22/2695], Step [648/910], Loss: 3.7039 (poly: 0.0754, lower: 0.0000, upper: 0.0000, cls_loss: 0.0000, line_iou: 0.4794, conf: 0.0004), s/iter: 0.1049, lr: 3.0e-04
[2024-12-25 21:59:31,002] [INFO] Epoch [22/2695], Step [649/910], Loss: 3.6991 (poly: 0.1326, lower: 0.0000, upper: 0.0002, cls_loss: 0.0000, line_iou: 0.4920, conf: 0.0007), s/iter: 0.1047, lr: 3.0e-04
[2024-12-25 21:59:31,110] [INFO] Epoch [22/2695], Step [650/910], Loss: 3.6941 (poly: 0.0051, lower: 0.0000, upper: 0.0000, cls_loss: 0.0000, line_iou: 0.4299, conf: 0.0004), s/iter: 0.1047, lr: 3.0e-04
[2024-12-25 21:59:31,204] [INFO] Epoch [22/2695], Step [651/910], Loss: 3.6890 (poly: 0.0039, lower: 0.0000, upper: 0.0000, cls_loss: 0.0000, line_iou: 0.3892, conf: 0.0004), s/iter: 0.1045, lr: 3.0e-04
[2024-12-25 21:59:31,308] [INFO] Epoch [22/2695], Step [652/910], Loss: 3.6840 (poly: 0.0039, lower: 0.0000, upper: 0.0000, cls_loss: 0.0000, line_iou: 0.4029, conf: 0.0004), s/iter: 0.1044, lr: 3.0e-04
[2024-12-25 21:59:31,399] [INFO] Epoch [22/2695], Step [653/910], Loss: 3.6791 (poly: 0.0374, lower: 0.0000, upper: 0.0001, cls_loss: 0.0000, line_iou: 0.4375, conf: 0.0007), s/iter: 0.1043, lr: 3.0e-04
[2024-12-25 21:59:31,509] [INFO] Epoch [22/2695], Step [654/910], Loss: 3.6741 (poly: 0.0066, lower: 0.0000, upper: 0.0000, cls_loss: 0.0000, line_iou: 0.4409, conf: 0.0004), s/iter: 0.1044, lr: 3.0e-04
[2024-12-25 21:59:31,617] [INFO] Epoch [22/2695], Step [655/910], Loss: 3.6694 (poly: 0.0621, lower: 0.0000, upper: 0.0001, cls_loss: 0.0000, line_iou: 0.4734, conf: 0.0007), s/iter: 0.1045, lr: 3.0e-04
[2024-12-25 21:59:31,728] [INFO] Epoch [22/2695], Step [656/910], Loss: 3.6646 (poly: 0.0994, lower: 0.0000, upper: 0.0000, cls_loss: 0.0000, line_iou: 0.4662, conf: 0.0007), s/iter: 0.1045, lr: 3.0e-04
[2024-12-25 21:59:31,794] [INFO] Weight SoftAdapt Loss tensor([0.4967, 0.0017, 0.0017, 0.0017, 0.4967, 0.0017], dtype=torch.float64)
[2024-12-25 21:59:31,852] [INFO] Epoch [22/2695], Step [657/910], Loss: 3.6598 (poly: 0.0000, lower: 0.0000, upper: 0.0000, cls_loss: 0.0000, line_iou: 0.4147, conf: 0.1086), s/iter: 0.1047, lr: 3.0e-04
[2024-12-25 21:59:31,977] [INFO] Epoch [22/2695], Step [658/910], Loss: 3.6553 (poly: 0.0002, lower: 0.0000, upper: 0.0002, cls_loss: 0.0000, line_iou: 0.4880, conf: 0.1950), s/iter: 0.1047, lr: 3.0e-04
[2024-12-25 21:59:32,091] [INFO] Epoch [22/2695], Step [659/910], Loss: 3.6508 (poly: 0.0003, lower: 0.0000, upper: 0.0001, cls_loss: 0.0000, line_iou: 0.4847, conf: 0.2202), s/iter: 0.1049, lr: 3.0e-04
[2024-12-25 21:59:32,202] [INFO] Epoch [22/2695], Step [660/910], Loss: 3.6464 (poly: 0.0004, lower: 0.0000, upper: 0.0001, cls_loss: 0.0000, line_iou: 0.4911, conf: 0.2203), s/iter: 0.1049, lr: 3.0e-04
[2024-12-25 21:59:32,327] [INFO] Epoch [22/2695], Step [661/910], Loss: 3.6419 (poly: 0.0002, lower: 0.0000, upper: 0.0002, cls_loss: 0.0000, line_iou: 0.4941, conf: 0.1950), s/iter: 0.1049, lr: 3.0e-04
[2024-12-25 21:59:32,453] [INFO] Epoch [22/2695], Step [662/910], Loss: 3.6375 (poly: 0.0004, lower: 0.0000, upper: 0.0000, cls_loss: 0.0000, line_iou: 0.4881, conf: 0.2203), s/iter: 0.1053, lr: 3.0e-04
[2024-12-25 21:59:32,589] [INFO] Epoch [22/2695], Step [663/910], Loss: 3.6328 (poly: 0.0000, lower: 0.0000, upper: 0.0000, cls_loss: 0.0000, line_iou: 0.3940, conf: 0.1086), s/iter: 0.1056, lr: 3.0e-04
[2024-12-25 21:59:32,697] [INFO] Epoch [22/2695], Step [664/910], Loss: 3.6281 (poly: 0.0000, lower: 0.0000, upper: 0.0000, cls_loss: 0.0000, line_iou: 0.4385, conf: 0.1086), s/iter: 0.1056, lr: 3.0e-04
[2024-12-25 21:59:32,808] [INFO] Epoch [22/2695], Step [665/910], Loss: 3.6235 (poly: 0.0000, lower: 0.0000, upper: 0.0000, cls_loss: 0.0000, line_iou: 0.4279, conf: 0.1086), s/iter: 0.1057, lr: 3.0e-04
[2024-12-25 21:59:32,864] [INFO] Weight SoftAdapt Loss tensor([0.0017, 0.0017, 0.0017, 0.0017, 0.4967, 0.4967], dtype=torch.float64)
[2024-12-25 21:59:32,933] [INFO] Epoch [22/2695], Step [666/910], Loss: 3.6182 (poly: 0.0042, lower: 0.0000, upper: 0.0000, cls_loss: 0.0000, line_iou: 0.0015, conf: 0.1086), s/iter: 0.1060, lr: 3.0e-04
[2024-12-25 21:59:33,032] [INFO] Epoch [22/2695], Step [667/910], Loss: 3.6129 (poly: 0.0027, lower: 0.0000, upper: 0.0000, cls_loss: 0.0000, line_iou: 0.0014, conf: 0.1086), s/iter: 0.1057, lr: 3.0e-04
[2024-12-25 21:59:33,130] [INFO] Epoch [22/2695], Step [668/910], Loss: 3.6077 (poly: 0.0037, lower: 0.0000, upper: 0.0000, cls_loss: 0.0000, line_iou: 0.0014, conf: 0.1085), s/iter: 0.1054, lr: 3.0e-04
[2024-12-25 21:59:33,226] [INFO] Epoch [22/2695], Step [669/910], Loss: 3.6025 (poly: 0.0034, lower: 0.0000, upper: 0.0000, cls_loss: 0.0000, line_iou: 0.0013, conf: 0.1085), s/iter: 0.1052, lr: 3.0e-04
[2024-12-25 21:59:33,332] [INFO] Epoch [22/2695], Step [670/910], Loss: 3.5975 (poly: 0.0446, lower: 0.0000, upper: 0.0001, cls_loss: 0.0000, line_iou: 0.0015, conf: 0.1950), s/iter: 0.1051, lr: 3.0e-04
[2024-12-25 21:59:33,428] [INFO] Epoch [22/2695], Step [671/910], Loss: 3.5926 (poly: 0.1282, lower: 0.0000, upper: 0.0001, cls_loss: 0.0000, line_iou: 0.0016, conf: 0.2201), s/iter: 0.1050, lr: 3.0e-04
[2024-12-25 21:59:33,523] [INFO] Epoch [22/2695], Step [672/910], Loss: 3.5877 (poly: 0.0846, lower: 0.0000, upper: 0.0001, cls_loss: 0.0000, line_iou: 0.0015, conf: 0.2201), s/iter: 0.1049, lr: 3.0e-04
[2024-12-25 21:59:33,625] [INFO] Epoch [22/2695], Step [673/910], Loss: 3.5829 (poly: 0.1198, lower: 0.0000, upper: 0.0000, cls_loss: 0.0000, line_iou: 0.0015, conf: 0.2200), s/iter: 0.1047, lr: 3.0e-04
[2024-12-25 21:59:33,741] [INFO] Epoch [22/2695], Step [674/910], Loss: 3.5778 (poly: 0.0077, lower: 0.0000, upper: 0.0000, cls_loss: 0.0000, line_iou: 0.0015, conf: 0.1085), s/iter: 0.1047, lr: 3.0e-04
[2024-12-25 21:59:33,812] [INFO] Weight SoftAdapt Loss tensor([0.4967, 0.0017, 0.0017, 0.0017, 0.0017, 0.4967], dtype=torch.float64)
[2024-12-25 21:59:33,865] [INFO] Epoch [22/2695], Step [675/910], Loss: 3.5731 (poly: 0.0051, lower: 0.0000, upper: 0.0000, cls_loss: 0.0000, line_iou: 0.4365, conf: 0.0004), s/iter: 0.1048, lr: 3.0e-04
[2024-12-25 21:59:33,953] [INFO] Epoch [22/2695], Step [676/910], Loss: 3.5685 (poly: 0.0031, lower: 0.0000, upper: 0.0000, cls_loss: 0.0000, line_iou: 0.4270, conf: 0.0004), s/iter: 0.1044, lr: 3.0e-04
[2024-12-25 21:59:34,039] [INFO] Epoch [22/2695], Step [677/910], Loss: 3.5640 (poly: 0.1170, lower: 0.0000, upper: 0.0000, cls_loss: 0.0000, line_iou: 0.4495, conf: 0.0007), s/iter: 0.1043, lr: 3.0e-04
[2024-12-25 21:59:34,142] [INFO] Epoch [22/2695], Step [678/910], Loss: 3.5594 (poly: 0.0050, lower: 0.0000, upper: 0.0000, cls_loss: 0.0000, line_iou: 0.4468, conf: 0.0004), s/iter: 0.1042, lr: 3.0e-04
[2024-12-25 21:59:34,242] [INFO] Epoch [22/2695], Step [679/910], Loss: 3.5548 (poly: 0.0022, lower: 0.0000, upper: 0.0001, cls_loss: 0.0000, line_iou: 0.4113, conf: 0.0004), s/iter: 0.1043, lr: 3.0e-04
[2024-12-25 21:59:34,343] [INFO] Epoch [22/2695], Step [680/910], Loss: 3.5502 (poly: 0.0073, lower: 0.0000, upper: 0.0000, cls_loss: 0.0000, line_iou: 0.4427, conf: 0.0004), s/iter: 0.1042, lr: 3.0e-04
[2024-12-25 21:59:34,444] [INFO] Epoch [22/2695], Step [681/910], Loss: 3.5456 (poly: 0.0028, lower: 0.0000, upper: 0.0000, cls_loss: 0.0000, line_iou: 0.3655, conf: 0.0004), s/iter: 0.1042, lr: 3.0e-04
[2024-12-25 21:59:34,550] [INFO] Epoch [22/2695], Step [682/910], Loss: 3.5410 (poly: 0.0049, lower: 0.0000, upper: 0.0000, cls_loss: 0.0000, line_iou: 0.4115, conf: 0.0007), s/iter: 0.1042, lr: 3.0e-04
[2024-12-25 21:59:34,645] [INFO] Epoch [22/2695], Step [683/910], Loss: 3.5366 (poly: 0.1111, lower: 0.0000, upper: 0.0000, cls_loss: 0.0000, line_iou: 0.4299, conf: 0.0007), s/iter: 0.1040, lr: 3.0e-04
[2024-12-25 21:59:34,703] [INFO] Weight SoftAdapt Loss tensor([0.4967, 0.0017, 0.0017, 0.0017, 0.4967, 0.0017], dtype=torch.float64)
[2024-12-25 21:59:34,756] [INFO] Epoch [22/2695], Step [684/910], Loss: 3.5321 (poly: 0.0000, lower: 0.0000, upper: 0.0000, cls_loss: 0.0000, line_iou: 0.3718, conf: 0.1084), s/iter: 0.1041, lr: 3.0e-04
[2024-12-25 21:59:34,843] [INFO] Epoch [22/2695], Step [685/910], Loss: 3.5278 (poly: 0.0000, lower: 0.0000, upper: 0.0000, cls_loss: 0.0000, line_iou: 0.4322, conf: 0.1083), s/iter: 0.1037, lr: 3.0e-04
[2024-12-25 21:59:34,938] [INFO] Epoch [22/2695], Step [686/910], Loss: 3.5235 (poly: 0.0003, lower: 0.0000, upper: 0.0000, cls_loss: 0.0000, line_iou: 0.4016, conf: 0.2199), s/iter: 0.1036, lr: 3.0e-04
[2024-12-25 21:59:35,064] [INFO] Epoch [22/2695], Step [687/910], Loss: 3.5193 (poly: 0.0003, lower: 0.0000, upper: 0.0000, cls_loss: 0.0000, line_iou: 0.4156, conf: 0.2199), s/iter: 0.1038, lr: 3.0e-04
[2024-12-25 21:59:35,161] [INFO] Epoch [22/2695], Step [688/910], Loss: 3.5152 (poly: 0.0000, lower: 0.0000, upper: 0.0000, cls_loss: 0.0000, line_iou: 0.4543, conf: 0.1951), s/iter: 0.1039, lr: 3.0e-04
[2024-12-25 21:59:35,245] [INFO] Epoch [22/2695], Step [689/910], Loss: 3.5108 (poly: 0.0000, lower: 0.0000, upper: 0.0000, cls_loss: 0.0000, line_iou: 0.4124, conf: 0.1083), s/iter: 0.1037, lr: 3.0e-04
[2024-12-25 21:59:35,327] [INFO] Epoch [22/2695], Step [690/910], Loss: 3.5067 (poly: 0.0002, lower: 0.0000, upper: 0.0002, cls_loss: 0.0000, line_iou: 0.4792, conf: 0.1951), s/iter: 0.1035, lr: 3.0e-04
[2024-12-25 21:59:35,417] [INFO] Epoch [22/2695], Step [691/910], Loss: 3.5024 (poly: 0.0000, lower: 0.0000, upper: 0.0000, cls_loss: 0.0000, line_iou: 0.4067, conf: 0.1083), s/iter: 0.1035, lr: 3.0e-04
[2024-12-25 21:59:35,510] [INFO] Epoch [22/2695], Step [692/910], Loss: 3.4980 (poly: 0.0000, lower: 0.0000, upper: 0.0000, cls_loss: 0.0000, line_iou: 0.3892, conf: 0.1083), s/iter: 0.1036, lr: 3.0e-04
[2024-12-25 21:59:35,558] [INFO] Weight SoftAdapt Loss tensor([0.0017, 0.0017, 0.0017, 0.0017, 0.4967, 0.4967], dtype=torch.float64)
[2024-12-25 21:59:35,614] [INFO] Epoch [22/2695], Step [693/910], Loss: 3.4935 (poly: 0.1166, lower: 0.0000, upper: 0.0000, cls_loss: 0.0000, line_iou: 0.0014, conf: 0.2198), s/iter: 0.1037, lr: 3.0e-04
[2024-12-25 21:59:35,704] [INFO] Epoch [22/2695], Step [694/910], Loss: 3.4887 (poly: 0.0064, lower: 0.0000, upper: 0.0000, cls_loss: 0.0000, line_iou: 0.0014, conf: 0.1951), s/iter: 0.1035, lr: 3.0e-04
[2024-12-25 21:59:35,788] [INFO] Epoch [22/2695], Step [695/910], Loss: 3.4839 (poly: 0.0037, lower: 0.0000, upper: 0.0000, cls_loss: 0.0000, line_iou: 0.0013, conf: 0.1083), s/iter: 0.1034, lr: 3.0e-04
[2024-12-25 21:59:35,871] [INFO] Epoch [22/2695], Step [696/910], Loss: 3.4790 (poly: 0.0038, lower: 0.0000, upper: 0.0000, cls_loss: 0.0000, line_iou: 0.0013, conf: 0.1083), s/iter: 0.1032, lr: 3.0e-04
[2024-12-25 21:59:35,975] [INFO] Epoch [22/2695], Step [697/910], Loss: 3.4742 (poly: 0.0171, lower: 0.0000, upper: 0.0001, cls_loss: 0.0000, line_iou: 0.0015, conf: 0.1082), s/iter: 0.1032, lr: 3.0e-04
[2024-12-25 21:59:36,087] [INFO] Epoch [22/2695], Step [698/910], Loss: 3.4694 (poly: 0.0029, lower: 0.0000, upper: 0.0000, cls_loss: 0.0000, line_iou: 0.0014, conf: 0.1083), s/iter: 0.1034, lr: 3.0e-04
[2024-12-25 21:59:36,196] [INFO] Epoch [22/2695], Step [699/910], Loss: 3.4647 (poly: 0.0035, lower: 0.0000, upper: 0.0000, cls_loss: 0.0000, line_iou: 0.0013, conf: 0.1950), s/iter: 0.1034, lr: 3.0e-04
[2024-12-25 21:59:36,294] [INFO] Epoch [22/2695], Step [700/910], Loss: 3.4601 (poly: 0.0039, lower: 0.0000, upper: 0.0000, cls_loss: 0.0000, line_iou: 0.0013, conf: 0.1951), s/iter: 0.1034, lr: 3.0e-04
[2024-12-25 21:59:36,398] [INFO] Epoch [22/2695], Step [701/910], Loss: 3.4553 (poly: 0.0023, lower: 0.0000, upper: 0.0000, cls_loss: 0.0000, line_iou: 0.0013, conf: 0.1082), s/iter: 0.1031, lr: 3.0e-04
[2024-12-25 21:59:36,444] [INFO] Weight SoftAdapt Loss tensor([0.4967, 0.0017, 0.0017, 0.0017, 0.0017, 0.4967], dtype=torch.float64)
[2024-12-25 21:59:36,495] [INFO] Epoch [22/2695], Step [702/910], Loss: 3.4510 (poly: 0.0276, lower: 0.0000, upper: 0.0001, cls_loss: 0.0000, line_iou: 0.4371, conf: 0.0006), s/iter: 0.1029, lr: 3.0e-04
[2024-12-25 21:59:36,596] [INFO] Epoch [22/2695], Step [703/910], Loss: 3.4467 (poly: 0.0037, lower: 0.0000, upper: 0.0000, cls_loss: 0.0000, line_iou: 0.4110, conf: 0.0007), s/iter: 0.1028, lr: 3.0e-04
[2024-12-25 21:59:36,705] [INFO] Epoch [22/2695], Step [704/910], Loss: 3.4424 (poly: 0.0025, lower: 0.0000, upper: 0.0000, cls_loss: 0.0000, line_iou: 0.3921, conf: 0.0004), s/iter: 0.1029, lr: 3.0e-04
[2024-12-25 21:59:36,819] [INFO] Epoch [22/2695], Step [705/910], Loss: 3.4382 (poly: 0.1027, lower: 0.0000, upper: 0.0000, cls_loss: 0.0000, line_iou: 0.4064, conf: 0.0007), s/iter: 0.1029, lr: 3.0e-04
[2024-12-25 21:59:36,952] [INFO] Epoch [22/2695], Step [706/910], Loss: 3.4339 (poly: 0.0032, lower: 0.0000, upper: 0.0000, cls_loss: 0.0000, line_iou: 0.3937, conf: 0.0004), s/iter: 0.1032, lr: 3.0e-04
[2024-12-25 21:59:37,058] [INFO] Epoch [22/2695], Step [707/910], Loss: 3.4297 (poly: 0.0030, lower: 0.0000, upper: 0.0000, cls_loss: 0.0000, line_iou: 0.4264, conf: 0.0004), s/iter: 0.1031, lr: 3.0e-04
[2024-12-25 21:59:37,146] [INFO] Epoch [22/2695], Step [708/910], Loss: 3.4254 (poly: 0.0026, lower: 0.0000, upper: 0.0000, cls_loss: 0.0000, line_iou: 0.3954, conf: 0.0004), s/iter: 0.1028, lr: 3.0e-04
[2024-12-25 21:59:37,243] [INFO] Epoch [22/2695], Step [709/910], Loss: 3.4212 (poly: 0.0035, lower: 0.0000, upper: 0.0000, cls_loss: 0.0000, line_iou: 0.4371, conf: 0.0004), s/iter: 0.1027, lr: 3.0e-04
[2024-12-25 21:59:37,340] [INFO] Epoch [22/2695], Step [710/910], Loss: 3.4170 (poly: 0.0032, lower: 0.0000, upper: 0.0000, cls_loss: 0.0000, line_iou: 0.4331, conf: 0.0004), s/iter: 0.1025, lr: 3.0e-04
[2024-12-25 21:59:37,406] [INFO] Weight SoftAdapt Loss tensor([0.4967, 0.0017, 0.0017, 0.0017, 0.4967, 0.0017], dtype=torch.float64)
[2024-12-25 21:59:37,453] [INFO] Epoch [22/2695], Step [711/910], Loss: 3.4129 (poly: 0.0000, lower: 0.0000, upper: 0.0000, cls_loss: 0.0000, line_iou: 0.4281, conf: 0.1081), s/iter: 0.1026, lr: 3.0e-04
[2024-12-25 21:59:37,547] [INFO] Epoch [22/2695], Step [712/910], Loss: 3.4089 (poly: 0.0000, lower: 0.0000, upper: 0.0000, cls_loss: 0.0000, line_iou: 0.4390, conf: 0.1082), s/iter: 0.1024, lr: 3.0e-04
[2024-12-25 21:59:37,649] [INFO] Epoch [22/2695], Step [713/910], Loss: 3.4048 (poly: 0.0000, lower: 0.0000, upper: 0.0000, cls_loss: 0.0000, line_iou: 0.4255, conf: 0.1081), s/iter: 0.1023, lr: 3.0e-04
[2024-12-25 21:59:37,744] [INFO] Epoch [22/2695], Step [714/910], Loss: 3.4008 (poly: 0.0000, lower: 0.0000, upper: 0.0001, cls_loss: 0.0000, line_iou: 0.4295, conf: 0.1081), s/iter: 0.1022, lr: 3.0e-04
[2024-12-25 21:59:37,838] [INFO] Epoch [22/2695], Step [715/910], Loss: 3.3968 (poly: 0.0000, lower: 0.0000, upper: 0.0000, cls_loss: 0.0000, line_iou: 0.4150, conf: 0.1081), s/iter: 0.1023, lr: 3.0e-04
[2024-12-25 21:59:37,926] [INFO] Epoch [22/2695], Step [716/910], Loss: 3.3927 (poly: 0.0000, lower: 0.0000, upper: 0.0000, cls_loss: 0.0000, line_iou: 0.3713, conf: 0.1081), s/iter: 0.1022, lr: 3.0e-04
[2024-12-25 21:59:38,026] [INFO] Epoch [22/2695], Step [717/910], Loss: 3.3888 (poly: 0.0000, lower: 0.0000, upper: 0.0000, cls_loss: 0.0000, line_iou: 0.3954, conf: 0.1949), s/iter: 0.1020, lr: 3.0e-04
[2024-12-25 21:59:38,118] [INFO] Epoch [22/2695], Step [718/910], Loss: 3.3848 (poly: 0.0000, lower: 0.0000, upper: 0.0000, cls_loss: 0.0000, line_iou: 0.3737, conf: 0.1081), s/iter: 0.1019, lr: 3.0e-04
[2024-12-25 21:59:38,218] [INFO] Epoch [22/2695], Step [719/910], Loss: 3.3808 (poly: 0.0000, lower: 0.0000, upper: 0.0000, cls_loss: 0.0000, line_iou: 0.4123, conf: 0.1080), s/iter: 0.1021, lr: 3.0e-04
[2024-12-25 21:59:38,258] [INFO] Weight SoftAdapt Loss tensor([0.0017, 0.0017, 0.0017, 0.0017, 0.4967, 0.4967], dtype=torch.float64)
[2024-12-25 21:59:38,307] [INFO] Epoch [22/2695], Step [720/910], Loss: 3.3763 (poly: 0.0041, lower: 0.0000, upper: 0.0000, cls_loss: 0.0000, line_iou: 0.0014, conf: 0.1080), s/iter: 0.1020, lr: 3.0e-04
[2024-12-25 21:59:38,408] [INFO] Epoch [22/2695], Step [721/910], Loss: 3.3721 (poly: 0.1293, lower: 0.0000, upper: 0.0003, cls_loss: 0.0000, line_iou: 0.0017, conf: 0.2197), s/iter: 0.1019, lr: 3.0e-04
[2024-12-25 21:59:38,496] [INFO] Epoch [22/2695], Step [722/910], Loss: 3.3675 (poly: 0.0045, lower: 0.0000, upper: 0.0000, cls_loss: 0.0000, line_iou: 0.0014, conf: 0.1080), s/iter: 0.1016, lr: 3.0e-04
[2024-12-25 21:59:38,579] [INFO] Epoch [22/2695], Step [723/910], Loss: 3.3634 (poly: 0.1269, lower: 0.0000, upper: 0.0001, cls_loss: 0.0000, line_iou: 0.0016, conf: 0.2197), s/iter: 0.1013, lr: 3.0e-04
[2024-12-25 21:59:38,673] [INFO] Epoch [22/2695], Step [724/910], Loss: 3.3589 (poly: 0.0028, lower: 0.0000, upper: 0.0000, cls_loss: 0.0000, line_iou: 0.0013, conf: 0.1080), s/iter: 0.1012, lr: 3.0e-04
[2024-12-25 21:59:38,786] [INFO] Epoch [22/2695], Step [725/910], Loss: 3.3544 (poly: 0.0025, lower: 0.0000, upper: 0.0000, cls_loss: 0.0000, line_iou: 0.0013, conf: 0.1079), s/iter: 0.1013, lr: 3.0e-04
[2024-12-25 21:59:38,894] [INFO] Epoch [22/2695], Step [726/910], Loss: 3.3501 (poly: 0.0651, lower: 0.0000, upper: 0.0002, cls_loss: 0.0000, line_iou: 0.0016, conf: 0.1950), s/iter: 0.1012, lr: 3.0e-04
[2024-12-25 21:59:39,001] [INFO] Epoch [22/2695], Step [727/910], Loss: 3.3460 (poly: 0.1237, lower: 0.0000, upper: 0.0001, cls_loss: 0.0000, line_iou: 0.0016, conf: 0.2196), s/iter: 0.1011, lr: 3.0e-04
[2024-12-25 21:59:39,103] [INFO] Epoch [22/2695], Step [728/910], Loss: 3.3419 (poly: 0.1256, lower: 0.0000, upper: 0.0001, cls_loss: 0.0000, line_iou: 0.0016, conf: 0.2196), s/iter: 0.1010, lr: 3.0e-04
[2024-12-25 21:59:39,144] [INFO] Weight SoftAdapt Loss tensor([0.4967, 0.0017, 0.0017, 0.0017, 0.0017, 0.4967], dtype=torch.float64)
[2024-12-25 21:59:39,194] [INFO] Epoch [22/2695], Step [729/910], Loss: 3.3379 (poly: 0.0051, lower: 0.0000, upper: 0.0000, cls_loss: 0.0000, line_iou: 0.4054, conf: 0.0006), s/iter: 0.1007, lr: 3.0e-04
[2024-12-25 21:59:39,278] [INFO] Epoch [22/2695], Step [730/910], Loss: 3.3338 (poly: 0.0033, lower: 0.0000, upper: 0.0000, cls_loss: 0.0000, line_iou: 0.3812, conf: 0.0004), s/iter: 0.1003, lr: 3.0e-04
[2024-12-25 21:59:39,399] [INFO] Epoch [22/2695], Step [731/910], Loss: 3.3299 (poly: 0.0301, lower: 0.0000, upper: 0.0001, cls_loss: 0.0000, line_iou: 0.4332, conf: 0.0004), s/iter: 0.1005, lr: 3.0e-04
[2024-12-25 21:59:39,507] [INFO] Epoch [22/2695], Step [732/910], Loss: 3.3259 (poly: 0.0031, lower: 0.0000, upper: 0.0000, cls_loss: 0.0000, line_iou: 0.3755, conf: 0.0004), s/iter: 0.1005, lr: 3.0e-04
[2024-12-25 21:59:39,614] [INFO] Epoch [22/2695], Step [733/910], Loss: 3.3219 (poly: 0.0034, lower: 0.0000, upper: 0.0000, cls_loss: 0.0000, line_iou: 0.3811, conf: 0.0004), s/iter: 0.1004, lr: 3.0e-04
[2024-12-25 21:59:39,708] [INFO] Epoch [22/2695], Step [734/910], Loss: 3.3179 (poly: 0.0077, lower: 0.0000, upper: 0.0000, cls_loss: 0.0000, line_iou: 0.4477, conf: 0.0006), s/iter: 0.0999, lr: 3.0e-04
[2024-12-25 21:59:39,808] [INFO] Epoch [22/2695], Step [735/910], Loss: 3.3141 (poly: 0.0913, lower: 0.0000, upper: 0.0000, cls_loss: 0.0000, line_iou: 0.3865, conf: 0.0007), s/iter: 0.0997, lr: 3.0e-04
[2024-12-25 21:59:39,917] [INFO] Epoch [22/2695], Step [736/910], Loss: 3.3101 (poly: 0.0037, lower: 0.0000, upper: 0.0000, cls_loss: 0.0000, line_iou: 0.3952, conf: 0.0004), s/iter: 0.0997, lr: 3.0e-04
[2024-12-25 21:59:40,029] [INFO] Epoch [22/2695], Step [737/910], Loss: 3.3062 (poly: 0.0047, lower: 0.0000, upper: 0.0000, cls_loss: 0.0000, line_iou: 0.4051, conf: 0.0004), s/iter: 0.0998, lr: 3.0e-04
[2024-12-25 21:59:40,088] [INFO] Weight SoftAdapt Loss tensor([0.4967, 0.0017, 0.0017, 0.0017, 0.4967, 0.0017], dtype=torch.float64)
[2024-12-25 21:59:40,147] [INFO] Epoch [22/2695], Step [738/910], Loss: 3.3026 (poly: 0.0002, lower: 0.0000, upper: 0.0001, cls_loss: 0.0000, line_iou: 0.4834, conf: 0.1950), s/iter: 0.0999, lr: 3.0e-04
[2024-12-25 21:59:40,261] [INFO] Epoch [22/2695], Step [739/910], Loss: 3.2988 (poly: 0.0000, lower: 0.0000, upper: 0.0000, cls_loss: 0.0000, line_iou: 0.3932, conf: 0.1078), s/iter: 0.0999, lr: 3.0e-04
[2024-12-25 21:59:40,389] [INFO] Epoch [22/2695], Step [740/910], Loss: 3.2952 (poly: 0.0003, lower: 0.0000, upper: 0.0000, cls_loss: 0.0000, line_iou: 0.4099, conf: 0.2195), s/iter: 0.0999, lr: 3.0e-04
[2024-12-25 21:59:40,502] [INFO] Epoch [22/2695], Step [741/910], Loss: 3.2915 (poly: 0.0000, lower: 0.0000, upper: 0.0000, cls_loss: 0.0000, line_iou: 0.4240, conf: 0.1077), s/iter: 0.1000, lr: 3.0e-04
[2024-12-25 21:59:40,619] [INFO] Epoch [22/2695], Step [742/910], Loss: 3.2878 (poly: 0.0000, lower: 0.0000, upper: 0.0000, cls_loss: 0.0000, line_iou: 0.4200, conf: 0.1078), s/iter: 0.1000, lr: 3.0e-04
[2024-12-25 21:59:40,738] [INFO] Epoch [22/2695], Step [743/910], Loss: 3.2841 (poly: 0.0000, lower: 0.0000, upper: 0.0000, cls_loss: 0.0000, line_iou: 0.4448, conf: 0.1077), s/iter: 0.1000, lr: 3.0e-04
[2024-12-25 21:59:40,853] [INFO] Epoch [22/2695], Step [744/910], Loss: 3.2804 (poly: 0.0000, lower: 0.0000, upper: 0.0000, cls_loss: 0.0000, line_iou: 0.4402, conf: 0.1078), s/iter: 0.0999, lr: 3.0e-04
[2024-12-25 21:59:40,980] [INFO] Epoch [22/2695], Step [745/910], Loss: 3.2770 (poly: 0.0004, lower: 0.0000, upper: 0.0001, cls_loss: 0.0000, line_iou: 0.4835, conf: 0.2194), s/iter: 0.0999, lr: 3.0e-04
[2024-12-25 21:59:41,093] [INFO] Epoch [22/2695], Step [746/910], Loss: 3.2733 (poly: 0.0000, lower: 0.0000, upper: 0.0000, cls_loss: 0.0000, line_iou: 0.3705, conf: 0.1951), s/iter: 0.0998, lr: 3.0e-04
[2024-12-25 21:59:41,145] [INFO] Weight SoftAdapt Loss tensor([0.0017, 0.0017, 0.0017, 0.0017, 0.4967, 0.4967], dtype=torch.float64)
[2024-12-25 21:59:41,196] [INFO] Epoch [22/2695], Step [747/910], Loss: 3.2693 (poly: 0.0647, lower: 0.0000, upper: 0.0002, cls_loss: 0.0000, line_iou: 0.0016, conf: 0.1950), s/iter: 0.0996, lr: 3.0e-04
[2024-12-25 21:59:41,325] [INFO] Epoch [22/2695], Step [748/910], Loss: 3.2653 (poly: 0.0554, lower: 0.0000, upper: 0.0002, cls_loss: 0.0000, line_iou: 0.0016, conf: 0.1950), s/iter: 0.0997, lr: 3.0e-04
[2024-12-25 21:59:41,441] [INFO] Epoch [22/2695], Step [749/910], Loss: 3.2614 (poly: 0.1510, lower: 0.0000, upper: 0.0001, cls_loss: 0.0000, line_iou: 0.0016, conf: 0.2195), s/iter: 0.0997, lr: 3.0e-04
[2024-12-25 21:59:41,557] [INFO] Epoch [22/2695], Step [750/910], Loss: 3.2572 (poly: 0.0040, lower: 0.0000, upper: 0.0000, cls_loss: 0.0000, line_iou: 0.0014, conf: 0.1077), s/iter: 0.0997, lr: 3.0e-04
[2024-12-25 21:59:41,676] [INFO] Epoch [22/2695], Step [751/910], Loss: 3.2533 (poly: 0.1229, lower: 0.0000, upper: 0.0001, cls_loss: 0.0000, line_iou: 0.0016, conf: 0.2193), s/iter: 0.1000, lr: 3.0e-04
[2024-12-25 21:59:41,764] [INFO] Epoch [22/2695], Step [752/910], Loss: 3.2495 (poly: 0.1592, lower: 0.0000, upper: 0.0000, cls_loss: 0.0000, line_iou: 0.0016, conf: 0.2193), s/iter: 0.0999, lr: 3.0e-04
[2024-12-25 21:59:41,873] [INFO] Epoch [22/2695], Step [753/910], Loss: 3.2454 (poly: 0.0375, lower: 0.0000, upper: 0.0001, cls_loss: 0.0000, line_iou: 0.0016, conf: 0.1077), s/iter: 0.1000, lr: 3.0e-04
[2024-12-25 21:59:41,990] [INFO] Epoch [22/2695], Step [754/910], Loss: 3.2412 (poly: 0.0059, lower: 0.0000, upper: 0.0000, cls_loss: 0.0000, line_iou: 0.0014, conf: 0.1077), s/iter: 0.1001, lr: 3.0e-04
[2024-12-25 21:59:42,104] [INFO] Epoch [22/2695], Step [755/910], Loss: 3.2373 (poly: 0.0676, lower: 0.0000, upper: 0.0002, cls_loss: 0.0000, line_iou: 0.0016, conf: 0.1950), s/iter: 0.1001, lr: 3.0e-04
[2024-12-25 21:59:42,166] [INFO] Weight SoftAdapt Loss tensor([0.4967, 0.0017, 0.0017, 0.0017, 0.0017, 0.4967], dtype=torch.float64)
[2024-12-25 21:59:42,240] [INFO] Epoch [22/2695], Step [756/910], Loss: 3.2337 (poly: 0.0569, lower: 0.0000, upper: 0.0001, cls_loss: 0.0000, line_iou: 0.4740, conf: 0.0007), s/iter: 0.1004, lr: 3.0e-04
[2024-12-25 21:59:42,349] [INFO] Epoch [22/2695], Step [757/910], Loss: 3.2300 (poly: 0.0064, lower: 0.0000, upper: 0.0000, cls_loss: 0.0000, line_iou: 0.4404, conf: 0.0004), s/iter: 0.1002, lr: 3.0e-04
[2024-12-25 21:59:42,450] [INFO] Epoch [22/2695], Step [758/910], Loss: 3.2265 (poly: 0.1117, lower: 0.0000, upper: 0.0000, cls_loss: 0.0000, line_iou: 0.4556, conf: 0.0007), s/iter: 0.1000, lr: 3.0e-04
[2024-12-25 21:59:42,570] [INFO] Epoch [22/2695], Step [759/910], Loss: 3.2228 (poly: 0.0074, lower: 0.0000, upper: 0.0000, cls_loss: 0.0000, line_iou: 0.4264, conf: 0.0004), s/iter: 0.1000, lr: 3.0e-04
[2024-12-25 21:59:42,698] [INFO] Epoch [22/2695], Step [760/910], Loss: 3.2191 (poly: 0.0030, lower: 0.0000, upper: 0.0000, cls_loss: 0.0000, line_iou: 0.4011, conf: 0.0004), s/iter: 0.1002, lr: 3.0e-04
[2024-12-25 21:59:42,822] [INFO] Epoch [22/2695], Step [761/910], Loss: 3.2154 (poly: 0.0059, lower: 0.0000, upper: 0.0000, cls_loss: 0.0000, line_iou: 0.4124, conf: 0.0004), s/iter: 0.1001, lr: 3.0e-04
[2024-12-25 21:59:42,950] [INFO] Epoch [22/2695], Step [762/910], Loss: 3.2118 (poly: 0.0047, lower: 0.0000, upper: 0.0000, cls_loss: 0.0000, line_iou: 0.4203, conf: 0.0004), s/iter: 0.1001, lr: 3.0e-04
[2024-12-25 21:59:43,068] [INFO] Epoch [22/2695], Step [763/910], Loss: 3.2081 (poly: 0.0026, lower: 0.0000, upper: 0.0000, cls_loss: 0.0000, line_iou: 0.3716, conf: 0.0006), s/iter: 0.0999, lr: 3.0e-04
[2024-12-25 21:59:43,183] [INFO] Epoch [22/2695], Step [764/910], Loss: 3.2046 (poly: 0.0513, lower: 0.0000, upper: 0.0002, cls_loss: 0.0000, line_iou: 0.4783, conf: 0.0006), s/iter: 0.1000, lr: 3.0e-04
[2024-12-25 21:59:43,235] [INFO] Weight SoftAdapt Loss tensor([0.4967, 0.0017, 0.0017, 0.0017, 0.4967, 0.0017], dtype=torch.float64)
[2024-12-25 21:59:43,287] [INFO] Epoch [22/2695], Step [765/910], Loss: 3.2011 (poly: 0.0000, lower: 0.0000, upper: 0.0000, cls_loss: 0.0000, line_iou: 0.4212, conf: 0.1076), s/iter: 0.1000, lr: 3.0e-04
[2024-12-25 21:59:43,374] [INFO] Epoch [22/2695], Step [766/910], Loss: 3.1975 (poly: 0.0000, lower: 0.0000, upper: 0.0000, cls_loss: 0.0000, line_iou: 0.4008, conf: 0.1076), s/iter: 0.0996, lr: 3.0e-04
[2024-12-25 21:59:43,492] [INFO] Epoch [22/2695], Step [767/910], Loss: 3.1943 (poly: 0.0005, lower: 0.0000, upper: 0.0001, cls_loss: 0.0000, line_iou: 0.4960, conf: 0.2192), s/iter: 0.0998, lr: 3.0e-04
[2024-12-25 21:59:43,593] [INFO] Epoch [22/2695], Step [768/910], Loss: 3.1908 (poly: 0.0000, lower: 0.0000, upper: 0.0000, cls_loss: 0.0000, line_iou: 0.4164, conf: 0.1076), s/iter: 0.0998, lr: 3.0e-04
[2024-12-25 21:59:43,691] [INFO] Epoch [22/2695], Step [769/910], Loss: 3.1876 (poly: 0.0002, lower: 0.0000, upper: 0.0001, cls_loss: 0.0000, line_iou: 0.4937, conf: 0.1949), s/iter: 0.0998, lr: 3.0e-04
[2024-12-25 21:59:43,819] [INFO] Epoch [22/2695], Step [770/910], Loss: 3.1841 (poly: 0.0000, lower: 0.0000, upper: 0.0000, cls_loss: 0.0000, line_iou: 0.3943, conf: 0.1076), s/iter: 0.1000, lr: 3.0e-04
[2024-12-25 21:59:43,925] [INFO] Epoch [22/2695], Step [771/910], Loss: 3.1807 (poly: 0.0000, lower: 0.0000, upper: 0.0000, cls_loss: 0.0000, line_iou: 0.3921, conf: 0.1949), s/iter: 0.1001, lr: 3.0e-04
[2024-12-25 21:59:44,042] [INFO] Epoch [22/2695], Step [772/910], Loss: 3.1775 (poly: 0.0004, lower: 0.0000, upper: 0.0002, cls_loss: 0.0000, line_iou: 0.4881, conf: 0.2191), s/iter: 0.1004, lr: 3.0e-04
[2024-12-25 21:59:44,147] [INFO] Epoch [22/2695], Step [773/910], Loss: 3.1741 (poly: 0.0000, lower: 0.0000, upper: 0.0000, cls_loss: 0.0000, line_iou: 0.4618, conf: 0.1075), s/iter: 0.1004, lr: 3.0e-04
[2024-12-25 21:59:44,190] [INFO] Weight SoftAdapt Loss tensor([0.0017, 0.0017, 0.0017, 0.0017, 0.4967, 0.4967], dtype=torch.float64)
[2024-12-25 21:59:44,244] [INFO] Epoch [22/2695], Step [774/910], Loss: 3.1702 (poly: 0.0025, lower: 0.0000, upper: 0.0000, cls_loss: 0.0000, line_iou: 0.0013, conf: 0.1075), s/iter: 0.1002, lr: 3.0e-04
[2024-12-25 21:59:44,341] [INFO] Epoch [22/2695], Step [775/910], Loss: 3.1665 (poly: 0.1202, lower: 0.0000, upper: 0.0002, cls_loss: 0.0000, line_iou: 0.0017, conf: 0.2191), s/iter: 0.1000, lr: 3.0e-04
[2024-12-25 21:59:44,441] [INFO] Epoch [22/2695], Step [776/910], Loss: 3.1626 (poly: 0.0038, lower: 0.0000, upper: 0.0000, cls_loss: 0.0000, line_iou: 0.0013, conf: 0.1075), s/iter: 0.1001, lr: 3.0e-04
[2024-12-25 21:59:44,533] [INFO] Epoch [22/2695], Step [777/910], Loss: 3.1587 (poly: 0.0070, lower: 0.0000, upper: 0.0000, cls_loss: 0.0000, line_iou: 0.0015, conf: 0.1075), s/iter: 0.1001, lr: 3.0e-04
[2024-12-25 21:59:44,625] [INFO] Epoch [22/2695], Step [778/910], Loss: 3.1548 (poly: 0.0038, lower: 0.0000, upper: 0.0000, cls_loss: 0.0000, line_iou: 0.0015, conf: 0.1075), s/iter: 0.1000, lr: 3.0e-04
[2024-12-25 21:59:44,719] [INFO] Epoch [22/2695], Step [779/910], Loss: 3.1511 (poly: 0.0980, lower: 0.0000, upper: 0.0000, cls_loss: 0.0000, line_iou: 0.0015, conf: 0.2190), s/iter: 0.1000, lr: 3.0e-04
[2024-12-25 21:59:44,826] [INFO] Epoch [22/2695], Step [780/910], Loss: 3.1472 (poly: 0.0046, lower: 0.0000, upper: 0.0000, cls_loss: 0.0000, line_iou: 0.0015, conf: 0.1075), s/iter: 0.1000, lr: 3.0e-04
[2024-12-25 21:59:44,921] [INFO] Epoch [22/2695], Step [781/910], Loss: 3.1435 (poly: 0.0053, lower: 0.0000, upper: 0.0000, cls_loss: 0.0000, line_iou: 0.0015, conf: 0.1949), s/iter: 0.1000, lr: 3.0e-04
[2024-12-25 21:59:45,020] [INFO] Epoch [22/2695], Step [782/910], Loss: 3.1396 (poly: 0.0024, lower: 0.0000, upper: 0.0000, cls_loss: 0.0000, line_iou: 0.0014, conf: 0.1074), s/iter: 0.0999, lr: 3.0e-04
[2024-12-25 21:59:45,065] [INFO] Weight SoftAdapt Loss tensor([0.4967, 0.0017, 0.0017, 0.0017, 0.0017, 0.4967], dtype=torch.float64)
[2024-12-25 21:59:45,121] [INFO] Epoch [22/2695], Step [783/910], Loss: 3.1361 (poly: 0.0042, lower: 0.0000, upper: 0.0000, cls_loss: 0.0000, line_iou: 0.4421, conf: 0.0004), s/iter: 0.1000, lr: 3.0e-04
[2024-12-25 21:59:45,233] [INFO] Epoch [22/2695], Step [784/910], Loss: 3.1327 (poly: 0.0031, lower: 0.0000, upper: 0.0000, cls_loss: 0.0000, line_iou: 0.4248, conf: 0.0004), s/iter: 0.1000, lr: 3.0e-04
[2024-12-25 21:59:45,342] [INFO] Epoch [22/2695], Step [785/910], Loss: 3.1293 (poly: 0.0026, lower: 0.0000, upper: 0.0000, cls_loss: 0.0000, line_iou: 0.4369, conf: 0.0004), s/iter: 0.1002, lr: 3.0e-04
[2024-12-25 21:59:45,439] [INFO] Epoch [22/2695], Step [786/910], Loss: 3.1260 (poly: 0.1206, lower: 0.0000, upper: 0.0001, cls_loss: 0.0000, line_iou: 0.4814, conf: 0.0007), s/iter: 0.1002, lr: 3.0e-04
[2024-12-25 21:59:45,540] [INFO] Epoch [22/2695], Step [787/910], Loss: 3.1226 (poly: 0.0034, lower: 0.0000, upper: 0.0000, cls_loss: 0.0000, line_iou: 0.4050, conf: 0.0006), s/iter: 0.1000, lr: 3.0e-04
[2024-12-25 21:59:45,647] [INFO] Epoch [22/2695], Step [788/910], Loss: 3.1194 (poly: 0.1232, lower: 0.0000, upper: 0.0001, cls_loss: 0.0000, line_iou: 0.4812, conf: 0.0007), s/iter: 0.1000, lr: 3.0e-04
[2024-12-25 21:59:45,756] [INFO] Epoch [22/2695], Step [789/910], Loss: 3.1160 (poly: 0.0060, lower: 0.0000, upper: 0.0000, cls_loss: 0.0000, line_iou: 0.4477, conf: 0.0004), s/iter: 0.1003, lr: 3.0e-04
[2024-12-25 21:59:45,851] [INFO] Epoch [22/2695], Step [790/910], Loss: 3.1127 (poly: 0.0098, lower: 0.0000, upper: 0.0001, cls_loss: 0.0000, line_iou: 0.4512, conf: 0.0004), s/iter: 0.1004, lr: 3.0e-04
[2024-12-25 21:59:45,947] [INFO] Epoch [22/2695], Step [791/910], Loss: 3.1093 (poly: 0.0050, lower: 0.0000, upper: 0.0000, cls_loss: 0.0000, line_iou: 0.4303, conf: 0.0004), s/iter: 0.1004, lr: 3.0e-04
[2024-12-25 21:59:46,008] [INFO] Weight SoftAdapt Loss tensor([0.4967, 0.0017, 0.0017, 0.0017, 0.4967, 0.0017], dtype=torch.float64)
[2024-12-25 21:59:46,064] [INFO] Epoch [22/2695], Step [792/910], Loss: 3.1060 (poly: 0.0000, lower: 0.0000, upper: 0.0000, cls_loss: 0.0000, line_iou: 0.4433, conf: 0.1073), s/iter: 0.1006, lr: 3.0e-04
[2024-12-25 21:59:46,175] [INFO] Epoch [22/2695], Step [793/910], Loss: 3.1028 (poly: 0.0000, lower: 0.0000, upper: 0.0000, cls_loss: 0.0000, line_iou: 0.4132, conf: 0.1073), s/iter: 0.1007, lr: 3.0e-04
[2024-12-25 21:59:46,293] [INFO] Epoch [22/2695], Step [794/910], Loss: 3.0997 (poly: 0.0002, lower: 0.0000, upper: 0.0002, cls_loss: 0.0000, line_iou: 0.4752, conf: 0.1949), s/iter: 0.1010, lr: 3.0e-04
[2024-12-25 21:59:46,392] [INFO] Epoch [22/2695], Step [795/910], Loss: 3.0965 (poly: 0.0000, lower: 0.0000, upper: 0.0000, cls_loss: 0.0000, line_iou: 0.4079, conf: 0.1073), s/iter: 0.1012, lr: 3.0e-04
[2024-12-25 21:59:46,499] [INFO] Epoch [22/2695], Step [796/910], Loss: 3.0932 (poly: 0.0000, lower: 0.0000, upper: 0.0000, cls_loss: 0.0000, line_iou: 0.4097, conf: 0.1073), s/iter: 0.1014, lr: 3.0e-04
[2024-12-25 21:59:46,599] [INFO] Epoch [22/2695], Step [797/910], Loss: 3.0900 (poly: 0.0000, lower: 0.0000, upper: 0.0001, cls_loss: 0.0000, line_iou: 0.4082, conf: 0.1073), s/iter: 0.1014, lr: 3.0e-04
[2024-12-25 21:59:46,717] [INFO] Epoch [22/2695], Step [798/910], Loss: 3.0868 (poly: 0.0000, lower: 0.0000, upper: 0.0000, cls_loss: 0.0000, line_iou: 0.4166, conf: 0.1072), s/iter: 0.1014, lr: 3.0e-04
[2024-12-25 21:59:46,810] [INFO] Epoch [22/2695], Step [799/910], Loss: 3.0836 (poly: 0.0000, lower: 0.0000, upper: 0.0000, cls_loss: 0.0000, line_iou: 0.4101, conf: 0.1073), s/iter: 0.1012, lr: 3.0e-04
[2024-12-25 21:59:46,906] [INFO] Epoch [22/2695], Step [800/910], Loss: 3.0805 (poly: 0.0003, lower: 0.0000, upper: 0.0000, cls_loss: 0.0000, line_iou: 0.4236, conf: 0.2189), s/iter: 0.1012, lr: 3.0e-04
[2024-12-25 21:59:46,960] [INFO] Weight SoftAdapt Loss tensor([0.0017, 0.0017, 0.0017, 0.0017, 0.4967, 0.4967], dtype=torch.float64)
[2024-12-25 21:59:47,011] [INFO] Epoch [22/2695], Step [801/910], Loss: 3.0768 (poly: 0.0034, lower: 0.0000, upper: 0.0000, cls_loss: 0.0000, line_iou: 0.0013, conf: 0.1072), s/iter: 0.1012, lr: 3.0e-04
[2024-12-25 21:59:47,097] [INFO] Epoch [22/2695], Step [802/910], Loss: 3.0731 (poly: 0.0036, lower: 0.0000, upper: 0.0000, cls_loss: 0.0000, line_iou: 0.0014, conf: 0.1072), s/iter: 0.1012, lr: 3.0e-04
[2024-12-25 21:59:47,193] [INFO] Epoch [22/2695], Step [803/910], Loss: 3.0697 (poly: 0.0986, lower: 0.0000, upper: 0.0001, cls_loss: 0.0000, line_iou: 0.0016, conf: 0.2189), s/iter: 0.1011, lr: 3.0e-04
[2024-12-25 21:59:47,312] [INFO] Epoch [22/2695], Step [804/910], Loss: 3.0663 (poly: 0.1280, lower: 0.0000, upper: 0.0001, cls_loss: 0.0000, line_iou: 0.0016, conf: 0.2189), s/iter: 0.1012, lr: 3.0e-04
[2024-12-25 21:59:47,427] [INFO] Epoch [22/2695], Step [805/910], Loss: 3.0626 (poly: 0.0038, lower: 0.0000, upper: 0.0000, cls_loss: 0.0000, line_iou: 0.0014, conf: 0.1071), s/iter: 0.1012, lr: 3.0e-04
[2024-12-25 21:59:47,526] [INFO] Epoch [22/2695], Step [806/910], Loss: 3.0593 (poly: 0.1244, lower: 0.0000, upper: 0.0001, cls_loss: 0.0000, line_iou: 0.0016, conf: 0.2189), s/iter: 0.1009, lr: 3.0e-04
[2024-12-25 21:59:47,645] [INFO] Epoch [22/2695], Step [807/910], Loss: 3.0556 (poly: 0.0033, lower: 0.0000, upper: 0.0000, cls_loss: 0.0000, line_iou: 0.0014, conf: 0.1071), s/iter: 0.1010, lr: 3.0e-04
[2024-12-25 21:59:47,764] [INFO] Epoch [22/2695], Step [808/910], Loss: 3.0521 (poly: 0.0045, lower: 0.0000, upper: 0.0000, cls_loss: 0.0000, line_iou: 0.0013, conf: 0.1950), s/iter: 0.1013, lr: 3.0e-04
[2024-12-25 21:59:47,871] [INFO] Epoch [22/2695], Step [809/910], Loss: 3.0484 (poly: 0.0029, lower: 0.0000, upper: 0.0000, cls_loss: 0.0000, line_iou: 0.0014, conf: 0.1071), s/iter: 0.1014, lr: 3.0e-04
[2024-12-25 21:59:47,921] [INFO] Weight SoftAdapt Loss tensor([0.4967, 0.0017, 0.0017, 0.0017, 0.0017, 0.4967], dtype=torch.float64)
[2024-12-25 21:59:47,978] [INFO] Epoch [22/2695], Step [810/910], Loss: 3.0454 (poly: 0.0671, lower: 0.0000, upper: 0.0002, cls_loss: 0.0000, line_iou: 0.4946, conf: 0.0007), s/iter: 0.1015, lr: 3.0e-04
[2024-12-25 21:59:48,075] [INFO] Epoch [22/2695], Step [811/910], Loss: 3.0421 (poly: 0.0037, lower: 0.0000, upper: 0.0001, cls_loss: 0.0000, line_iou: 0.4153, conf: 0.0007), s/iter: 0.1014, lr: 3.0e-04
[2024-12-25 21:59:48,181] [INFO] Epoch [22/2695], Step [812/910], Loss: 3.0389 (poly: 0.0040, lower: 0.0000, upper: 0.0000, cls_loss: 0.0000, line_iou: 0.4426, conf: 0.0004), s/iter: 0.1015, lr: 3.0e-04
[2024-12-25 21:59:48,290] [INFO] Epoch [22/2695], Step [813/910], Loss: 3.0358 (poly: 0.0042, lower: 0.0000, upper: 0.0000, cls_loss: 0.0000, line_iou: 0.4446, conf: 0.0004), s/iter: 0.1016, lr: 3.0e-04
[2024-12-25 21:59:48,391] [INFO] Epoch [22/2695], Step [814/910], Loss: 3.0326 (poly: 0.0045, lower: 0.0000, upper: 0.0000, cls_loss: 0.0000, line_iou: 0.4372, conf: 0.0004), s/iter: 0.1016, lr: 3.0e-04
[2024-12-25 21:59:48,491] [INFO] Epoch [22/2695], Step [815/910], Loss: 3.0295 (poly: 0.0587, lower: 0.0000, upper: 0.0002, cls_loss: 0.0000, line_iou: 0.4907, conf: 0.0004), s/iter: 0.1017, lr: 3.0e-04
[2024-12-25 21:59:48,609] [INFO] Epoch [22/2695], Step [816/910], Loss: 3.0265 (poly: 0.0672, lower: 0.0000, upper: 0.0002, cls_loss: 0.0000, line_iou: 0.4899, conf: 0.0007), s/iter: 0.1020, lr: 3.0e-04
[2024-12-25 21:59:48,746] [INFO] Epoch [22/2695], Step [817/910], Loss: 3.0233 (poly: 0.0049, lower: 0.0000, upper: 0.0000, cls_loss: 0.0000, line_iou: 0.4008, conf: 0.0004), s/iter: 0.1023, lr: 3.0e-04
[2024-12-25 21:59:48,868] [INFO] Epoch [22/2695], Step [818/910], Loss: 3.0201 (poly: 0.0042, lower: 0.0000, upper: 0.0000, cls_loss: 0.0000, line_iou: 0.4113, conf: 0.0004), s/iter: 0.1026, lr: 3.0e-04
[2024-12-25 21:59:48,917] [INFO] Weight SoftAdapt Loss tensor([0.4967, 0.0017, 0.0017, 0.0017, 0.4967, 0.0017], dtype=torch.float64)
[2024-12-25 21:59:48,970] [INFO] Epoch [22/2695], Step [819/910], Loss: 3.0173 (poly: 0.0005, lower: 0.0000, upper: 0.0001, cls_loss: 0.0000, line_iou: 0.4952, conf: 0.2187), s/iter: 0.1026, lr: 3.0e-04
[2024-12-25 21:59:49,075] [INFO] Epoch [22/2695], Step [820/910], Loss: 3.0144 (poly: 0.0003, lower: 0.0000, upper: 0.0000, cls_loss: 0.0000, line_iou: 0.4287, conf: 0.2187), s/iter: 0.1028, lr: 3.0e-04
[2024-12-25 21:59:49,183] [INFO] Epoch [22/2695], Step [821/910], Loss: 3.0113 (poly: 0.0000, lower: 0.0000, upper: 0.0000, cls_loss: 0.0000, line_iou: 0.3849, conf: 0.1070), s/iter: 0.1029, lr: 3.0e-04
[2024-12-25 21:59:49,274] [INFO] Epoch [22/2695], Step [822/910], Loss: 3.0083 (poly: 0.0000, lower: 0.0000, upper: 0.0000, cls_loss: 0.0000, line_iou: 0.3848, conf: 0.1069), s/iter: 0.1029, lr: 3.0e-04
[2024-12-25 21:59:49,365] [INFO] Epoch [22/2695], Step [823/910], Loss: 3.0053 (poly: 0.0000, lower: 0.0000, upper: 0.0000, cls_loss: 0.0000, line_iou: 0.4377, conf: 0.1069), s/iter: 0.1030, lr: 3.0e-04
[2024-12-25 21:59:49,479] [INFO] Epoch [22/2695], Step [824/910], Loss: 3.0025 (poly: 0.0004, lower: 0.0000, upper: 0.0001, cls_loss: 0.0000, line_iou: 0.4926, conf: 0.2187), s/iter: 0.1032, lr: 3.0e-04
[2024-12-25 21:59:49,602] [INFO] Epoch [22/2695], Step [825/910], Loss: 2.9995 (poly: 0.0000, lower: 0.0000, upper: 0.0000, cls_loss: 0.0000, line_iou: 0.4483, conf: 0.1069), s/iter: 0.1033, lr: 3.0e-04
[2024-12-25 21:59:49,710] [INFO] Epoch [22/2695], Step [826/910], Loss: 2.9965 (poly: 0.0000, lower: 0.0000, upper: 0.0000, cls_loss: 0.0000, line_iou: 0.4323, conf: 0.1069), s/iter: 0.1033, lr: 3.0e-04
[2024-12-25 21:59:49,835] [INFO] Epoch [22/2695], Step [827/910], Loss: 2.9938 (poly: 0.0004, lower: 0.0000, upper: 0.0001, cls_loss: 0.0000, line_iou: 0.4801, conf: 0.2185), s/iter: 0.1035, lr: 3.0e-04
[2024-12-25 21:59:49,897] [INFO] Weight SoftAdapt Loss tensor([0.0017, 0.0017, 0.0017, 0.0017, 0.4967, 0.4967], dtype=torch.float64)
[2024-12-25 21:59:49,957] [INFO] Epoch [22/2695], Step [828/910], Loss: 2.9903 (poly: 0.0059, lower: 0.0000, upper: 0.0000, cls_loss: 0.0000, line_iou: 0.0015, conf: 0.1069), s/iter: 0.1036, lr: 3.0e-04
[2024-12-25 21:59:50,047] [INFO] Epoch [22/2695], Step [829/910], Loss: 2.9871 (poly: 0.1244, lower: 0.0000, upper: 0.0001, cls_loss: 0.0000, line_iou: 0.0016, conf: 0.2184), s/iter: 0.1037, lr: 3.0e-04
[2024-12-25 21:59:50,163] [INFO] Epoch [22/2695], Step [830/910], Loss: 2.9837 (poly: 0.0040, lower: 0.0000, upper: 0.0000, cls_loss: 0.0000, line_iou: 0.0014, conf: 0.1952), s/iter: 0.1039, lr: 3.0e-04
[2024-12-25 21:59:50,261] [INFO] Epoch [22/2695], Step [831/910], Loss: 2.9806 (poly: 0.1264, lower: 0.0000, upper: 0.0001, cls_loss: 0.0000, line_iou: 0.0016, conf: 0.2183), s/iter: 0.1037, lr: 3.0e-04
[2024-12-25 21:59:50,377] [INFO] Epoch [22/2695], Step [832/910], Loss: 2.9771 (poly: 0.0078, lower: 0.0000, upper: 0.0000, cls_loss: 0.0000, line_iou: 0.0015, conf: 0.1068), s/iter: 0.1038, lr: 3.0e-04
[2024-12-25 21:59:50,493] [INFO] Epoch [22/2695], Step [833/910], Loss: 2.9737 (poly: 0.0053, lower: 0.0000, upper: 0.0000, cls_loss: 0.0000, line_iou: 0.0014, conf: 0.1068), s/iter: 0.1039, lr: 3.0e-04
[2024-12-25 21:59:50,585] [INFO] Epoch [22/2695], Step [834/910], Loss: 2.9702 (poly: 0.0034, lower: 0.0000, upper: 0.0000, cls_loss: 0.0000, line_iou: 0.0013, conf: 0.1068), s/iter: 0.1039, lr: 3.0e-04
[2024-12-25 21:59:50,686] [INFO] Epoch [22/2695], Step [835/910], Loss: 2.9668 (poly: 0.0044, lower: 0.0000, upper: 0.0000, cls_loss: 0.0000, line_iou: 0.0013, conf: 0.1068), s/iter: 0.1040, lr: 3.0e-04
[2024-12-25 21:59:50,772] [INFO] Epoch [22/2695], Step [836/910], Loss: 2.9634 (poly: 0.0029, lower: 0.0000, upper: 0.0000, cls_loss: 0.0000, line_iou: 0.0013, conf: 0.1068), s/iter: 0.1037, lr: 3.0e-04
[2024-12-25 21:59:50,823] [INFO] Weight SoftAdapt Loss tensor([0.4967, 0.0017, 0.0017, 0.0017, 0.0017, 0.4967], dtype=torch.float64)
[2024-12-25 21:59:50,885] [INFO] Epoch [22/2695], Step [837/910], Loss: 2.9605 (poly: 0.0992, lower: 0.0000, upper: 0.0000, cls_loss: 0.0000, line_iou: 0.3985, conf: 0.0007), s/iter: 0.1038, lr: 3.0e-04
[2024-12-25 21:59:51,003] [INFO] Epoch [22/2695], Step [838/910], Loss: 2.9575 (poly: 0.1030, lower: 0.0000, upper: 0.0000, cls_loss: 0.0000, line_iou: 0.4024, conf: 0.0007), s/iter: 0.1038, lr: 3.0e-04
[2024-12-25 21:59:51,116] [INFO] Epoch [22/2695], Step [839/910], Loss: 2.9545 (poly: 0.0048, lower: 0.0000, upper: 0.0000, cls_loss: 0.0000, line_iou: 0.3833, conf: 0.0007), s/iter: 0.1038, lr: 3.0e-04
[2024-12-25 21:59:51,218] [INFO] Epoch [22/2695], Step [840/910], Loss: 2.9514 (poly: 0.0039, lower: 0.0000, upper: 0.0000, cls_loss: 0.0000, line_iou: 0.4021, conf: 0.0004), s/iter: 0.1035, lr: 3.0e-04
[2024-12-25 21:59:51,320] [INFO] Epoch [22/2695], Step [841/910], Loss: 2.9486 (poly: 0.0697, lower: 0.0000, upper: 0.0002, cls_loss: 0.0000, line_iou: 0.4967, conf: 0.0007), s/iter: 0.1034, lr: 3.0e-04
[2024-12-25 21:59:51,423] [INFO] Epoch [22/2695], Step [842/910], Loss: 2.9456 (poly: 0.0053, lower: 0.0000, upper: 0.0000, cls_loss: 0.0000, line_iou: 0.4430, conf: 0.0004), s/iter: 0.1033, lr: 3.0e-04
[2024-12-25 21:59:51,536] [INFO] Epoch [22/2695], Step [843/910], Loss: 2.9429 (poly: 0.1363, lower: 0.0000, upper: 0.0002, cls_loss: 0.0000, line_iou: 0.4947, conf: 0.0007), s/iter: 0.1032, lr: 3.0e-04
[2024-12-25 21:59:51,638] [INFO] Epoch [22/2695], Step [844/910], Loss: 2.9401 (poly: 0.1144, lower: 0.0000, upper: 0.0000, cls_loss: 0.0000, line_iou: 0.4822, conf: 0.0007), s/iter: 0.1031, lr: 3.0e-04
[2024-12-25 21:59:51,728] [INFO] Epoch [22/2695], Step [845/910], Loss: 2.9373 (poly: 0.0697, lower: 0.0000, upper: 0.0002, cls_loss: 0.0000, line_iou: 0.4967, conf: 0.0007), s/iter: 0.1028, lr: 3.0e-04
[2024-12-25 21:59:51,772] [INFO] Weight SoftAdapt Loss tensor([0.4967, 0.0017, 0.0017, 0.0017, 0.4967, 0.0017], dtype=torch.float64)
[2024-12-25 21:59:51,821] [INFO] Epoch [22/2695], Step [846/910], Loss: 2.9345 (poly: 0.0000, lower: 0.0000, upper: 0.0000, cls_loss: 0.0000, line_iou: 0.4495, conf: 0.1067), s/iter: 0.1026, lr: 3.0e-04
[2024-12-25 21:59:51,907] [INFO] Epoch [22/2695], Step [847/910], Loss: 2.9318 (poly: 0.0004, lower: 0.0000, upper: 0.0000, cls_loss: 0.0000, line_iou: 0.4784, conf: 0.2182), s/iter: 0.1024, lr: 3.0e-04
[2024-12-25 21:59:51,992] [INFO] Epoch [22/2695], Step [848/910], Loss: 2.9290 (poly: 0.0000, lower: 0.0000, upper: 0.0000, cls_loss: 0.0000, line_iou: 0.4463, conf: 0.1066), s/iter: 0.1020, lr: 3.0e-04
[2024-12-25 21:59:52,082] [INFO] Epoch [22/2695], Step [849/910], Loss: 2.9264 (poly: 0.0004, lower: 0.0000, upper: 0.0001, cls_loss: 0.0000, line_iou: 0.4892, conf: 0.2181), s/iter: 0.1018, lr: 3.0e-04
[2024-12-25 21:59:52,193] [INFO] Epoch [22/2695], Step [850/910], Loss: 2.9236 (poly: 0.0000, lower: 0.0000, upper: 0.0000, cls_loss: 0.0000, line_iou: 0.4346, conf: 0.1066), s/iter: 0.1017, lr: 3.0e-04
[2024-12-25 21:59:52,282] [INFO] Epoch [22/2695], Step [851/910], Loss: 2.9208 (poly: 0.0000, lower: 0.0000, upper: 0.0000, cls_loss: 0.0000, line_iou: 0.3745, conf: 0.1954), s/iter: 0.1014, lr: 3.0e-04
[2024-12-25 21:59:52,386] [INFO] Epoch [22/2695], Step [852/910], Loss: 2.9182 (poly: 0.0000, lower: 0.0000, upper: 0.0000, cls_loss: 0.0000, line_iou: 0.4403, conf: 0.1955), s/iter: 0.1015, lr: 3.0e-04
[2024-12-25 21:59:52,497] [INFO] Epoch [22/2695], Step [853/910], Loss: 2.9154 (poly: 0.0000, lower: 0.0000, upper: 0.0000, cls_loss: 0.0000, line_iou: 0.4319, conf: 0.1066), s/iter: 0.1016, lr: 3.0e-04
[2024-12-25 21:59:52,609] [INFO] Epoch [22/2695], Step [854/910], Loss: 2.9126 (poly: 0.0000, lower: 0.0000, upper: 0.0000, cls_loss: 0.0000, line_iou: 0.3873, conf: 0.1954), s/iter: 0.1015, lr: 3.0e-04
[2024-12-25 21:59:52,670] [INFO] Weight SoftAdapt Loss tensor([0.0017, 0.0017, 0.0017, 0.0017, 0.4967, 0.4967], dtype=torch.float64)
[2024-12-25 21:59:52,724] [INFO] Epoch [22/2695], Step [855/910], Loss: 2.9095 (poly: 0.0693, lower: 0.0000, upper: 0.0001, cls_loss: 0.0000, line_iou: 0.0016, conf: 0.1954), s/iter: 0.1015, lr: 3.0e-04
[2024-12-25 21:59:52,824] [INFO] Epoch [22/2695], Step [856/910], Loss: 2.9063 (poly: 0.0052, lower: 0.0000, upper: 0.0000, cls_loss: 0.0000, line_iou: 0.0015, conf: 0.1066), s/iter: 0.1012, lr: 3.0e-04
[2024-12-25 21:59:52,911] [INFO] Epoch [22/2695], Step [857/910], Loss: 2.9030 (poly: 0.0019, lower: 0.0000, upper: 0.0000, cls_loss: 0.0000, line_iou: 0.0013, conf: 0.1066), s/iter: 0.1010, lr: 3.0e-04
[2024-12-25 21:59:52,999] [INFO] Epoch [22/2695], Step [858/910], Loss: 2.9000 (poly: 0.1181, lower: 0.0000, upper: 0.0001, cls_loss: 0.0000, line_iou: 0.0016, conf: 0.2181), s/iter: 0.1009, lr: 3.0e-04
[2024-12-25 21:59:53,083] [INFO] Epoch [22/2695], Step [859/910], Loss: 2.8969 (poly: 0.0029, lower: 0.0000, upper: 0.0000, cls_loss: 0.0000, line_iou: 0.0013, conf: 0.1953), s/iter: 0.1005, lr: 3.0e-04
[2024-12-25 21:59:53,171] [INFO] Epoch [22/2695], Step [860/910], Loss: 2.8938 (poly: 0.0645, lower: 0.0000, upper: 0.0002, cls_loss: 0.0000, line_iou: 0.0016, conf: 0.1953), s/iter: 0.1002, lr: 3.0e-04
[2024-12-25 21:59:53,285] [INFO] Epoch [22/2695], Step [861/910], Loss: 2.8908 (poly: 0.0676, lower: 0.0000, upper: 0.0002, cls_loss: 0.0000, line_iou: 0.0016, conf: 0.1953), s/iter: 0.1001, lr: 3.0e-04
[2024-12-25 21:59:53,386] [INFO] Epoch [22/2695], Step [862/910], Loss: 2.8878 (poly: 0.0899, lower: 0.0000, upper: 0.0000, cls_loss: 0.0000, line_iou: 0.0014, conf: 0.2182), s/iter: 0.0998, lr: 3.0e-04
[2024-12-25 21:59:53,482] [INFO] Epoch [22/2695], Step [863/910], Loss: 2.8848 (poly: 0.0938, lower: 0.0000, upper: 0.0000, cls_loss: 0.0000, line_iou: 0.0013, conf: 0.2181), s/iter: 0.0996, lr: 3.0e-04
[2024-12-25 21:59:53,536] [INFO] Weight SoftAdapt Loss tensor([0.4967, 0.0017, 0.0017, 0.0017, 0.0017, 0.4967], dtype=torch.float64)
[2024-12-25 21:59:53,596] [INFO] Epoch [22/2695], Step [864/910], Loss: 2.8819 (poly: 0.0023, lower: 0.0000, upper: 0.0000, cls_loss: 0.0000, line_iou: 0.4174, conf: 0.0004), s/iter: 0.0996, lr: 3.0e-04
[2024-12-25 21:59:53,711] [INFO] Epoch [22/2695], Step [865/910], Loss: 2.8791 (poly: 0.0039, lower: 0.0000, upper: 0.0000, cls_loss: 0.0000, line_iou: 0.4101, conf: 0.0007), s/iter: 0.0997, lr: 3.0e-04
[2024-12-25 21:59:53,834] [INFO] Epoch [22/2695], Step [866/910], Loss: 2.8762 (poly: 0.0027, lower: 0.0000, upper: 0.0000, cls_loss: 0.0000, line_iou: 0.4048, conf: 0.0004), s/iter: 0.1001, lr: 3.0e-04
[2024-12-25 21:59:53,943] [INFO] Epoch [22/2695], Step [867/910], Loss: 2.8734 (poly: 0.0038, lower: 0.0000, upper: 0.0000, cls_loss: 0.0000, line_iou: 0.4400, conf: 0.0004), s/iter: 0.1000, lr: 3.0e-04
[2024-12-25 21:59:54,065] [INFO] Epoch [22/2695], Step [868/910], Loss: 2.8708 (poly: 0.1227, lower: 0.0000, upper: 0.0001, cls_loss: 0.0000, line_iou: 0.4825, conf: 0.0007), s/iter: 0.1002, lr: 3.0e-04
[2024-12-25 21:59:54,165] [INFO] Epoch [22/2695], Step [869/910], Loss: 2.8680 (poly: 0.0022, lower: 0.0000, upper: 0.0000, cls_loss: 0.0000, line_iou: 0.4102, conf: 0.0004), s/iter: 0.1002, lr: 3.0e-04
[2024-12-25 21:59:54,277] [INFO] Epoch [22/2695], Step [870/910], Loss: 2.8651 (poly: 0.0022, lower: 0.0000, upper: 0.0000, cls_loss: 0.0000, line_iou: 0.3858, conf: 0.0004), s/iter: 0.1000, lr: 3.0e-04
[2024-12-25 21:59:54,386] [INFO] Epoch [22/2695], Step [871/910], Loss: 2.8623 (poly: 0.0050, lower: 0.0000, upper: 0.0000, cls_loss: 0.0000, line_iou: 0.4296, conf: 0.0004), s/iter: 0.1000, lr: 3.0e-04
[2024-12-25 21:59:54,482] [INFO] Epoch [22/2695], Step [872/910], Loss: 2.8595 (poly: 0.0021, lower: 0.0000, upper: 0.0000, cls_loss: 0.0000, line_iou: 0.4005, conf: 0.0004), s/iter: 0.0998, lr: 3.0e-04
[2024-12-25 21:59:54,528] [INFO] Weight SoftAdapt Loss tensor([0.4967, 0.0017, 0.0017, 0.0017, 0.4967, 0.0017], dtype=torch.float64)
[2024-12-25 21:59:54,595] [INFO] Epoch [22/2695], Step [873/910], Loss: 2.8571 (poly: 0.0004, lower: 0.0000, upper: 0.0001, cls_loss: 0.0000, line_iou: 0.4853, conf: 0.2180), s/iter: 0.0999, lr: 3.0e-04
[2024-12-25 21:59:54,692] [INFO] Epoch [22/2695], Step [874/910], Loss: 2.8544 (poly: 0.0000, lower: 0.0000, upper: 0.0000, cls_loss: 0.0000, line_iou: 0.4245, conf: 0.1065), s/iter: 0.0999, lr: 3.0e-04
[2024-12-25 21:59:54,803] [INFO] Epoch [22/2695], Step [875/910], Loss: 2.8519 (poly: 0.0002, lower: 0.0000, upper: 0.0002, cls_loss: 0.0000, line_iou: 0.4860, conf: 0.1951), s/iter: 0.1000, lr: 3.0e-04
[2024-12-25 21:59:54,899] [INFO] Epoch [22/2695], Step [876/910], Loss: 2.8494 (poly: 0.0002, lower: 0.0000, upper: 0.0002, cls_loss: 0.0000, line_iou: 0.4887, conf: 0.1951), s/iter: 0.1000, lr: 3.0e-04
[2024-12-25 21:59:54,998] [INFO] Epoch [22/2695], Step [877/910], Loss: 2.8469 (poly: 0.0000, lower: 0.0000, upper: 0.0000, cls_loss: 0.0000, line_iou: 0.4051, conf: 0.1951), s/iter: 0.1001, lr: 3.0e-04
[2024-12-25 21:59:55,094] [INFO] Epoch [22/2695], Step [878/910], Loss: 2.8443 (poly: 0.0000, lower: 0.0000, upper: 0.0000, cls_loss: 0.0000, line_iou: 0.4405, conf: 0.1065), s/iter: 0.1001, lr: 3.0e-04
[2024-12-25 21:59:55,181] [INFO] Epoch [22/2695], Step [879/910], Loss: 2.8418 (poly: 0.0004, lower: 0.0000, upper: 0.0001, cls_loss: 0.0000, line_iou: 0.4842, conf: 0.2180), s/iter: 0.1000, lr: 3.0e-04
[2024-12-25 21:59:55,269] [INFO] Epoch [22/2695], Step [880/910], Loss: 2.8392 (poly: 0.0000, lower: 0.0000, upper: 0.0000, cls_loss: 0.0000, line_iou: 0.4121, conf: 0.1065), s/iter: 0.0999, lr: 3.0e-04
[2024-12-25 21:59:55,365] [INFO] Epoch [22/2695], Step [881/910], Loss: 2.8366 (poly: 0.0000, lower: 0.0000, upper: 0.0000, cls_loss: 0.0000, line_iou: 0.4223, conf: 0.1065), s/iter: 0.0999, lr: 3.0e-04
[2024-12-25 21:59:55,414] [INFO] Weight SoftAdapt Loss tensor([0.0017, 0.0017, 0.0017, 0.0017, 0.4967, 0.4967], dtype=torch.float64)
[2024-12-25 21:59:55,478] [INFO] Epoch [22/2695], Step [882/910], Loss: 2.8335 (poly: 0.0481, lower: 0.0000, upper: 0.0001, cls_loss: 0.0000, line_iou: 0.0016, conf: 0.1065), s/iter: 0.1000, lr: 3.0e-04
[2024-12-25 21:59:55,602] [INFO] Epoch [22/2695], Step [883/910], Loss: 2.8304 (poly: 0.0045, lower: 0.0000, upper: 0.0000, cls_loss: 0.0000, line_iou: 0.0015, conf: 0.1065), s/iter: 0.1002, lr: 3.0e-04
[2024-12-25 21:59:55,707] [INFO] Epoch [22/2695], Step [884/910], Loss: 2.8274 (poly: 0.0043, lower: 0.0000, upper: 0.0000, cls_loss: 0.0000, line_iou: 0.0014, conf: 0.1065), s/iter: 0.1002, lr: 3.0e-04
[2024-12-25 21:59:55,814] [INFO] Epoch [22/2695], Step [885/910], Loss: 2.8244 (poly: 0.0594, lower: 0.0000, upper: 0.0002, cls_loss: 0.0000, line_iou: 0.0016, conf: 0.1064), s/iter: 0.1002, lr: 3.0e-04
[2024-12-25 21:59:55,940] [INFO] Epoch [22/2695], Step [886/910], Loss: 2.8215 (poly: 0.0782, lower: 0.0000, upper: 0.0002, cls_loss: 0.0000, line_iou: 0.0016, conf: 0.1950), s/iter: 0.1005, lr: 3.0e-04
[2024-12-25 21:59:56,074] [INFO] Epoch [22/2695], Step [887/910], Loss: 2.8184 (poly: 0.0057, lower: 0.0000, upper: 0.0000, cls_loss: 0.0000, line_iou: 0.0015, conf: 0.1065), s/iter: 0.1008, lr: 3.0e-04
[2024-12-25 21:59:56,172] [INFO] Epoch [22/2695], Step [888/910], Loss: 2.8154 (poly: 0.0039, lower: 0.0000, upper: 0.0000, cls_loss: 0.0000, line_iou: 0.0015, conf: 0.1064), s/iter: 0.1007, lr: 3.0e-04
[2024-12-25 21:59:56,260] [INFO] Epoch [22/2695], Step [889/910], Loss: 2.8126 (poly: 0.1410, lower: 0.0000, upper: 0.0002, cls_loss: 0.0000, line_iou: 0.0016, conf: 0.2180), s/iter: 0.1005, lr: 3.0e-04
[2024-12-25 21:59:56,353] [INFO] Epoch [22/2695], Step [890/910], Loss: 2.8096 (poly: 0.0030, lower: 0.0000, upper: 0.0000, cls_loss: 0.0000, line_iou: 0.0012, conf: 0.1064), s/iter: 0.1005, lr: 3.0e-04
[2024-12-25 21:59:56,397] [INFO] Weight SoftAdapt Loss tensor([0.4967, 0.0017, 0.0017, 0.0017, 0.0017, 0.4967], dtype=torch.float64)
[2024-12-25 21:59:56,457] [INFO] Epoch [22/2695], Step [891/910], Loss: 2.8070 (poly: 0.0674, lower: 0.0000, upper: 0.0001, cls_loss: 0.0000, line_iou: 0.4864, conf: 0.0006), s/iter: 0.1006, lr: 3.0e-04
[2024-12-25 21:59:56,545] [INFO] Epoch [22/2695], Step [892/910], Loss: 2.8044 (poly: 0.0059, lower: 0.0000, upper: 0.0000, cls_loss: 0.0000, line_iou: 0.4357, conf: 0.0004), s/iter: 0.1003, lr: 3.0e-04
[2024-12-25 21:59:56,634] [INFO] Epoch [22/2695], Step [893/910], Loss: 2.8019 (poly: 0.1242, lower: 0.0000, upper: 0.0002, cls_loss: 0.0000, line_iou: 0.4752, conf: 0.0007), s/iter: 0.1001, lr: 3.0e-04
[2024-12-25 21:59:56,741] [INFO] Epoch [22/2695], Step [894/910], Loss: 2.7992 (poly: 0.0030, lower: 0.0000, upper: 0.0000, cls_loss: 0.0000, line_iou: 0.3935, conf: 0.0004), s/iter: 0.1000, lr: 3.0e-04
[2024-12-25 21:59:56,838] [INFO] Epoch [22/2695], Step [895/910], Loss: 2.7965 (poly: 0.0037, lower: 0.0000, upper: 0.0000, cls_loss: 0.0000, line_iou: 0.3553, conf: 0.0006), s/iter: 0.0999, lr: 3.0e-04
[2024-12-25 21:59:56,954] [INFO] Epoch [22/2695], Step [896/910], Loss: 2.7938 (poly: 0.0042, lower: 0.0000, upper: 0.0000, cls_loss: 0.0000, line_iou: 0.4042, conf: 0.0004), s/iter: 0.1000, lr: 3.0e-04
[2024-12-25 21:59:57,062] [INFO] Epoch [22/2695], Step [897/910], Loss: 2.7913 (poly: 0.0958, lower: 0.0000, upper: 0.0000, cls_loss: 0.0000, line_iou: 0.4326, conf: 0.0007), s/iter: 0.1001, lr: 3.0e-04
[2024-12-25 21:59:57,159] [INFO] Epoch [22/2695], Step [898/910], Loss: 2.7887 (poly: 0.0042, lower: 0.0000, upper: 0.0000, cls_loss: 0.0000, line_iou: 0.4308, conf: 0.0004), s/iter: 0.0999, lr: 3.0e-04
[2024-12-25 21:59:57,262] [INFO] Epoch [22/2695], Step [899/910], Loss: 2.7861 (poly: 0.0050, lower: 0.0000, upper: 0.0000, cls_loss: 0.0000, line_iou: 0.4040, conf: 0.0006), s/iter: 0.1001, lr: 3.0e-04
[2024-12-25 21:59:57,311] [INFO] Weight SoftAdapt Loss tensor([0.4967, 0.0017, 0.0017, 0.0017, 0.4967, 0.0017], dtype=torch.float64)
[2024-12-25 21:59:57,369] [INFO] Epoch [22/2695], Step [900/910], Loss: 2.7836 (poly: 0.0000, lower: 0.0000, upper: 0.0000, cls_loss: 0.0000, line_iou: 0.4280, conf: 0.1063), s/iter: 0.1002, lr: 3.0e-04
[2024-12-25 21:59:57,459] [INFO] Epoch [22/2695], Step [901/910], Loss: 2.7811 (poly: 0.0000, lower: 0.0000, upper: 0.0000, cls_loss: 0.0000, line_iou: 0.4277, conf: 0.1062), s/iter: 0.1000, lr: 3.0e-04
[2024-12-25 21:59:57,547] [INFO] Epoch [22/2695], Step [902/910], Loss: 2.7787 (poly: 0.0002, lower: 0.0000, upper: 0.0002, cls_loss: 0.0000, line_iou: 0.4744, conf: 0.1949), s/iter: 0.1000, lr: 3.0e-04
[2024-12-25 21:59:57,638] [INFO] Epoch [22/2695], Step [903/910], Loss: 2.7762 (poly: 0.0000, lower: 0.0000, upper: 0.0000, cls_loss: 0.0000, line_iou: 0.4211, conf: 0.1062), s/iter: 0.1000, lr: 3.0e-04
[2024-12-25 21:59:57,730] [INFO] Epoch [22/2695], Step [904/910], Loss: 2.7737 (poly: 0.0000, lower: 0.0000, upper: 0.0000, cls_loss: 0.0000, line_iou: 0.4265, conf: 0.1062), s/iter: 0.0997, lr: 3.0e-04
[2024-12-25 21:59:57,827] [INFO] Epoch [22/2695], Step [905/910], Loss: 2.7714 (poly: 0.0003, lower: 0.0000, upper: 0.0000, cls_loss: 0.0000, line_iou: 0.4152, conf: 0.2179), s/iter: 0.0996, lr: 3.0e-04
[2024-12-25 21:59:57,931] [INFO] Epoch [22/2695], Step [906/910], Loss: 2.7691 (poly: 0.0004, lower: 0.0000, upper: 0.0003, cls_loss: 0.0000, line_iou: 0.4942, conf: 0.2179), s/iter: 0.0996, lr: 3.0e-04
[2024-12-25 21:59:58,046] [INFO] Epoch [22/2695], Step [907/910], Loss: 2.7666 (poly: 0.0000, lower: 0.0000, upper: 0.0000, cls_loss: 0.0000, line_iou: 0.3943, conf: 0.1062), s/iter: 0.0996, lr: 3.0e-04
[2024-12-25 21:59:58,143] [INFO] Epoch [22/2695], Step [908/910], Loss: 2.7643 (poly: 0.0004, lower: 0.0000, upper: 0.0001, cls_loss: 0.0000, line_iou: 0.4911, conf: 0.2178), s/iter: 0.0994, lr: 3.0e-04
[2024-12-25 21:59:58,197] [INFO] Weight SoftAdapt Loss tensor([0.0017, 0.0017, 0.0017, 0.0017, 0.4967, 0.4967], dtype=torch.float64)
[2024-12-25 21:59:58,258] [INFO] Epoch [22/2695], Step [909/910], Loss: 2.7615 (poly: 0.0305, lower: 0.0000, upper: 0.0001, cls_loss: 0.0000, line_iou: 0.0015, conf: 0.1949), s/iter: 0.0995, lr: 3.0e-04
[2024-12-25 21:59:58,351] [INFO] Epoch [22/2695], Step [910/910], Loss: 2.7586 (poly: 0.0079, lower: 0.0000, upper: 0.0000, cls_loss: 0.0000, line_iou: 0.0016, conf: 0.1061), s/iter: 0.0993, lr: 3.0e-04
[2024-12-25 22:00:00,059] [INFO] Epoch time: 146.8859
[2024-12-25 22:00:00,253] [INFO] Checkpoint saved at experiments\tusimple\models\model_022.pt
